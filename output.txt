From https://github.com/rato-tokyo/new-llm
 * branch            main       -> FETCH_HEAD
Already up to date.
Device: cuda (NVIDIA L4, 23.8GB)
======================================================================
V-DPROJ EXPERIMENT: Value Compression
======================================================================
Samples: 10,000
Sequence length: 128
Epochs: 30
Learning rate: 0.0001
V proj dim: 320 (from 512)
Reconstruction weight: 0.1
Skip baseline: True
======================================================================

KV Cache reduction (V only): 18.8%
======================================================================

[Data] Loading Pile data...
Preparing data: 10,000 samples, seq_len=128
Downloading Pile dataset: 1,280,128 tokens
  Loading tokenizer: EleutherAI/pythia-70m
tokenizer_config.json: 100% 396/396 [00:00<00:00, 3.56MB/s]
tokenizer.json: 2.11MB [00:00, 119MB/s]
special_tokens_map.json: 100% 99.0/99.0 [00:00<00:00, 1.20MB/s]
  Loading dataset (streaming)...
README.md: 100% 776/776 [00:00<00:00, 9.09MB/s]
Resolving data files: 100% 30/30 [00:00<00:00, 93.54it/s]
  Tokenizing...
  Saved 1,280,128 tokens to cache: cache/pile_tokens/pile_1280128.pt
  Train: 9,000 samples
  Val: 1,000 samples

======================================================================
1. PYTHIA-70M (Baseline) - SKIPPED
======================================================================

======================================================================
2. V-DPROJ PYTHIA (V: 512 â†’ 320)
======================================================================
  Total parameters: 72,391,552
  V projection: 1,971,072
  KV Cache reduction: 18.8%

[V-DProj] Training (recon_weight=0.1)...
  Epoch  1: train_ppl=615.6 val_ppl=635.5 recon=0.1266 [79.6s] *
  Epoch  2: train_ppl=160.7 val_ppl=477.9 recon=0.1248 [80.6s] *
  Epoch  3: train_ppl=85.8 val_ppl=435.4 recon=0.1268 [80.8s] *
  Epoch  4: train_ppl=53.4 val_ppl=428.7 recon=0.1300 [80.7s] *
  Epoch  5: train_ppl=35.6 val_ppl=456.5 recon=0.1366 [80.7s] 
  Epoch  6: train_ppl=24.4 val_ppl=514.0 recon=0.1422 [80.9s] 
  Epoch  7: train_ppl=16.9 val_ppl=613.3 recon=0.1498 [80.8s] 
  -> Early stop
  Best: epoch 4, ppl=428.7

  Position-wise PPL:
    Position 0-16: 853.0
    Position 16-32: 667.5
    Position 32-64: 586.6
    Position 64-96: 578.1
    Position 96-128: 552.8

======================================================================
SUMMARY
======================================================================

| Model | PPL | Epoch | KV Reduction |
|-------|-----|-------|--------------|
| V-DProj | 428.7 | 4 | 18.8% |

DONE
