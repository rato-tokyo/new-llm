From https://github.com/rato-tokyo/new-llm
 * branch            main       -> FETCH_HEAD
Already up to date.
Device: cuda (NVIDIA L4, 23.8GB)
======================================================================
V-DPROJ EXPERIMENT: Value Compression (No Restoration)
======================================================================
Samples: 10,000
Sequence length: 128
Epochs: 30
Learning rate: 0.0001
V proj dim: 320 (from 512)
Skip baseline: True
======================================================================

KV Cache reduction: 18.8%
======================================================================

[Data] Loading Pile data...
Preparing data: 10,000 samples, seq_len=128
Downloading Pile dataset: 1,280,128 tokens
  Loading tokenizer: EleutherAI/pythia-70m
tokenizer_config.json: 100% 396/396 [00:00<00:00, 3.73MB/s]
tokenizer.json: 2.11MB [00:00, 71.6MB/s]
special_tokens_map.json: 100% 99.0/99.0 [00:00<00:00, 972kB/s]
  Loading dataset (streaming)...
README.md: 100% 776/776 [00:00<00:00, 8.54MB/s]
Resolving data files: 100% 30/30 [00:00<00:00, 260.39it/s]
  Tokenizing...
  Saved 1,280,128 tokens to cache: cache/pile_tokens/pile_1280128.pt
  Train: 9,000 samples
  Val: 1,000 samples

======================================================================
1. PYTHIA-70M (Baseline) - SKIPPED
======================================================================

======================================================================
2. V-DPROJ PYTHIA (V: 512 â†’ 320)
======================================================================
  Total parameters: 69,239,680
  V projection: 1,971,072
  KV Cache reduction: 18.8%

[V-DProj] Training...
  Epoch  1: train_ppl=621.1 val_ppl=646.1 [73.7s] *
  Epoch  2: train_ppl=155.8 val_ppl=454.8 [74.3s] *
  Epoch  3: train_ppl=80.4 val_ppl=423.9 [75.2s] *
  Epoch  4: train_ppl=48.2 val_ppl=424.8 [75.5s] 
  -> Early stop
  Best: epoch 3, ppl=423.9

  Position-wise PPL:
    Position 0-16: 564.6
    Position 16-32: 450.5
    Position 32-64: 405.1
    Position 64-96: 406.7
    Position 96-128: 391.8

======================================================================
SUMMARY
======================================================================

| Model | PPL | Epoch | KV Reduction |
|-------|-----|-------|--------------|
| V-DProj | 423.9 | 3 | 18.8% |

DONE
