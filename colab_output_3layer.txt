
======================================================================
New-LLM Training for Google Colab (Eæ¡ˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£)
======================================================================

âœ… Random seed fixed: 42 (å®Œå…¨ãªå†ç¾æ€§ä¿è¨¼)
ğŸ–¥ï¸  Device: cuda
   GPU: NVIDIA L4
   Memory: 23.8 GB

ğŸ“‹ Configuration:
   Architecture: Eæ¡ˆ (Separated ContextBlock + TokenBlock)
   Context layers: 3
   Token layers: 3
   Context dim: 768
   Embed dim: 768
   Diversity weight: 0.5
   Phase 2 epochs: 10
   Early stopping patience: 3

ğŸ“¥ Downloading GPT-2 tokenizer...
tokenizer_config.json: 100% 26.0/26.0 [00:00<00:00, 175kB/s]
vocab.json: 100% 1.04M/1.04M [00:00<00:00, 2.43MB/s]
merges.txt: 100% 456k/456k [00:00<00:00, 1.07MB/s]
tokenizer.json: 100% 1.36M/1.36M [00:00<00:00, 3.05MB/s]
config.json: 100% 665/665 [00:00<00:00, 6.23MB/s]
âœ“ Tokenizer saved

ğŸ“¦ Creating model (Eæ¡ˆ architecture)...
2025-11-26 08:10:56.969419: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-26 08:10:56.985974: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1764144657.004969    6653 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1764144657.010495    6653 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1764144657.027310    6653 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1764144657.027344    6653 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1764144657.027347    6653 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1764144657.027349    6653 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-26 08:10:57.032251: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
Loading GPT-2 pretrained embeddings...
âœ“ Loaded GPT-2 embeddings: torch.Size([50257, 768])
Using Eæ¡ˆ architecture: ContextBlock(3 layers) + TokenBlock(3 layers)
âœ“ Model created: 84,338,257 parameters

ğŸ“Š Loading data from UltraChat...
tokenizer_config.json: 100% 26.0/26.0 [00:00<00:00, 236kB/s]
config.json: 100% 665/665 [00:00<00:00, 6.00MB/s]
vocab.json: 100% 1.04M/1.04M [00:00<00:00, 2.48MB/s]
merges.txt: 100% 456k/456k [00:00<00:00, 85.1MB/s]
tokenizer.json: 100% 1.36M/1.36M [00:00<00:00, 2.11MB/s]
   Downloading UltraChat dataset...
Generating train_sft split: 100% 207865/207865 [00:04<00:00, 51505.40 examples/s]
Generating test_sft split: 100% 23110/23110 [00:00<00:00, 55822.76 examples/s]
Generating train_gen split: 100% 256032/256032 [00:05<00:00, 47021.55 examples/s]
Generating test_gen split: 100% 28304/28304 [00:00<00:00, 72457.89 examples/s]
   Cached to: ./cache/ultrachat_500samples_128len.pt
   Total tokens: 64,000
   Train: 62,720 tokens
   Val:   1,280 tokens (fixed size)
   âœ“ Validation auto-generated from training data

======================================================================
PHASE 1: å›ºå®šç‚¹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’ (CVFP) - ContextBlock
======================================================================


======================================================================
PHASE 1: å›ºå®šç‚¹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’ (ContextBlock) - Train
======================================================================
Training ContextBlock only (3545856 parameters)
Iteration 1/30: é †ä¼æ’­ã®ã¿ï¼ˆã‚·ãƒ¼ã‚±ãƒ³ã‚·ãƒ£ãƒ«ï¼‰ [35.93s]
Iteration 2/30: åæŸ=100.0% | Total=-0.049174 | CVFP=0.000005 | Div=-0.098353 | Time=2.82s
Iteration 3/30: åæŸ=0.0% | Total=0.111256 | CVFP=0.329293 | Div=-0.106782 | Time=0.17s
Iteration 4/30: åæŸ=0.0% | Total=0.075773 | CVFP=0.256596 | Div=-0.105050 | Time=0.18s
Iteration 5/30: åæŸ=0.0% | Total=0.025402 | CVFP=0.154372 | Div=-0.103568 | Time=0.18s
Iteration 6/30: åæŸ=0.7% | Total=-0.015653 | CVFP=0.071442 | Div=-0.102748 | Time=0.18s
Iteration 7/30: åæŸ=41.3% | Total=-0.034850 | CVFP=0.032932 | Div=-0.102631 | Time=0.18s
Iteration 8/30: åæŸ=99.2% | Total=-0.043757 | CVFP=0.015437 | Div=-0.102951 | Time=0.18s
Iteration 9/30: åæŸ=100.0% | Total=-0.048172 | CVFP=0.006987 | Div=-0.103332 | Time=0.18s
Iteration 10/30: åæŸ=100.0% | Total=-0.050286 | CVFP=0.003105 | Div=-0.103677 | Time=0.18s
Iteration 11/30: åæŸ=100.0% | Total=-0.051278 | CVFP=0.001445 | Div=-0.104001 | Time=0.18s
Iteration 12/30: åæŸ=100.0% | Total=-0.051801 | CVFP=0.000725 | Div=-0.104327 | Time=0.18s
Iteration 13/30: åæŸ=100.0% | Total=-0.052122 | CVFP=0.000407 | Div=-0.104652 | Time=0.18s
Iteration 14/30: åæŸ=100.0% | Total=-0.052357 | CVFP=0.000262 | Div=-0.104977 | Time=0.18s
Iteration 15/30: åæŸ=100.0% | Total=-0.052554 | CVFP=0.000194 | Div=-0.105302 | Time=0.18s
Iteration 16/30: åæŸ=100.0% | Total=-0.052734 | CVFP=0.000158 | Div=-0.105627 | Time=0.18s
Iteration 17/30: åæŸ=100.0% | Total=-0.052907 | CVFP=0.000138 | Div=-0.105951 | Time=0.18s
Iteration 18/30: åæŸ=100.0% | Total=-0.053074 | CVFP=0.000124 | Div=-0.106273 | Time=0.18s
Iteration 19/30: åæŸ=100.0% | Total=-0.053239 | CVFP=0.000115 | Div=-0.106593 | Time=0.18s
Iteration 20/30: åæŸ=100.0% | Total=-0.053401 | CVFP=0.000107 | Div=-0.106910 | Time=0.18s
Iteration 21/30: åæŸ=100.0% | Total=-0.053561 | CVFP=0.000101 | Div=-0.107224 | Time=0.18s
Iteration 22/30: åæŸ=100.0% | Total=-0.053720 | CVFP=0.000096 | Div=-0.107535 | Time=0.18s
Iteration 23/30: åæŸ=100.0% | Total=-0.053876 | CVFP=0.000091 | Div=-0.107843 | Time=0.18s
Iteration 24/30: åæŸ=100.0% | Total=-0.054030 | CVFP=0.000087 | Div=-0.108148 | Time=0.18s
Iteration 25/30: åæŸ=100.0% | Total=-0.054183 | CVFP=0.000083 | Div=-0.108450 | Time=0.18s
Iteration 26/30: åæŸ=100.0% | Total=-0.054334 | CVFP=0.000080 | Div=-0.108748 | Time=0.18s
Iteration 27/30: åæŸ=100.0% | Total=-0.054483 | CVFP=0.000077 | Div=-0.109044 | Time=0.18s
Iteration 28/30: åæŸ=100.0% | Total=-0.054631 | CVFP=0.000074 | Div=-0.109336 | Time=0.18s
Iteration 29/30: åæŸ=100.0% | Total=-0.054777 | CVFP=0.000071 | Div=-0.109626 | Time=0.18s
Iteration 30/30: åæŸ=100.0% | Total=-0.054922 | CVFP=0.000069 | Div=-0.109912 | Time=0.18s

Phase 1 å®Œäº†: 62720/62720 ãƒˆãƒ¼ã‚¯ãƒ³ãŒåæŸ


======================================================================
Evaluating on validation data...
======================================================================


â±ï¸  Phase 1 completed in 46.5s
ğŸ’¾ Checkpoint saved: ./checkpoints/model_latest.pt

======================================================================
FIXED-POINT ANALYSIS
======================================================================


======================================================================
FIXED-POINT ANALYSIS - Train
======================================================================

(Sampling 5000/62720 tokens for pairwise analysis)

1. Global Attractor Detection:
  Avg L2 Distance: 38.797886 (Range: [0.000000, 45.744625])
  Avg Cosine Sim:  0.055463 (Range: [-0.302664, 1.000001])
  âœ… Token-specific fixed points

2. Zero Solution Detection:
  Avg Norm: 28.336758 (Range: [28.240046, 28.448603])
  âœ… Non-zero contexts

3. Distribution Statistics:
  Norm - Mean: 28.3368, Median: 28.3370, Std: 0.0239
  Pairwise Dist - Mean: 38.7979
  Sparsity: 0.63% of values < 0.01

4. Information Content:
  Actual Rank: 768 / 768 (100.0%)
  Effective Rank: 616.92 / 768 (80.3%)
  Top 5 Singular Values: [989.1885375976562, 624.0169067382812, 599.4425659179688, 476.6092224121094, 443.9137878417969]
  âœ… Good diversity
======================================================================


======================================================================
FIXED-POINT ANALYSIS - Val
======================================================================

1. Global Attractor Detection:
  Avg L2 Distance: 38.832539 (Range: [0.000000, 45.096485])
  Avg Cosine Sim:  0.056143 (Range: [-0.262817, 1.000000])
  âœ… Token-specific fixed points

2. Zero Solution Detection:
  Avg Norm: 28.377045 (Range: [28.297693, 28.467369])
  âœ… Non-zero contexts

3. Distribution Statistics:
  Norm - Mean: 28.3770, Median: 28.3765, Std: 0.0245
  Pairwise Dist - Mean: 38.8325
  Sparsity: 0.62% of values < 0.01

4. Information Content:
  Actual Rank: 768 / 768 (100.0%)
  Effective Rank: 533.69 / 768 (69.5%)
  Top 5 Singular Values: [361.1494140625, 232.88351440429688, 213.8627471923828, 166.22763061523438, 152.5756378173828]
  âœ… Good diversity
======================================================================


======================================================================
æ’ç­‰å†™åƒãƒã‚§ãƒƒã‚¯ (Identity Mapping Check)
======================================================================
ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦çµ±è¨ˆ (100ã‚µãƒ³ãƒ—ãƒ«):
  å¹³å‡: 0.0638
  æœ€å¤§: 0.1447
  æœ€å°: -0.0197
  é–¾å€¤(0.95)è¶…é: 0/100 (0.0%)

âœ… æ­£å¸¸: æ’ç­‰å†™åƒã§ã¯ã‚ã‚Šã¾ã›ã‚“
    ãƒ¢ãƒ‡ãƒ«ãŒãƒˆãƒ¼ã‚¯ãƒ³æƒ…å ±ã‚’ä½¿ç”¨ã—ã¦ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å¤‰æ›ã—ã¦ã„ã¾ã™ã€‚
======================================================================


======================================================================
PHASE 2: ãƒˆãƒ¼ã‚¯ãƒ³äºˆæ¸¬å­¦ç¿’ (TokenBlock)
======================================================================

âœ“ ContextBlock frozen
âœ“ token_output layer unfrozen
âœ“ Training TokenBlock + token_output: 42,193,489/84,338,257 parameters

======================================================================
PHASE 2: Next-Token Prediction Training (Eæ¡ˆ - ãƒ¬ã‚¤ãƒ¤ãƒ¼å¯¾å¿œç‰ˆ)
======================================================================

Training tokens: 62,720
Validation tokens: 1,280
Epochs: 10
Batch size: 512
Learning rate: 0.002
Gradient clip: 1.0
Early stopping patience: 3

Architecture: Eæ¡ˆ (ContextBlock + TokenBlock Layer-wise)
  - ContextBlock: FROZEN (Phase 1ã§å­¦ç¿’æ¸ˆã¿)
  - TokenBlock: TRAINING
  - token_output: TRAINING
  - Eæ¡ˆ: TokenBlock Layer i ã¯ ContextBlock Layer i ã®å‡ºåŠ›ã‚’å‚ç…§

Epoch 1/10 [295.8s]:
  Train Loss: 7.2477 | Train PPL: 1404.88
  Val Loss: 6.6525 | Val PPL: 774.75 | Val Acc: 16.18%
  âœ“ New best validation loss: 6.6525

Epoch 2/10 [295.4s]:
  Train Loss: 4.6388 | Train PPL: 103.42
  Val Loss: 6.9805 | Val PPL: 1075.45 | Val Acc: 17.04%
  âš ï¸ No improvement (1/3)

Epoch 3/10 [295.3s]:
  Train Loss: 3.3043 | Train PPL: 27.23
  Val Loss: 7.5120 | Val PPL: 1829.88 | Val Acc: 16.65%
  âš ï¸ No improvement (2/3)

Epoch 4/10 [296.2s]:
  Train Loss: 2.8499 | Train PPL: 17.29
  Val Loss: 7.4663 | Val PPL: 1748.19 | Val Acc: 17.36%
  âš ï¸ No improvement (3/3)

â›” Early stopping triggered at epoch 4
   Val loss hasn't improved for 3 epochs
======================================================================
Phase 2 Training Complete
======================================================================

Best epoch: 1
Best validation loss: 6.6525
Best validation PPL: 774.75
Best validation accuracy: 16.18%
Early stopped at epoch: 4


â±ï¸  Phase 2 completed in 1182.6s
ğŸ’¾ Final checkpoint saved: ./checkpoints/model_latest.pt


======================================================================
                    NEW-LLM TRAINING RESULTS                         
======================================================================

[PHASE 1: Context Learning (CVFP) - ContextBlock]
  Effective Rank (Train): 80.3% (616.92/768)
  Effective Rank (Val):   69.5% (533.69/768)
  Time: 46.5s
  Status: âœ… PASSED

[PHASE 2: Token Prediction - TokenBlock]
  Best Val PPL:    774.75 (Epoch 1)
  Best Val Acc:    16.18%
  Final Val PPL:   1748.19
  Final Val Acc:   17.36%
  Epochs Run:      4/10
  Time: 1182.6s
  Status: âš ï¸  EARLY STOPPED at epoch 4

----------------------------------------------------------------------
  TOTAL TIME: 1264.9s
======================================================================

ğŸ“‰ Epoch-by-Epoch Progress:
--------------------------------------------------
 Epoch |  Train PPL |    Val PPL |  Val Acc
--------------------------------------------------
     1 |    1404.88 |     774.75 |   16.18% â­
     2 |     103.42 |    1075.45 |   17.04%
     3 |      27.23 |    1829.88 |   16.65%
     4 |      17.29 |    1748.19 |   17.36%
--------------------------------------------------

âœ… Training complete!
