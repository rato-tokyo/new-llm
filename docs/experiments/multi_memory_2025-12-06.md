# Multi-Memory Infini-Attention 実験結果

**日付**: 2025-12-06
**環境**: NVIDIA L4 (23.8GB)

---

## 実験概要

Multi-Memory Infini-Attention（Attention-based Selection）の性能検証。
Single Memory Infini-Pythiaとの比較。

### 設定

| 項目 | 値 |
|------|-----|
| サンプル数 | 5,000 |
| シーケンス長 | 256 |
| エポック数 | 30 (early stopping) |
| 学習率 | 1e-4 |
| メモリ数 | 4 |
| Delta Rule | 有効 |

---

## 結果サマリー

| モデル | Best PPL | Best Epoch | メモリサイズ |
|--------|----------|------------|--------------|
| Single Memory | 105.9 | 7 | 133KB |
| Multi Memory (4) | 105.8 | 7 | 532KB |

**差分**: -0.1 PPL（ほぼ同等）

---

## 詳細分析

### 1. 学習曲線

両モデルの学習曲線はほぼ同一:

| Epoch | Single train | Single val | Multi train | Multi val |
|-------|--------------|------------|-------------|-----------|
| 1 | 595.5 | 406.0 | 596.2 | 405.8 |
| 2 | 163.4 | 234.3 | 164.0 | 232.1 |
| 3 | 92.5 | 169.3 | 92.5 | 169.0 |
| 4 | 60.4 | 137.5 | 60.4 | 137.8 |
| 5 | 42.2 | 119.4 | 42.2 | 119.4 |
| 6 | 30.5 | 110.1 | 30.5 | 110.2 |
| 7 | 22.4 | 105.9* | 22.3 | 105.8* |
| 8 | 16.5 | 107.9 | 16.5 | 107.5 |

両モデルともEpoch 8でearly stopping。

### 2. Position-wise PPL

| Position | Single | Multi | 差分 |
|----------|--------|-------|------|
| 0-16 | 154.0 | 156.5 | +2.5 |
| 16-32 | 111.3 | 111.4 | +0.1 |
| 32-64 | 102.0 | 102.5 | +0.5 |
| 64-96 | 98.4 | 99.1 | +0.7 |
| 96-256 | 103.7 | 103.1 | -0.6 |

ほぼ同等の位置依存性を示す。

### 3. Reversal Curse

| モデル | Forward PPL | Backward PPL | Gap |
|--------|-------------|--------------|-----|
| Single | 1.8 | 604.5 | +602.7 |
| Multi | 1.8 | 508.6 | +506.8 |

**Multi-Memoryで約16%改善** (604.5 → 508.6)

---

## 考察

### 1. PPL維持

Multi-Memoryはメモリ数を4倍に増やしたにも関わらず、PPLがほぼ同等（-0.1）を維持。

**解釈**:
- Attention-based selectionが適切に機能
- 追加パラメータなしでも学習が安定
- 情報の分散保存が性能を損なわない

### 2. Reversal Curse改善

Backward PPLが約16%改善（604.5 → 508.6）。

**仮説**:
- 複数メモリに情報が分散されることで、順方向・逆方向の情報が分離
- 特定メモリに特定パターンが蓄積されやすくなった可能性

### 3. メモリ効率

| 項目 | Single | Multi |
|------|--------|-------|
| メモリ | 133KB | 532KB |
| パラメータ | 70.4M | 70.4M |

メモリ使用量は4倍だが、パラメータ数は同一。
メモリはGPU上の固定バッファであり、推論時のKVキャッシュより遥かに小さい。

---

## 結論

1. **Multi-Memoryは性能を維持**: メモリを増やしても性能低下なし
2. **Reversal Curse改善**: 複数メモリで約16%改善
3. **学習安定**: 追加パラメータなしで学習が安定
4. **実装の妥当性確認**: Attention-based selectionが正常に動作

---

## 次のステップ

1. **Long Context評価**: 長文でのメモリ活用効果を検証
2. **メモリ数の最適化**: 8, 16メモリでの実験
3. **Hierarchical Memory**: 粗粒度→細粒度の階層検索を検証
