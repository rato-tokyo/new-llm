# New-LLM ä»Šå¾Œã®ãƒ†ã‚¹ãƒˆæ–¹é‡

**ä½œæˆæ—¥**: 2025-11-21

## ğŸ¯ ç¾çŠ¶ã¨ç›®æ¨™

### ç¾çŠ¶
- âœ… Phase 1: å›ºæœ‰ç‚¹å­¦ç¿’ã®å®Ÿè£…å®Œäº†
- âœ… Phase 2: ãƒˆãƒ¼ã‚¯ãƒ³äºˆæ¸¬è¨“ç·´ã®å®Ÿè£…å®Œäº†
- âœ… ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¯”è¼ƒ: Sequential/Layer-wise/Mixed [2,2]
- âœ… å˜ä¸€ã‚µãƒ³ãƒ—ãƒ«ï¼ˆ512ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰ã§ã®ãƒ†ã‚¹ãƒˆå®Œäº†

### ç›®æ¨™
1. **è¤‡æ•°ã‚µãƒ³ãƒ—ãƒ«ã§ã®è¨“ç·´**: ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã®æ¤œè¨¼
2. **Early Stoppingå®Ÿè£…**: éå­¦ç¿’é˜²æ­¢ã¨è¨“ç·´åŠ¹ç‡åŒ–
3. **æœ¬æ ¼çš„ãªå¯¾è©±ãƒ¢ãƒ‡ãƒ«è¨“ç·´**: UltraChatãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®å®Ÿç”¨ãƒ¬ãƒ™ãƒ«åˆ°é”

---

## ğŸ“‹ ææ¡ˆ: æ¬¡ã®ãƒ†ã‚¹ãƒˆã‚¹ãƒ†ãƒƒãƒ—

### Step 1: è¤‡æ•°ã‚µãƒ³ãƒ—ãƒ«çµ±åˆè¨“ç·´ï¼ˆå„ªå…ˆåº¦: é«˜ï¼‰

**ç›®çš„**: å˜ä¸€ã‚µãƒ³ãƒ—ãƒ«ã‹ã‚‰è¤‡æ•°ã‚µãƒ³ãƒ—ãƒ«ã¸ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°

**å®Ÿè£…å†…å®¹**:
```python
# tests/phase2_experiments/test_multi_sample_training.py

def load_multiple_samples(num_samples=10, max_length=512):
    """è¤‡æ•°ã®UltraChatã‚µãƒ³ãƒ—ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰"""
    dataset = load_dataset("HuggingFaceH4/ultrachat_200k", split="train_sft")

    all_token_ids = []
    for i in range(num_samples):
        sample = dataset[i]
        text = ""
        for msg in sample['messages']:
            text += msg['content'] + " "

        tokens = tokenizer.encode(text, max_length=max_length, truncation=True)
        all_token_ids.extend(tokens)

    return torch.tensor(all_token_ids)

def phase1_multi_sample_train(model, token_ids, batch_size=512):
    """Phase 1: ãƒãƒƒãƒå‡¦ç†ã§åŠ¹ç‡çš„ã«å›ºæœ‰ç‚¹å­¦ç¿’"""
    # ãƒˆãƒ¼ã‚¯ãƒ³åˆ—ã‚’ batch_size ã”ã¨ã«åˆ†å‰²
    # å„ãƒãƒƒãƒã§ä¸¦åˆ—ã«å›ºæœ‰ç‚¹å­¦ç¿’
    pass
```

**ãƒ†ã‚¹ãƒˆè¨ˆç”»**:
1. 10ã‚µãƒ³ãƒ—ãƒ«ï¼ˆç´„5,000ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰
2. 50ã‚µãƒ³ãƒ—ãƒ«ï¼ˆç´„25,000ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰
3. 100ã‚µãƒ³ãƒ—ãƒ«ï¼ˆç´„50,000ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰

**æœŸå¾…ã•ã‚Œã‚‹ç™ºè¦‹**:
- å›ºæœ‰ç‚¹ã®å†åˆ©ç”¨æ€§ï¼ˆç•°ãªã‚‹ã‚µãƒ³ãƒ—ãƒ«é–“ã§ä¼¼ãŸæ–‡è„ˆãƒ™ã‚¯ãƒˆãƒ«ï¼‰
- ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®ç·šå½¢ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ˆNew-LLMã®å„ªä½æ€§ï¼‰
- è¨“ç·´æ™‚é–“ã®æ¨ç§»

---

### Step 2: Early Stoppingå®Ÿè£…ï¼ˆå„ªå…ˆåº¦: é«˜ï¼‰

**ç›®çš„**: éå­¦ç¿’é˜²æ­¢ã¨è¨“ç·´åŠ¹ç‡åŒ–

**å®Ÿè£…å†…å®¹**:

#### 2.1 Phase 1ç”¨Early Stopping
```python
class Phase1EarlyStopping:
    """Phase 1å›ºæœ‰ç‚¹å­¦ç¿’ç”¨Early Stopping

    åœæ­¢æ¡ä»¶:
    - åæŸç‡ãŒé–¾å€¤ä»¥ä¸Šï¼ˆä¾‹: 95%ä»¥ä¸Šã®ãƒˆãƒ¼ã‚¯ãƒ³ãŒåæŸï¼‰
    - ã¾ãŸã¯æœ€å¤§ã‚¨ãƒãƒƒã‚¯æ•°åˆ°é”
    """
    def __init__(self, convergence_threshold=0.95, patience=3):
        self.convergence_threshold = convergence_threshold
        self.patience = patience
        self.best_convergence = 0
        self.epochs_no_improve = 0

    def __call__(self, convergence_rate):
        if convergence_rate >= self.convergence_threshold:
            return True  # ååˆ†åæŸã—ãŸã®ã§åœæ­¢

        if convergence_rate > self.best_convergence:
            self.best_convergence = convergence_rate
            self.epochs_no_improve = 0
        else:
            self.epochs_no_improve += 1

        return self.epochs_no_improve >= self.patience
```

#### 2.2 Phase 2ç”¨Early Stopping
```python
class Phase2EarlyStopping:
    """Phase 2ãƒˆãƒ¼ã‚¯ãƒ³äºˆæ¸¬ç”¨Early Stopping

    åœæ­¢æ¡ä»¶:
    - Validation LossãŒ patience ã‚¨ãƒãƒƒã‚¯æ”¹å–„ã—ãªã„
    - ã¾ãŸã¯ Validation PerplexityãŒé–¾å€¤ä»¥ä¸‹
    """
    def __init__(self, patience=5, min_delta=0.001, ppl_threshold=None):
        self.patience = patience
        self.min_delta = min_delta
        self.ppl_threshold = ppl_threshold
        self.best_loss = float('inf')
        self.epochs_no_improve = 0
        self.best_model_state = None

    def __call__(self, val_loss, val_ppl, model):
        # PPLé–¾å€¤ãƒã‚§ãƒƒã‚¯
        if self.ppl_threshold and val_ppl <= self.ppl_threshold:
            return True

        # Lossæ”¹å–„ãƒã‚§ãƒƒã‚¯
        if val_loss < self.best_loss - self.min_delta:
            self.best_loss = val_loss
            self.epochs_no_improve = 0
            self.best_model_state = model.state_dict().copy()
        else:
            self.epochs_no_improve += 1

        if self.epochs_no_improve >= self.patience:
            # ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã«å¾©å…ƒ
            model.load_state_dict(self.best_model_state)
            return True

        return False
```

**ä½¿ç”¨ä¾‹**:
```python
# Phase 1
early_stop = Phase1EarlyStopping(convergence_threshold=0.95, patience=3)
for epoch in range(max_epochs):
    convergence_rate = train_phase1_epoch(...)
    if early_stop(convergence_rate):
        print(f"Early stopping at epoch {epoch}: convergence = {convergence_rate:.1%}")
        break

# Phase 2
early_stop = Phase2EarlyStopping(patience=5, min_delta=0.001)
for epoch in range(max_epochs):
    train_loss, train_ppl = train_phase2_epoch(...)
    val_loss, val_ppl = evaluate_phase2(...)

    if early_stop(val_loss, val_ppl, model):
        print(f"Early stopping at epoch {epoch}: val_ppl = {val_ppl:.2f}")
        break
```

---

### Step 3: Train/Validationåˆ†å‰²ï¼ˆå„ªå…ˆåº¦: é«˜ï¼‰

**ç›®çš„**: éå­¦ç¿’ã®é©åˆ‡ãªæ¤œå‡º

**å®Ÿè£…å†…å®¹**:
```python
def split_samples(num_total_samples=100, train_ratio=0.8):
    """Train/Validationåˆ†å‰²"""
    dataset = load_dataset("HuggingFaceH4/ultrachat_200k", split="train_sft")

    train_size = int(num_total_samples * train_ratio)

    train_samples = dataset[:train_size]
    val_samples = dataset[train_size:num_total_samples]

    return train_samples, val_samples
```

**ãƒ†ã‚¹ãƒˆè¨ˆç”»**:
- 100ã‚µãƒ³ãƒ—ãƒ«: Train 80 / Val 20
- Validation Lossã§early stopping
- éå­¦ç¿’æ¤œå‡ºã®ç¢ºèª

---

### Step 4: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ ã®æ‹¡å¼µï¼ˆå„ªå…ˆåº¦: ä¸­ï¼‰

**ç›®çš„**: è¤‡æ•°ã‚µãƒ³ãƒ—ãƒ«ã®å›ºæœ‰ç‚¹ã‚’åŠ¹ç‡çš„ã«ç®¡ç†

**å®Ÿè£…å†…å®¹**:
```python
# cache/fixed_contexts/ ã®æ§‹é€ 
# - sample_0001_hash.pt
# - sample_0002_hash.pt
# - ...
# - index.json  # å…¨ã‚µãƒ³ãƒ—ãƒ«ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹

def save_fixed_contexts_batch(samples, fixed_contexts_list, architecture):
    """è¤‡æ•°ã‚µãƒ³ãƒ—ãƒ«ã®å›ºæœ‰ç‚¹ã‚’ãƒãƒƒãƒä¿å­˜"""
    index = {
        'architecture': architecture,
        'num_samples': len(samples),
        'samples': []
    }

    for i, (sample, contexts) in enumerate(zip(samples, fixed_contexts_list)):
        sample_hash = get_sample_hash(sample)
        cache_path = f"cache/fixed_contexts/{architecture}_sample_{i:04d}_{sample_hash}.pt"
        save_fixed_contexts(cache_path, sample, contexts, ...)

        index['samples'].append({
            'id': i,
            'hash': sample_hash,
            'path': cache_path
        })

    with open('cache/fixed_contexts/index.json', 'w') as f:
        json.dump(index, f)
```

---

### Step 5: ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å®Ÿé¨“ï¼ˆå„ªå…ˆåº¦: ä¸­ï¼‰

**ç›®çš„**: ã‚ˆã‚Šæ·±ã„ãƒ¢ãƒ‡ãƒ«ã§ã®æ€§èƒ½æ¤œè¨¼

**ãƒ†ã‚¹ãƒˆæ§‹æˆ**:
1. **Mixed [2,2]** - Baselineï¼ˆç¾åœ¨ã®ãƒ™ã‚¹ãƒˆï¼‰
2. **Mixed [2,2,2]** - 6å±¤ã€3ãƒ–ãƒ­ãƒƒã‚¯
3. **Mixed [2,2,2,2]** - 8å±¤ã€4ãƒ–ãƒ­ãƒƒã‚¯
4. **Mixed [3,3]** - 6å±¤ã€2ãƒ–ãƒ­ãƒƒã‚¯ï¼ˆTransformeræ¨™æº–ã«è¿‘ã„ï¼‰

**æœŸå¾…ã•ã‚Œã‚‹ç™ºè¦‹**:
- æœ€é©ãªå±¤æ•°ã¨ãƒ–ãƒ­ãƒƒã‚¯æ•°
- Perplexityã®æ”¹å–„åº¦åˆã„
- éå­¦ç¿’ã®å‚¾å‘

---

### Step 6: å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ï¼ˆå„ªå…ˆåº¦: ä½ï¼‰

**ç›®çš„**: è¨“ç·´ã®å®‰å®šåŒ–ã¨é«˜é€ŸåŒ–

**å®Ÿè£…å€™è£œ**:
```python
# Cosine Annealing with Warm Restarts
scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(
    optimizer,
    T_0=10,  # æœ€åˆã®ãƒªã‚¹ã‚¿ãƒ¼ãƒˆã¾ã§ã®ã‚¨ãƒãƒƒã‚¯æ•°
    T_mult=2  # ãƒªã‚¹ã‚¿ãƒ¼ãƒˆã”ã¨ã«T_0ã‚’2å€
)

# ReduceLROnPlateauï¼ˆValidation Lossãƒ™ãƒ¼ã‚¹ï¼‰
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
    optimizer,
    mode='min',
    factor=0.5,
    patience=3
)
```

---

## ğŸ¯ æ¨å¥¨å®Ÿè£…é †åº

### Phase A: åŸºç¤å›ºã‚ï¼ˆ1-2é€±é–“ï¼‰
1. âœ… **Step 2: Early Stoppingå®Ÿè£…**
   - Phase 1ã¨Phase 2ã®ä¸¡æ–¹
   - æ—¢å­˜ã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆã«çµ±åˆ

2. âœ… **Step 3: Train/Validationåˆ†å‰²**
   - 10ã‚µãƒ³ãƒ—ãƒ«ã§å‹•ä½œç¢ºèª
   - Early Stoppingã®åŠ¹æœæ¤œè¨¼

### Phase B: ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ˆ2-3é€±é–“ï¼‰
3. âœ… **Step 1: è¤‡æ•°ã‚µãƒ³ãƒ—ãƒ«çµ±åˆè¨“ç·´**
   - 10 â†’ 50 â†’ 100ã‚µãƒ³ãƒ—ãƒ«ã§æ®µéšçš„ã«ãƒ†ã‚¹ãƒˆ
   - ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã¨Perplexityã‚’è¨˜éŒ²

4. âœ… **Step 4: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ æ‹¡å¼µ**
   - è¤‡æ•°ã‚µãƒ³ãƒ—ãƒ«ã®å›ºæœ‰ç‚¹ç®¡ç†
   - å†å®Ÿé¨“æ™‚ã®é«˜é€ŸåŒ–

### Phase C: æœ€é©åŒ–ï¼ˆ3-4é€±é–“ï¼‰
5. âœ… **Step 5: ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°**
   - Mixed [2,2,2], [2,2,2,2], [3,3] ã‚’æ¯”è¼ƒ
   - 100ã‚µãƒ³ãƒ—ãƒ«ã§æ€§èƒ½è©•ä¾¡

6. â¸ï¸ **Step 6: å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°**ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
   - å¿…è¦ã«å¿œã˜ã¦å®Ÿè£…

---

## ğŸ“Š æˆåŠŸã®æŒ‡æ¨™

### Phase 1ï¼ˆå›ºæœ‰ç‚¹å­¦ç¿’ï¼‰
- âœ… åæŸç‡ > 95%
- âœ… å¹³å‡åå¾©æ•° < 20
- âœ… Phase 1 Loss: 0.1 - 0.5ï¼ˆå¥å…¨ãªç¯„å›²ï¼‰

### Phase 2ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³äºˆæ¸¬ï¼‰
- ğŸ¯ **Perplexity < 30**ï¼ˆ10ã‚µãƒ³ãƒ—ãƒ«ï¼‰
- ğŸ¯ **Perplexity < 20**ï¼ˆ100ã‚µãƒ³ãƒ—ãƒ«ï¼‰
- ğŸ¯ Train/Val Perplexityã®å·® < 5ï¼ˆéå­¦ç¿’ãªã—ï¼‰
- ğŸ¯ Accuracy > 30%

### æœ€çµ‚ç›®æ¨™
- ğŸ† **Perplexity < 15**ï¼ˆæœ¬æ ¼è¨“ç·´å¾Œï¼‰
- ğŸ† **å®Ÿç”¨çš„ãªå¯¾è©±ç”Ÿæˆèƒ½åŠ›**

---

## ğŸ’¡ è¿½åŠ ã®ææ¡ˆ

### ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ
- **Multiple Turns**: å¯¾è©±ã®è¤‡æ•°ã‚¿ãƒ¼ãƒ³ã‚’1ã‚µãƒ³ãƒ—ãƒ«ã¨ã—ã¦æ‰±ã†
- **Context Mixing**: ç•°ãªã‚‹å¯¾è©±ã‚’çµ„ã¿åˆã‚ã›ã¦å›ºæœ‰ç‚¹ã®æ±åŒ–æ€§ã‚’å‘ä¸Š

### ãƒ¢ãƒ‡ãƒ«æ”¹å–„
- **Residual Connection**: æ–‡è„ˆãƒ™ã‚¯ãƒˆãƒ«æ›´æ–°ã«Residualã‚’è¿½åŠ 
- **Layer Dropout**: ãƒ–ãƒ­ãƒƒã‚¯å˜ä½ã§ã®Dropout

### è©•ä¾¡æŒ‡æ¨™
- **BLEU Score**: ç”Ÿæˆå“è³ªã®å®šé‡è©•ä¾¡
- **Human Evaluation**: å¯¾è©±ã®è‡ªç„¶ã•ã®ä¸»è¦³è©•ä¾¡

---

## ğŸš€ æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³

### å³åº§ã«å®Ÿè£…ã™ã¹ãã‚‚ã®
1. **Early Stopping**ï¼ˆPhase 1 & Phase 2ï¼‰
2. **Train/Validationåˆ†å‰²**
3. **10ã‚µãƒ³ãƒ—ãƒ«ã§ã®å‹•ä½œç¢ºèª**

### æº–å‚™ãŒæ•´ã£ãŸã‚‰å®Ÿè£…
4. **è¤‡æ•°ã‚µãƒ³ãƒ—ãƒ«çµ±åˆè¨“ç·´**ï¼ˆ50-100ã‚µãƒ³ãƒ—ãƒ«ï¼‰
5. **ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ æ‹¡å¼µ**
6. **ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å®Ÿé¨“**

---

**æœ€å„ªå…ˆã‚¿ã‚¹ã‚¯**: Early Stopping + Train/Valåˆ†å‰²ã®å®Ÿè£…ã¨æ¤œè¨¼
