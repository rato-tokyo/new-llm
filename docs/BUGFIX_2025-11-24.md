# Critical Bug Fix Report - November 24, 2025

**Commit ID**: `79a188a372b34e67fd33362e83a6a3484282fd4a`
**Commit Message**: "Fix CVFP loss: remove F.normalize() and fix gradient flow"
**Date**: 2025-11-24
**Status**: ✅ Bugs Fixed, ⚠️ Performance Trade-off Identified

---

## Executive Summary

Fixed two critical bugs in CVFP (Context Vector Fixed-Point) learning that prevented convergence:
1. **F.normalize() in CVFP loss** - prevented value-level convergence
2. **Missing context.detach()** - caused gradient flow errors

**Result**: Convergence mechanism now works correctly. However, identified a fundamental trade-off between convergence rate and diversity (Effective Rank).

---

## Bug #1: F.normalize() in CVFP Loss

### Location
- **File**: [src/training/phase1_trainer.py](../src/training/phase1_trainer.py)
- **Lines**: 265-267

### Problem Description

CVFP loss calculation used `F.normalize()` on both contexts, enforcing only **cosine similarity** (directional match) instead of **value equality** required for fixed-point learning.

**Mathematical Issue**:
- Fixed-point: f(x) = x (requires exact values)
- Cosine similarity: Only requires same direction, allows different magnitudes
- Result: Context norms diverge while directions align → No convergence

### Symptoms

```
Iteration 1/10: 収束=0.0% | CVFP=0.001587 | Diversity=-0.008732
Iteration 2/10: 収束=0.0% | CVFP=0.002056 | Diversity=-0.008513
...
Iteration 10/10: 収束=0.0% | CVFP=0.002147 | Diversity=-0.008364

Final: 0/6400 tokens converged (0.0%)
MSE between iterations: ~32-33 (vs threshold 0.1 = 300x too large)
```

### Code Changes

```python
# BEFORE (BUGGY):
if self.current_iteration > 0 and self.previous_contexts is not None:
    previous_token_context = self.previous_contexts[token_idx:token_idx+1].detach()
    cvfp_loss = F.mse_loss(
        F.normalize(new_context, p=2, dim=1),      # ❌ Only direction
        F.normalize(previous_token_context, p=2, dim=1)
    )

# AFTER (FIXED):
# CRITICAL BUG FIX: 正規化なしのMSE（固定点への収束には実際の値の一致が必要）
# F.normalize()を使うと方向だけが一致すればよくなり、ノルムは変化し続ける
if self.current_iteration > 0 and self.previous_contexts is not None:
    previous_token_context = self.previous_contexts[token_idx:token_idx+1].detach()
    cvfp_loss = F.mse_loss(new_context, previous_token_context)  # ✅ Raw MSE
```

### Verification

Created [debug_convergence_with_training.py](../debug_convergence_with_training.py) to verify fix:

```bash
python3 debug_convergence_with_training.py
```

**Results** (dist_reg_weight=0.01):
- ✅ CVFP loss decreasing: 1.58 → 0.25 → 0.16 → 0.18
- ✅ Convergence: 96.0% (training), 100.0% (validation)
- ❌ Effective Rank collapsed: 6.9% (training), 1.1% (validation)

**Conclusion**: Bug fixed, convergence mechanism works.

---

## Bug #2: Missing context.detach() Between Tokens

### Location
- **File**: [src/training/phase1_trainer.py](../src/training/phase1_trainer.py)
- **Lines**: 228, 240

### Problem Description

Context passed between tokens without `detach()`, causing gradient graph reuse across the token sequence.

**PyTorch Issue**:
- Gradient graph accumulated across all tokens
- When optimizing token t, backward pass attempted to traverse graph from tokens 0..t-1
- Result: RuntimeError: "Trying to backward through the graph a second time"

### Symptoms

```
RuntimeError: Trying to backward through the graph a second time, but the
buffers have already been freed. Specify retain_graph=True when calling
.backward() or autograd.grad() the first time.
```

### Code Changes

```python
# BEFORE (BUGGY):
if is_training:
    context = self._train_one_token(
        token_embed.unsqueeze(0),
        context,  # ❌ Gradient graph carries over
        token_idx=t
    )
else:
    with torch.no_grad():
        context = self.model._update_context_one_step(
            token_embed.unsqueeze(0),
            context
        )

current_contexts[t] = context.squeeze(0)  # ❌ No detach

# AFTER (FIXED):
if is_training:
    # CRITICAL: トークン間でcontextをdetach（gradient flowを遮断）
    context = self._train_one_token(
        token_embed.unsqueeze(0),
        context.detach(),  # ✅ Break gradient flow between tokens
        token_idx=t
    )
else:
    # 評価モード: 最適化なし
    with torch.no_grad():
        context = self.model._update_context_one_step(
            token_embed.unsqueeze(0),
            context
        )

# 事前確保されたテンソルに直接代入（appendの代わり）
current_contexts[t] = context.squeeze(0).detach()  # ✅ Detach for convergence tracking
```

### Verification

- ✅ No more gradient flow errors
- ✅ Training completes successfully
- ✅ Convergence tracking works correctly

---

## Performance Analysis: Convergence vs Diversity Trade-off

### Experimental Results

**Test 1: dist_reg_weight=0.01** (99% CVFP, 1% Diversity):
```
Training:
- Convergence Rate: 96.0% (6144/6400) ✅
- Effective Rank: 6.9% (53/768) ❌
- CVFP Loss: 1.02 → 0.021 → 0.025

Validation:
- Convergence Rate: 100.0% (1280/1280) ✅
- Effective Rank: 1.1% (8/768) ❌
```

**Test 2: dist_reg_weight=0.5** (50% CVFP, 50% Diversity):
```
Training:
- Convergence Rate: 0.0% (0/6400) ❌
- Effective Rank: 88.7% (681/768) ✅
- CVFP Loss: Fluctuating

Validation:
- Convergence Rate: 0.0% (0/1280) ❌
- Effective Rank: 81.7% (627/768) ✅
```

### Analysis

**Fundamental Conflict**:
```python
total_loss = (1 - dist_reg_weight) * cvfp_loss + dist_reg_weight * diversity_loss
```

- **CVFP Loss**: `MSE(context_t, context_{t-1})` → Minimize change (promote convergence)
- **Diversity Loss**: `-||context - mean||` → Maximize deviation (promote diversity)
- **50/50 Balance**: Forces cancel each other → No convergence, but high diversity

**Trade-off Curve**:
```
dist_reg_weight=0.01:  96.0% convergence, 6.9% diversity
dist_reg_weight=0.5:   0.0% convergence, 88.7% diversity
```

**Target** (from CLAUDE.md):
- Convergence: >50%
- Effective Rank: ~89.4%

**Status**: ⚠️ No single weight achieves both targets simultaneously

---

## Recommended Solutions

### Option 1: Staged Training (推奨)

Train with decreasing diversity weight over iterations:

```python
# Early iterations: High diversity
iteration 1-3: dist_reg_weight = 0.8
# Mid iterations: Balanced
iteration 4-6: dist_reg_weight = 0.5
# Late iterations: Focus convergence
iteration 7-10: dist_reg_weight = 0.2
```

**Expected Result**: High diversity in early phase, convergence in late phase.

### Option 2: Adaptive Weighting

Dynamically adjust based on current state:

```python
if effective_rank < 0.8 * context_dim:
    # Need more diversity
    dist_reg_weight = 0.7
elif convergence_rate < 0.5:
    # Need more convergence
    dist_reg_weight = 0.2
else:
    # Balanced
    dist_reg_weight = 0.5
```

### Option 3: Relaxed Convergence Threshold

Increase threshold to accept more variation:

```python
phase1_convergence_threshold = 0.5  # Was 0.1
```

**Trade-off**: Faster convergence, but less stable fixed points.

### Option 4: Alternative Diversity Loss

Replace conflicting diversity loss with non-interfering version:

```python
# Current: Penalizes deviation from mean (conflicts with convergence)
diversity_loss = -torch.norm(new_context_flat - old_mean, p=2)

# Alternative: Maximize pairwise distances (orthogonal to convergence)
# (Requires batch processing - more complex implementation)
```

---

## Hyperparameter Optimization with Optuna

**Recommended Search Space**:
```python
dist_reg_weight: [0.1, 0.9]
phase1_learning_rate: [0.0005, 0.005]
phase1_convergence_threshold: [0.05, 0.5]
layernorm_mix: [0.5, 1.0]
```

**Objective Function**:
```python
# Multi-objective: Balance convergence and diversity
score = (
    0.5 * convergence_rate +
    0.5 * (effective_rank / context_dim)
)
```

**See**: [scripts/optimize_dist_reg_weight.py](../scripts/optimize_dist_reg_weight.py) (to be created)

---

## Testing Protocol

### Quick Test (Verify Implementation)
```bash
# 100 tokens, 5 iterations (~10 seconds)
python3 debug_convergence_with_training.py
```

### Standard Test (Full Validation)
```bash
# 6400 training + 1280 validation tokens (~3 minutes)
python3 test.py
```

**Expected Results** (if bugs still fixed):
- ✅ No gradient flow errors
- ✅ CVFP loss should decrease (if dist_reg_weight < 0.5)
- ⚠️ Trade-off between convergence and diversity persists

### Hyperparameter Search
```bash
# Optuna optimization (~hours)
python3 scripts/optimize_dist_reg_weight.py --n-trials 50
```

---

## Files Modified

### Core Implementation
1. **[src/training/phase1_trainer.py](../src/training/phase1_trainer.py)**
   - Line 267: Removed F.normalize() from CVFP loss
   - Line 228: Added context.detach() between tokens (training)
   - Line 240: Added context.detach() for convergence tracking

### Configuration
2. **[config.py](../config.py)**
   - Line 31: Changed dist_reg_weight from 0.01 to 0.5 (testing)

### Documentation
3. **[CLAUDE.md](../CLAUDE.md)**
   - Lines 424-506: Added bug fix history
   - Lines 509-567: Added architecture specification

### Debug Scripts
4. **[debug_convergence_with_training.py](../debug_convergence_with_training.py)** (NEW)
   - Verification script for bug fixes

---

## Reproduction Steps

### Reproduce Original Bugs

1. Checkout commit before fix:
   ```bash
   git checkout 79a188a^  # Parent of fix commit
   ```

2. Run test:
   ```bash
   python3 test.py
   ```

3. Observe:
   - 0% convergence rate
   - MSE ~32-33 (vs threshold 0.1)
   - Possible gradient flow errors

### Verify Bug Fixes

1. Checkout fix commit:
   ```bash
   git checkout 79a188a
   ```

2. Test with high CVFP weight:
   ```bash
   # Edit config.py: dist_reg_weight = 0.01
   python3 debug_convergence_with_training.py
   ```

3. Observe:
   - ✅ 96%+ convergence rate
   - ✅ CVFP loss decreasing
   - ❌ Effective Rank collapsed to 6.9%

4. Test with balanced weight:
   ```bash
   # Edit config.py: dist_reg_weight = 0.5
   python3 test.py
   ```

5. Observe:
   - ❌ 0% convergence rate (trade-off issue)
   - ✅ Effective Rank 88.7%

---

## Next Steps

1. **Hyperparameter Optimization**:
   - Create Optuna script to search optimal dist_reg_weight
   - Explore staged training approach

2. **Alternative Diversity Loss**:
   - Research non-conflicting diversity regularization methods
   - Implement and compare performance

3. **Convergence Threshold Analysis**:
   - Test with relaxed thresholds (0.2, 0.5, 1.0)
   - Measure impact on downstream tasks

4. **Staged Training Implementation**:
   - Implement decreasing dist_reg_weight schedule
   - Validate on full dataset

---

## References

- **Project Documentation**: [CLAUDE.md](../CLAUDE.md)
- **Architecture**: [src/models/new_llm_residual.py](../src/models/new_llm_residual.py)
- **Training Logic**: [src/training/phase1_trainer.py](../src/training/phase1_trainer.py)
- **Test Script**: [test.py](../test.py)
- **Debug Script**: [debug_convergence_with_training.py](../debug_convergence_with_training.py)

---

## Contact & Acknowledgments

**Bug Reporter**: User (observed 0% convergence with dist_reg_weight=0.01)
**Bug Fixer**: Claude AI (Anthropic)
**Verification**: Systematic testing with dist_reg_weight=[0.01, 0.5]

---

**Last Updated**: 2025-11-24
**Document Version**: 1.0
**Commit**: 79a188a372b34e67fd33362e83a6a3484282fd4a
