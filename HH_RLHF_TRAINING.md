# HH-RLHF Training Guide

Anthropic HH-RLHFï¼ˆHuman-Human RLHFï¼‰ã§ã®è¨“ç·´ã‚¬ã‚¤ãƒ‰

---

## ğŸ“Š HH-RLHFã¨ã¯

**é«˜å“è³ªãªäººé–“åŒå£«ã®å¯¾è©±ãƒ‡ãƒ¼ã‚¿**

| ç‰¹å¾´ | è©³ç´° |
|-----|------|
| **ãƒ‡ãƒ¼ã‚¿é‡** | 85,000ä»¶ï¼ˆHelpful: 43k + Harmless: 42kï¼‰ |
| **å½¢å¼** | è¤‡æ•°ã‚¿ãƒ¼ãƒ³å¯¾è©±ï¼ˆMulti-turnï¼‰ |
| **è¨€èª** | è‹±èªã®ã¿ |
| **å“è³ª** | äººé–“ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ä»˜ã |
| **ä½œæˆå…ƒ** | Anthropic |

---

## ğŸ¯ Dolly-15kã¨ã®æ¯”è¼ƒ

| é …ç›® | Dolly-15k | HH-RLHF |
|-----|-----------|---------|
| **ãƒ‡ãƒ¼ã‚¿é‡** | 15,000 | **85,000ï¼ˆ5.7å€ï¼‰** |
| **ä¼šè©±å½¢å¼** | å˜ç™ºQ&A | **è¤‡æ•°ã‚¿ãƒ¼ãƒ³** |
| **æ–‡è„ˆç†è§£** | ä¸è¦ | **å¿…é ˆ** |
| **å“è³ª** | é«˜ã„ | **éå¸¸ã«é«˜ã„** |
| **æœŸå¾…PPL** | 15.6ï¼ˆå®Ÿæ¸¬ï¼‰ | **17-20** |

**HH-RLHFã®æ–¹ãŒé›£ã—ã„**ãŒã€ã‚ˆã‚Šå®Ÿè·µçš„ãªå¯¾è©±èƒ½åŠ›ã‚’ç²å¾—ã§ãã¾ã™ã€‚

---

## ğŸš€ Google Colabã§ã®å®Ÿè¡Œæ–¹æ³•

### ã‚¹ãƒ†ãƒƒãƒ—1: ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

```python
# GPUç¢ºèª
!nvidia-smi

# ãƒªãƒã‚¸ãƒˆãƒªã‚¯ãƒ­ãƒ¼ãƒ³
%cd /content
!rm -rf new-llm
!git clone https://github.com/rato-tokyo/new-llm
%cd new-llm

# ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
!pip install -q datasets
```

### ã‚¹ãƒ†ãƒƒãƒ—2: HH-RLHFè¨“ç·´é–‹å§‹ï¼ˆLayer 1ï¼‰

```bash
# ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å®Ÿè¡Œ
!nohup python3 scripts/train_hh_rlhf.py --num_layers 1 > /content/hh_rlhf_layer1.log 2>&1 &

# ãƒ­ã‚°ç¢ºèª
!tail -20 /content/hh_rlhf_layer1.log

# GPUä½¿ç”¨çŠ¶æ³
!nvidia-smi
```

### ã‚¹ãƒ†ãƒƒãƒ—3: Layer 4ã§è¨“ç·´ï¼ˆæ¨å¥¨ï¼‰

```bash
# Layer 4ã¯WikiText-2ã§æœ€ã‚‚æ€§èƒ½ãŒè‰¯ã‹ã£ãŸ
!nohup python3 scripts/train_hh_rlhf.py --num_layers 4 > /content/hh_rlhf_layer4.log 2>&1 &

# ãƒ­ã‚°ç¢ºèª
!tail -20 /content/hh_rlhf_layer4.log
```

---

## ğŸ“ˆ æœŸå¾…ã•ã‚Œã‚‹çµæœ

### Layer 1

| æŒ‡æ¨™ | æœŸå¾…å€¤ |
|-----|--------|
| **Val PPL** | **18-20** |
| **Val Acc** | **43-45%** |
| **è¨“ç·´æ™‚é–“** | 20-30åˆ†ï¼ˆ100 epochsï¼‰ |

### Layer 4ï¼ˆæ¨å¥¨ï¼‰

| æŒ‡æ¨™ | æœŸå¾…å€¤ |
|-----|--------|
| **Val PPL** | **16-18** |
| **Val Acc** | **45-47%** |
| **è¨“ç·´æ™‚é–“** | 30-40åˆ†ï¼ˆ100 epochsï¼‰ |

**Dolly-15kã¨ã®æ¯”è¼ƒ**:
- Dolly Layer 1: PPL 15.6
- HH-RLHF Layer 1: PPL 18-20ï¼ˆ+2-4ãƒã‚¤ãƒ³ãƒˆé›£ã—ã„ï¼‰

---

## âš™ï¸ è¨­å®š

### è‡ªå‹•è¨­å®šï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰

| ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | å€¤ | ç†ç”± |
|-----------|-----|------|
| **batch_size** | 2048 | L4 GPUæœ€é©åŒ– |
| **learning_rate** | 0.0008 | Square Root Scaling |
| **max_seq_length** | 128 | è¤‡æ•°ã‚¿ãƒ¼ãƒ³å¯¾è©±ç”¨ |
| **epochs** | 100 | HH-RLHFç”¨ |
| **context_dim** | 256 | æ¨™æº– |

### ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º

```bash
# ã‚ˆã‚Šé•·ã„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹
python scripts/train_hh_rlhf.py --num_layers 4 --max_seq_length 256

# Harmless subsetï¼ˆå®‰å…¨æ€§é‡è¦–ï¼‰
python scripts/train_hh_rlhf.py --num_layers 4 --subset harmless
```

---

## ğŸ” é€²æ—ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°

### ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ­ã‚°è¡¨ç¤º

```bash
# æœ€æ–°20è¡Œ
!tail -20 /content/hh_rlhf_layer1.log

# ç¶™ç¶šçš„ãªç›£è¦–
!tail -f /content/hh_rlhf_layer1.log
```

### âœ“ãƒãƒ¼ã‚¯ã®æ„å‘³

```
Epoch 50/100
  Training... 100% | 0.2min | Loss: 2.85
  Val: Loss=2.82 PPL=16.8 Acc=45.1% âœ“
  [Checkpoint saved]
  â†‘
  âœ“ = ã“ã®EpochãŒãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«
```

### GPUä½¿ç”¨çŠ¶æ³

```bash
!nvidia-smi
```

---

## ğŸ“Š çµæœã®è§£é‡ˆ

### æˆåŠŸã®æŒ‡æ¨™

| PPLç¯„å›² | è©•ä¾¡ | æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ— |
|---------|------|-------------|
| **< 18** | ğŸ† **å„ªç§€** | Level 3ï¼ˆUltraChatï¼‰ã¸ |
| **18-21** | âœ… **æˆåŠŸ** | Layer 4ã§å†æŒ‘æˆ¦ or Level 3ã¸ |
| **> 21** | âš ï¸ **è¦æ”¹å–„** | è¨­å®šèª¿æ•´ or Layerå¢—ã‚„ã™ |

### Dollyã¨ã®æ¯”è¼ƒ

**æœŸå¾…ã•ã‚Œã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³**:
```
Dolly-15k (Layer 1): PPL 15.6 â† æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã§ç°¡å˜
HH-RLHF (Layer 1): PPL 18-20 â† è¤‡æ•°ã‚¿ãƒ¼ãƒ³ã§é›£ã—ã„
```

**ã“ã‚Œã¯æ­£å¸¸ã§ã™ï¼** HH-RLHFã®æ–¹ãŒé›£ã—ã„ã‚¿ã‚¹ã‚¯ã§ã™ã€‚

---

## ğŸ¯ ä½•ã‚’å­¦ç¿’ã™ã‚‹ã‹

### Dolly-15kã§å­¦ã‚“ã ã“ã¨

- å˜ç™ºQ&Aã®å¿œç­”
- åŸºæœ¬çš„ãªInstructionç†è§£
- æ˜ç¢ºãªãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜

### HH-RLHFã§å­¦ã¶ã“ã¨

- **è¤‡æ•°ã‚¿ãƒ¼ãƒ³å¯¾è©±**: å‰ã®ç™ºè¨€ã‚’è¸ã¾ãˆãŸå¿œç­”
- **æ–‡è„ˆä¿æŒ**: ä¼šè©±ã®æµã‚Œã‚’ç†è§£
- **é«˜å“è³ªå¿œç­”**: äººé–“ãŒå¥½ã‚€å¿œç­”ãƒ‘ã‚¿ãƒ¼ãƒ³
- **å®‰å…¨æ€§**: æœ‰å®³ãªå¿œç­”ã‚’é¿ã‘ã‚‹

---

## âš¡ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### GPU Out of Memory

```bash
# batch_sizeã‚’æ¸›ã‚‰ã™
# src/utils/config.pyã®NewLLML4Configã‚’ç·¨é›†
batch_size = 1024  # 2048 â†’ 1024
```

### è¨“ç·´ãŒé…ã„

```bash
# Layeræ•°ã‚’æ¸›ã‚‰ã™
python scripts/train_hh_rlhf.py --num_layers 1  # 4 â†’ 1
```

### PPLãŒä¸‹ãŒã‚‰ãªã„

1. **Epochã‚’å¢—ã‚„ã™**: 100 â†’ 150
2. **Learning rateã‚’ä¸‹ã’ã‚‹**: 0.0008 â†’ 0.0004
3. **Layer 4ã§è©¦ã™**: ã‚ˆã‚Šæ·±ã„ãƒ¢ãƒ‡ãƒ«

---

## ğŸ“ ä¿å­˜ã•ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ«

| ãƒ•ã‚¡ã‚¤ãƒ« | èª¬æ˜ |
|---------|------|
| `checkpoints/best_new_llm_hh_rlhf_layers1.pt` | ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ« |
| `new_llm_hh_rlhf_layers1_final.pt` | æœ€çµ‚Epoch |
| `/content/hh_rlhf_layer1.log` | è¨“ç·´ãƒ­ã‚° |

---

## ğŸš€ è¨“ç·´å®Œäº†å¾Œ

### çµæœã®ä¿å­˜

```bash
# Colabã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
from google.colab import files
files.download('/content/new-llm/checkpoints/best_new_llm_hh_rlhf_layers1.pt')
files.download('/content/hh_rlhf_layer1.log')
```

### æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

**æˆåŠŸã—ãŸã‚‰ï¼ˆPPL < 21ï¼‰**:

1. **Layer 4ã§è©¦ã™**: ã•ã‚‰ã«æ€§èƒ½å‘ä¸Š
2. **Level 3ã¸é€²ã‚€**: UltraChatï¼ˆå¤§è¦æ¨¡å¯¾è©±ï¼‰
3. **Context Expansion**: 256â†’512æ¬¡å…ƒ

---

## ğŸ“– é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

- `TRAINING_PROGRESSION.md` - ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆé›£æ˜“åº¦é †
- `experiments/dolly_dialog_experiment_2025-11-19.md` - Dollyçµæœ
- `ARCHITECTURE.md` - New-LLMã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

---

**æº–å‚™å®Œäº†ï¼** HH-RLHFè¨“ç·´ã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚

```bash
python scripts/train_hh_rlhf.py --num_layers 1
```
