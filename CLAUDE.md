# New-LLM Project Guidelines

## ğŸ¯ Context-KV Attention Architecture (2025-12-03)

**KVã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å¤§å¹…ã«å‰Šæ¸›ã™ã‚‹Context-KV Attentionæ–¹å¼ã‚’æ¡ç”¨ã€‚**

### ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¦‚è¦

```
Context-KV Attention:
  - ç­‰é–“éš”ï¼ˆintervalï¼‰ã§Contextã‚’å–å¾—
  - å¸¸ã«ã€Œç¾åœ¨ä½ç½®ã€ã‚’å«ã‚ãŸcontextã§Attention
  - ~99% KVã‚­ãƒ£ãƒƒã‚·ãƒ¥å‰Šæ¸›
```

### ğŸš¨ Context Intervalæ–¹å¼ï¼ˆé‡è¦ï¼‰

**Position i ã®äºˆæ¸¬ã«ã¯ã€ç¾åœ¨ä½ç½®ã‹ã‚‰ç­‰é–“éš”ã§éå»ã®contextã‚’å–å¾—ï¼š**

```
interval = 100 ã®å ´åˆ:

Position 350:
  KV Cache = [context[350], context[250], context[150], context[50]]
              â†‘ç¾åœ¨          â†‘100å‰        â†‘200å‰        â†‘300å‰
           = 4 context vectors

Position 150:
  KV Cache = [context[150], context[50]]
              â†‘ç¾åœ¨          â†‘100å‰
           = 2 context vectors

Position 50:
  KV Cache = [context[50]]
              â†‘ç¾åœ¨
           = 1 context vector
```

**ãƒã‚¤ãƒ³ãƒˆï¼š**
- å¸¸ã«ã€Œç¾åœ¨ä½ç½®ã®contextã€ã‚’å«ã‚ã‚‹ï¼ˆæœ€æ–°æƒ…å ±ï¼‰
- éå»ã®contextã¯ç­‰é–“éš”ï¼ˆintervalï¼‰ã§å–å¾—
- å¤ã„ã€Œãƒãƒ£ãƒ³ã‚¯å¢ƒç•Œã€æ–¹å¼ã§ã¯ãªãã€ã€Œç¾åœ¨ä½ç½®åŸºæº–ã€æ–¹å¼ã‚’ä½¿ç”¨

### ğŸš¨ max_contextsï¼ˆContext Windowï¼‰è¨­è¨ˆæ–¹é‡

**é€šå¸¸LLMã®ã€Œcontext windowã€ã¨åŒæ§˜ã«ã€ä½¿ç”¨ã™ã‚‹contextæ•°ã«ä¸Šé™ã‚’è¨­ã‘ã‚‹ã€‚**

```
é€šå¸¸LLM:
  - max_length ã§å…¥åŠ›ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·ã‚’åˆ¶é™
  - å¤ã„ãƒˆãƒ¼ã‚¯ãƒ³ã¯åˆ‡ã‚Šæ¨ã¦

Context-KVæ–¹å¼:
  - max_contexts ã§ä½¿ç”¨ã™ã‚‹contextæ•°ã‚’åˆ¶é™
  - å¤ã„contextã¯åˆ‡ã‚Šæ¨ã¦
```

**ä¾‹: interval=100, max_contexts=32 ã®å ´åˆ**
```
Position 3500:
  ç†è«–ä¸Š: [ctx[3500], ctx[3400], ..., ctx[0]] = 36å€‹
  å®Ÿéš›:   [ctx[3500], ctx[3400], ..., ctx[300]] = 32å€‹ï¼ˆæœ€æ–°ã®32å€‹ã®ã¿ï¼‰

  â†’ å¤ã™ãã‚‹contextï¼ˆposition 0ã€œ200ï¼‰ã¯åˆ‡ã‚Šæ¨ã¦
  â†’ ã“ã‚Œã«ã‚ˆã‚Š 32 Ã— 100 = 3200 ãƒˆãƒ¼ã‚¯ãƒ³åˆ†ã®å±¥æ­´ã‚’å‚ç…§
```

**OOMé˜²æ­¢ã®é‡è¦æ€§ï¼š**
- max_contextsã‚’è¨­å®šã—ãªã„ã¨ã€é•·ã„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã§Attentionè¨ˆç®—ãŒçˆ†ç™º
- é€šå¸¸LLMã¨åŒã˜è¨­è¨ˆæ€æƒ³ã‚’ç¶­æŒã™ã‚‹ã“ã¨ã§ã€ãƒ¡ãƒ¢ãƒªç®¡ç†ãŒå®¹æ˜“

### å®Ÿé¨“ã®å®Ÿè¡Œ

```bash
# Colabï¼ˆGPUï¼‰: 200ã‚µãƒ³ãƒ—ãƒ«ã€interval=100
python3 scripts/experiment_context_kv.py -s 200 --chunk-size 100

# ã‚«ã‚¹ã‚¿ãƒ contextæ¬¡å…ƒ
python3 scripts/experiment_context_kv.py -s 200 -c 256 --chunk-size 50
```

---

## ğŸ¯ OACDã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ  (Phase 1)

**Phase 1ã§ã¯OACD (Origin-Anchored Centroid Dispersion) ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’æ¡ç”¨ã€‚**

```python
def oacd_loss(contexts, centroid_weight=0.1):
    # Term 1: é‡å¿ƒã‹ã‚‰ã®åˆ†æ•£ã‚’æœ€å¤§åŒ–
    dispersion_loss = -||X - mean(X)|| / n

    # Term 2: é‡å¿ƒã‚’åŸç‚¹ã«å¼•ãå¯„ã›ã‚‹
    centroid_loss = ||mean(X)||Â²

    return dispersion_loss + centroid_weight * centroid_loss
```

---

## ğŸš¨ğŸš¨ Phase 1å­¦ç¿’ã§ã¯é †æ¬¡å‡¦ç†ç¦æ­¢ (CRITICAL) ğŸš¨ğŸš¨

**Phase 1å­¦ç¿’ã§ã¯ã€é †æ¬¡å‡¦ç†ã¯å³ç¦ã€‚å¿…ãšshifted_prev_contextæ–¹å¼ã§ä¸¦åˆ—å‡¦ç†ã™ã‚‹ã“ã¨ã€‚**

```python
# âŒ ç¦æ­¢: Phase 1å­¦ç¿’ã§é †æ¬¡å‡¦ç†ï¼ˆéå¸¸ã«é…ã„ï¼‰
for i in range(num_tokens):
    new_context = model.forward_context(prev_context, token_embed)
    prev_context = new_context

# âœ… æ¨å¥¨: shifted_prev_contextæ–¹å¼ï¼ˆä¸¦åˆ—å‡¦ç†ï¼‰
for iteration in range(max_iterations):
    shifted_prev_context = torch.cat([zero_init, previous_contexts[:-1]], dim=0)
    new_contexts = model.forward_context(shifted_prev_context, input_embeds)
    previous_contexts = new_contexts
```

---

## ğŸš¨ CPU/GPUãƒ†ãƒ³ã‚½ãƒ«ç®¡ç†

**å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§OOMã‚’é˜²ããŸã‚ã€ãƒ†ãƒ³ã‚½ãƒ«ã®ãƒ‡ãƒã‚¤ã‚¹ç®¡ç†ã‚’å¾¹åº•ã€‚**

```python
# âŒ ä¿®æ­£å‰
batch_contexts = previous_contexts[start_idx:end_idx].detach()

# âœ… ä¿®æ­£å¾Œ
batch_contexts = previous_contexts[start_idx:end_idx].detach().to(self.device)
```

---

## ğŸ”§ é–‹ç™ºç’°å¢ƒã®Lint/Type Check

```bash
# Lint (ruff)
python3 -m ruff check src/

# Type check (mypy)
python3 -m mypy src/ --ignore-missing-imports

# å®Ÿé¨“ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
python3 -m ruff check scripts/experiment_context_kv.py
python3 -m mypy scripts/experiment_context_kv.py --ignore-missing-imports
```

---

## ğŸš¨ CRITICAL: å¾Œæ–¹äº’æ›æ€§ã‚³ãƒ¼ãƒ‰ç¦æ­¢

**å¤ã„æ©Ÿèƒ½ã‚’æ®‹ã™ã“ã¨ã¯å³ç¦ã€‚å¾Œæ–¹äº’æ›æ€§ã‚’æ„è­˜ã—ãŸã‚³ãƒ¼ãƒ‰ã¯çµ¶å¯¾ã«æ›¸ã‹ãªã„ã€‚**

---

## ğŸ“ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ä»•æ§˜

### Core Components

**1. ContextKVAttentionLLM**
- è¤‡æ•°ã®ContextBlockï¼ˆå„1å±¤å›ºå®šï¼‰
- Context-KV Attention Layer
- Token Embedding: GPT-2 pretrained (768-dim, frozen)
- Weight Tying: token_output shares weights with token_embedding

**2. ContextBlock**
- 1å±¤å›ºå®šã€Phase 1ã§å­¦ç¿’ã€Phase 2ã§freeze
- OACDã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§å¤šæ§˜æ€§å­¦ç¿’

**3. Context-KV Attention**
- Contextã‚’K,Vã«å¤‰æ›
- ç­‰é–“éš”ï¼ˆintervalï¼‰ã§contextã‚’å–å¾—ã—ã¦Attention
- å¸¸ã«ç¾åœ¨ä½ç½®ã®contextã‚’å«ã‚ã‚‹

### Phase 1: å¤šæ§˜æ€§å­¦ç¿’ï¼ˆOACDï¼‰

- **å­¦ç¿’å¯¾è±¡**: ContextBlockã®ã¿
- **æå¤±**: OACDï¼ˆå¤šæ§˜æ€§æå¤±ï¼‰

### Phase 2: ãƒˆãƒ¼ã‚¯ãƒ³äºˆæ¸¬

- **ContextBlock**: frozenï¼ˆé‡ã¿å›ºå®šï¼‰
- **Context-KV Attention + FFN**: å­¦ç¿’
- **æå¤±**: CrossEntropyï¼ˆæ¬¡ãƒˆãƒ¼ã‚¯ãƒ³äºˆæ¸¬ï¼‰

---

## Code Quality Standards

### Principles

1. **No Hardcoding**: All hyperparameters in config.py
2. **Single Responsibility**: Each module has one clear purpose
3. **Type Hints Required**: é–¢æ•°ãƒ»ãƒ¡ã‚½ãƒƒãƒ‰ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«ã¯å‹æ³¨é‡ˆã‚’å¿…é ˆ

### ğŸš¨ğŸš¨ ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å³ç¦ - å…¨ã¦ã®å€¤ã¯configã‹ã‚‰èª­ã¿è¾¼ã‚€ (CRITICAL) ğŸš¨ğŸš¨

**å®Ÿé¨“ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã—ãªã„ã€‚å…¨ã¦ã®å€¤ã¯configã‹ã‚‰èª­ã¿è¾¼ã‚€ã€‚**

**ç¦æ­¢äº‹é …:**
1. é–¢æ•°ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå¼•æ•°ã«æ•°å€¤ã‚’ç›´æ¥æ›¸ã
2. argparseã®defaultã«æ•°å€¤ã‚’ç›´æ¥æ›¸ã
3. ã‚³ãƒ¼ãƒ‰å†…ã«ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼ã‚’æ›¸ã

```python
# âŒ ç¦æ­¢: é–¢æ•°ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå¼•æ•°ã«ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰
def train_phase2(..., num_epochs: int = 40, patience: int = 3):
    ...

# âŒ ç¦æ­¢: argparseã®defaultã«ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰
parser.add_argument('--samples', type=int, default=200)

# âœ… æ¨å¥¨: configã‹ã‚‰èª­ã¿è¾¼ã¿ï¼ˆé–¢æ•°ï¼‰
def train_phase2(..., num_epochs: int, patience: int):  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ãªã—
    ...

# âœ… æ¨å¥¨: configã‹ã‚‰èª­ã¿è¾¼ã¿ï¼ˆargparseï¼‰
default_config = Config()
parser.add_argument('--samples', type=int, default=default_config.num_samples)

# âœ… æ¨å¥¨: å‘¼ã³å‡ºã—æ™‚ã«configã‹ã‚‰å€¤ã‚’æ¸¡ã™
train_phase2(
    ...,
    num_epochs=base_config.phase2_epochs,
    patience=base_config.phase2_patience,
)
```

**Config ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ:**
- `config/base.py` - ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€ãƒ‡ãƒ¼ã‚¿è¨­å®šã€max_contextsã€context_interval
- `config/phase1.py` - Phase 1å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆmax_iterations, early_stoppingç­‰ï¼‰
- `config/phase2.py` - Phase 2å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆepochs, patience, lrç­‰ï¼‰
- `config/__init__.py` - çµ±åˆConfigã‚¯ãƒ©ã‚¹

**ã“ã®æ–¹é‡ã®ç†ç”±:**
- è¨­å®šå¤‰æ›´ã¯configãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã§å®Œçµ
- å®Ÿé¨“ã®å†ç¾æ€§ã‚’ä¿è¨¼
- ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ä¸€å…ƒç®¡ç†

---

## File Structure

**Main Scripts**:
- `scripts/experiment_context_kv.py` - Context-KV Attentionå®Ÿé¨“ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

**Core Implementation**:
- `src/models/context_kv.py` - ContextKVAttentionLLM
- `src/models/blocks.py` - ContextBlockï¼ˆ1å±¤å›ºå®šï¼‰
- `src/models/layers.py` - ContextLayer
- `src/trainers/phase1/memory.py` - Phase 1è¨“ç·´ãƒ­ã‚¸ãƒƒã‚¯
- `src/losses/diversity.py` - OACDã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 

---

Last Updated: 2025-12-03 (Context-KV Attentionæ–¹å¼ã«å®Œå…¨ç§»è¡Œ)
