# Claude Code Development Guidelines for New-LLM Project

## ğŸ¯ Colabå®Ÿé¨“ã®1è¡Œã‚³ãƒãƒ³ãƒ‰å®Œçµãƒãƒªã‚·ãƒ¼ - CRITICAL

**âš ï¸ çµ¶å¯¾ãƒ«ãƒ¼ãƒ«ï¼šã™ã¹ã¦ã®è¨“ç·´ã¯1è¡Œcurlã‚³ãƒãƒ³ãƒ‰ã§é–‹å§‹ã§ãã‚‹ã“ã¨**

### åŸºæœ¬åŸå‰‡

**ã™ã¹ã¦ã®è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€Google Colabã§1è¡Œã®curlã‚³ãƒãƒ³ãƒ‰ã‚’ã‚³ãƒ”ãƒšã™ã‚‹ã ã‘ã§å®Ÿé¨“ãŒé–‹å§‹ã§ãã‚‹ã“ã¨ã€‚**

```bash
# âœ… ã“ã‚ŒãŒæ­£ã—ã„å½¢
!curl -s https://raw.githubusercontent.com/rato-tokyo/new-llm/main/scripts/colab_train_<dataset>.sh | bash
```

**ã“ã®æ–¹é‡ã¯ä¾‹å¤–ãªãå¾¹åº•ã™ã‚‹ã€‚**

### å¿…é ˆå®Ÿè£…è¦ä»¶

æ–°ã—ã„è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è¿½åŠ ã™ã‚‹éš›ã¯ã€**å¿…ãšä»¥ä¸‹ã‚’å®Ÿè£…**ã™ã‚‹ã“ã¨ï¼š

1. âœ… `scripts/train_<dataset>.py` - Pythonè¨“ç·´ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
2. âœ… **`scripts/colab_train_<dataset>.sh`** - 1è¡Œå®Ÿè¡Œç”¨bashã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆ**æœ€é‡è¦ãƒ»å¿…é ˆ**ï¼‰
3. âœ… ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼ˆ1è¡Œã‚³ãƒãƒ³ãƒ‰ã‚’æœ€åˆã«è¨˜è¼‰ï¼‰

**`scripts/colab_train_<dataset>.sh`ãŒãªã„å®Ÿè£…ã¯ä¸å®Œå…¨ã¨ã¿ãªã™ã€‚**

### colab_train_*.sh ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å¿…é ˆå†…å®¹

```bash
#!/bin/bash
set -e

# 1. ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è§£æ
NUM_LAYERS=1
while [[ $# -gt 0 ]]; do
    case $1 in
        --num_layers) NUM_LAYERS="$2"; shift 2 ;;
        --max_samples) MAX_SAMPLES="$2"; shift 2 ;;
        *) echo "Unknown: $1"; exit 1 ;;
    esac
done

# 2. æœ€æ–°ç‰ˆå–å¾—
cd /content
rm -rf new-llm
git clone https://github.com/rato-tokyo/new-llm
cd new-llm

# 3. ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -q datasets tqdm

# 4. ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œ
nohup python scripts/train_<dataset>.py --num_layers $NUM_LAYERS > /content/log.txt 2>&1 &

# 5. åˆæœŸãƒ­ã‚°è¡¨ç¤º
sleep 10
tail -30 /content/log.txt

# 6. ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã‚³ãƒãƒ³ãƒ‰è¡¨ç¤º
echo "ğŸ“‹ Monitoring: !tail -20 /content/log.txt"
echo "ğŸ›‘ Stop: !pkill -9 -f train_<dataset>"
```

---

## ğŸ§ª ã‚³ãƒ¼ãƒ‰ä¿®æ­£æ™‚ã®å¿…é ˆãƒ†ã‚¹ãƒˆãƒãƒªã‚·ãƒ¼ - CRITICAL

**ã™ã¹ã¦ã®ã‚³ãƒ¼ãƒ‰ä¿®æ­£å¾Œã€å¿…ãšæ‰‹å…ƒã§ãƒ†ã‚¹ãƒˆã—ã¦ã‹ã‚‰ã‚³ãƒŸãƒƒãƒˆãƒ»ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹ã“ã¨**

### å¿…é ˆå®Ÿè¡Œæ‰‹é †

**ãƒ†ã‚¹ãƒˆã¯æœ€å°é™ã®ãƒ‡ãƒ¼ã‚¿ãƒ»epochãƒ»stepã§å®Ÿæ–½ã™ã‚‹**

```bash
# ã‚¹ãƒ†ãƒƒãƒ—1: æ§‹æ–‡ãƒã‚§ãƒƒã‚¯
python3 -m py_compile train.py

# ã‚¹ãƒ†ãƒƒãƒ—2: æœ€å°é™ã®ãƒ‡ãƒ¼ã‚¿ã§ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ†ã‚¹ãƒˆ
python3 train.py \
    --max-samples 100 \      # æœ€å°é™ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆ100ã‚µãƒ³ãƒ—ãƒ«ï¼‰
    --epochs 2 \             # æœ€å°é™ã®epochï¼ˆ2ã‚¨ãƒãƒƒã‚¯ï¼‰
    --batch-size 4 \
    --device cpu

# ã‚¹ãƒ†ãƒƒãƒ—3: å‹•ä½œç¢ºèª
# - ã‚¨ãƒãƒƒã‚¯ã”ã¨ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤ºã‚’ç¢ºèª
# - ã‚¨ãƒ©ãƒ¼ãªãå®Œäº†ã™ã‚‹ã“ã¨ã‚’ç¢ºèª
```

**ãƒ†ã‚¹ãƒˆæ™‚é–“ã®ç›®å®‰**:
- 100ã‚µãƒ³ãƒ—ãƒ«ã€2ã‚¨ãƒãƒƒã‚¯ â†’ **4-5åˆ†**

**é‰„å‰‡**: ãƒ†ã‚¹ãƒˆã™ã‚‹ã¨ãã¯**epoch=2ã€samples=100**ã§ååˆ†

### ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

ã‚³ãƒŸãƒƒãƒˆå‰ã«å¿…ãšç¢ºèªï¼š

- [ ] **æ§‹æ–‡ãƒã‚§ãƒƒã‚¯å®Œäº†** - `python3 -m py_compile`
- [ ] **ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆã§å‹•ä½œç¢ºèª**
- [ ] **ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å®Ÿéš›ã«ç¢ºèª**

---

## ğŸ”„ ã‚³ãƒ¼ãƒ‰å“è³ªãƒ»ä¿å®ˆæ€§ã®é‰„å‰‡ - CRITICAL

**ã‚³ãƒ¼ãƒ‰ã®é‡è¤‡ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ä¸æ•´åˆã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¸è¶³ã«ã‚ˆã‚‹ãƒŸã‚¹ã‚’é˜²ã**

### 1. ã‚³ãƒ¼ãƒ‰é‡è¤‡ã®å¾¹åº•æ’é™¤ - DRYåŸå‰‡

**âŒ çµ¶å¯¾ã«é¿ã‘ã‚‹ã¹ããƒ‘ã‚¿ãƒ¼ãƒ³**:

```python
# âŒ æ‚ªã„ä¾‹ - trainã¨evalã§åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ã‚’é‡è¤‡å®Ÿè£…
def train_epoch(...):
    token_loss = F.cross_entropy(...)
    recon_loss = F.mse_loss(...)
    # ... ç´„90è¡Œã®ãƒ­ã‚¸ãƒƒã‚¯

def evaluate(...):
    # â† ã¾ã£ãŸãåŒã˜ãƒ­ã‚¸ãƒƒã‚¯ã‚’ã‚³ãƒ”ãƒš
    token_loss = F.cross_entropy(...)
    recon_loss = F.mse_loss(...)
    # ... ç´„90è¡Œã®é‡è¤‡ã‚³ãƒ¼ãƒ‰
```

**âœ… æ­£ã—ã„ãƒ‘ã‚¿ãƒ¼ãƒ³ - å…±é€šé–¢æ•°ã§ä¸€å…ƒåŒ–**:

```python
# âœ… è‰¯ã„ä¾‹ - å…±é€šãƒ­ã‚¸ãƒƒã‚¯ã‚’1ç®‡æ‰€ã«é›†ç´„
def _compute_batch_metrics(model, input_ids, device, context_loss_weight):
    """å…±é€šã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—ï¼ˆtrainã¨valä¸¡æ–¹ã§ä½¿ç”¨ï¼‰"""
    token_loss = F.cross_entropy(...)
    recon_loss = F.mse_loss(...)

    return {
        'loss': loss,
        'token_loss': token_loss,
        'recon_loss': recon_loss,
    }

def train_epoch(...):
    metrics = _compute_batch_metrics(...)  # å…±é€šé–¢æ•°ã‚’ä½¿ç”¨
    optimizer.zero_grad()
    metrics['loss'].backward()
    optimizer.step()

def evaluate(...):
    metrics = _compute_batch_metrics(...)  # åŒã˜é–¢æ•°ã‚’ä½¿ç”¨
```

**ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ**:
- [ ] trainã¨evalã§åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ã‚’é‡è¤‡å®Ÿè£…ã—ã¦ã„ãªã„ã‹ï¼Ÿ
- [ ] å…±é€šå‡¦ç†ã‚’`_compute_*`ãªã©ã®é–¢æ•°ã«æŠ½å‡ºã—ãŸã‹ï¼Ÿ
- [ ] ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¿½åŠ æ™‚ã«1ç®‡æ‰€ä¿®æ­£ã§æ¸ˆã‚€ã‹ï¼Ÿ

---

### 2. ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒæœŸã®å¾¹åº• - CRITICAL

æ–°ã—ã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¿½åŠ ã™ã‚‹éš›ã¯ã€**å¿…ãšä»¥ä¸‹ã®å…¨ã¦ã‚’æ›´æ–°**ã™ã‚‹ã“ã¨ï¼š

1. **`train.py`** - `argparse`ã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å®šç¾©
2. **`scripts/colab_train_*.sh`** - ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è§£æã«è¿½åŠ 
3. **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ** - ä½¿ç”¨ä¾‹ã‚’è¨˜è¼‰

**ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ**:
- [ ] `train.py`ã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å®šç¾©ã‚’è¿½åŠ ã—ãŸã‹ï¼Ÿ
- [ ] **`scripts/colab_train_*.sh`ã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è§£æã‚’è¿½åŠ ã—ãŸã‹ï¼Ÿ** â† æœ€é‡è¦
- [ ] ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«ä½¿ç”¨ä¾‹ã‚’è¨˜è¼‰ã—ãŸã‹ï¼Ÿ

---

### 3. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ç©æ¥µæ´»ç”¨ - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

**âœ… æ­£ã—ã„ãƒ‘ã‚¿ãƒ¼ãƒ³ - ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ´»ç”¨**:

```python
def create_tokenizer(texts, vocab_size=10000, output_dir='./tokenizer'):
    """Create or load BPE tokenizer"""
    tokenizer_path = f"{output_dir}/tokenizer.json"

    # æ—¢å­˜ã®ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’ç¢ºèª
    if os.path.exists(tokenizer_path):
        print(f"Loading existing tokenizer from {tokenizer_path}...")
        return Tokenizer.from_file(tokenizer_path)  # 0.1ç§’ã§å®Œäº†

    # åˆå›ã®ã¿è¨“ç·´
    print(f"Training BPE tokenizer...")
    tokenizer.train_from_iterator(texts, trainer)
    tokenizer.save(tokenizer_path)
    return tokenizer
```

**ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã¹ãã‚‚ã®**:
1. **ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼** - `tokenizer.json`
2. **ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ** - HuggingFace DatasetsãŒè‡ªå‹•ã‚­ãƒ£ãƒƒã‚·ãƒ¥
3. **ãƒ¢ãƒ‡ãƒ«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ** - å®Ÿé¨“å†é–‹æ™‚ã«å†åˆ©ç”¨

---

### ã¾ã¨ã‚

**äºŒåº¦ã¨åŒã˜ãƒŸã‚¹ã‚’ã—ãªã„ãŸã‚ã®é‰„å‰‡**:

1. **DRYåŸå‰‡ã‚’å¾¹åº•** - ã‚³ãƒ¼ãƒ‰ã‚’é‡è¤‡ã•ã›ãªã„
2. **ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒæœŸã‚’å¾¹åº•** - `train.py`ã¨`colab_train_*.sh`ã®ä¸¡æ–¹ã‚’æ›´æ–°
3. **ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ´»ç”¨** - åŒã˜å‡¦ç†ã‚’ç¹°ã‚Šè¿”ã•ãªã„

---

## ğŸš€ GPUæœ€é©åŒ–è¨­å®šã®ç¢ºèª - CRITICAL

**ã‚¹ã‚¯ãƒªãƒ—ãƒˆä½œæˆãƒ»ä¿®æ­£æ™‚ã¯ã€å¿…ãšGPUç”¨ã®è¨­å®šã«ãªã£ã¦ã„ã‚‹ã‹ç¢ºèªã™ã‚‹ã“ã¨**

### GPUåˆ¥ã®æ¨å¥¨batch_size

| GPU | VRAM | æ¨å¥¨batch_size | å‚™è€ƒ |
|-----|------|---------------|------|
| **T4** | 16GB | 512 | Baseline model |
| **L4** | 24GB | **2048** | **4x T4** |
| **A100** | 40GB | **4096** | **8x T4** |

### Learning Rate Scaling Rule - CRITICAL

**batch_sizeã‚’å¤‰æ›´ã—ãŸã‚‰ã€learning_rateã‚‚é©åˆ‡ã«ã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹ã“ã¨**

**å¤§è¦æ¨¡batchï¼ˆ>= 256ï¼‰**: Square Root Scalingï¼ˆæ¨å¥¨ï¼‰
```
batch_sizeã‚’kå€ â†’ learning_rateã‚’âˆškå€
```

**æ­£ã—ã„è¨ˆç®—ï¼ˆCPU baselineåŸºæº–ï¼‰**:
```python
# CPU Baseline
batch_size = 32
learning_rate = 0.0001

# L4 GPUï¼ˆbatch 64å€ = 32â†’2048ï¼‰
batch_size = 2048
# Square Root Scaling: 0.0001 * âˆš64 = 0.0001 * 8 = 0.0008
learning_rate = 0.0008  # âˆš64 = 8å€

# A100 GPUï¼ˆbatch 128å€ = 32â†’4096ï¼‰
batch_size = 4096
# Square Root Scaling: 0.0001 * âˆš128 â‰ˆ 0.0001 * 11.3 = 0.0011
learning_rate = 0.0011  # âˆš128 â‰ˆ 11.3å€
```

**ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ**:
- [ ] batch >= 256: **Square Root Scalingï¼ˆâˆškå€ï¼‰** â† æ¨å¥¨
- [ ] æœ€åˆã®ã‚¨ãƒãƒƒã‚¯ã§PPLãŒæ€¥é€Ÿã«æ¸›å°‘ã—ã¦ã„ã‚‹ã‹ï¼Ÿ

---

### Model Size Scaling Rule - CRITICAL

**ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã‚’å¤§ããã—ãŸã‚‰ã€learning_rateã‚’å°ã•ãã™ã‚‹ã“ã¨**

**åŸºæœ¬åŸå‰‡**:
```
ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã„ â†’ learning_rateã‚’å°ã•ãã™ã‚‹
```

**æ¨å¥¨ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°**:
```python
# Baseline (2.74M params)
learning_rate = 0.0004

# Advanced (4.84M params, 1.77x larger)
learning_rate = 0.0002  # åŠåˆ†ã«æ¸›ã‚‰ã™ï¼ˆä¿å®ˆçš„ï¼‰
```

**ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ**:
- [ ] learning_rateã‚’å°ã•ãã—ãŸã‹ï¼Ÿ
- [ ] å¤§ããªãƒ¢ãƒ‡ãƒ«ãŒå°ã•ãªãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šæ€§èƒ½ãŒè‰¯ã„ã‹ï¼Ÿï¼ˆãã†ã§ãªã‘ã‚Œã°LRèª¿æ•´ä¸è¶³ï¼‰

---

### è¨­å®šã®ä¸€å…ƒç®¡ç†ãƒãƒªã‚·ãƒ¼ - CRITICAL

**ã™ã¹ã¦ã®è¨­å®šå€¤ã¯ `src/utils/config.py` ã§ä¸€å…ƒç®¡ç†ã™ã‚‹ã“ã¨**

```python
# âœ… è‰¯ã„ä¾‹ - config.pyã‹ã‚‰ç¶™æ‰¿
from src.utils.config import NewLLMGPUConfig

class MyConfig(NewLLMGPUConfig):
    # GPUæœ€é©åŒ–è¨­å®šã‚’è‡ªå‹•ç¶™æ‰¿
    num_epochs = 100
```

**åˆ©ç”¨å¯èƒ½ãªè¨­å®šã‚¯ãƒ©ã‚¹**:
- `NewLLMConfig` - CPUè¨“ç·´ï¼ˆãƒ¬ã‚¬ã‚·ãƒ¼ï¼‰
- `NewLLMGPUConfig` - T4 GPUè¨“ç·´
- **`NewLLML4Config`** - **L4 GPUè¨“ç·´ï¼ˆæ¨å¥¨ï¼‰**
- **`NewLLMA100Config`** - **A100 GPUè¨“ç·´**

---

## New-LLM Architecture Design Principles - CRITICAL

### ğŸ¯ å›ºå®šãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®åŸå‰‡ï¼ˆFixed Memory Usage Principleï¼‰

**New-LLMã®æ ¹æœ¬çš„è¨­è¨ˆç›®æ¨™**: ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·ã«é–¢ã‚ã‚‰ãš**ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒä¸€å®š**ã§ã‚ã‚‹ã“ã¨

ã“ã‚Œã¯New-LLMã®å­˜åœ¨æ„ç¾©ã§ã‚ã‚Šã€**çµ¶å¯¾ã«å®ˆã‚‹ã¹ãåŸå‰‡**ã§ã™ã€‚

### Transformerã¨ã®æ¯”è¼ƒ

| ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ | ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ | ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·ã®åˆ¶ç´„ |
|--------------|-------------|------------------|
| **Transformer** | O(nÂ²) | AttentionãŒé•·ã„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã§çˆ†ç™º |
| **New-LLM** | O(1) | å›ºå®šã‚µã‚¤ã‚ºæ–‡è„ˆãƒ™ã‚¯ãƒˆãƒ«ã§ä»»æ„é•·å¯¾å¿œå¯èƒ½ |

### å®Ÿè£…ã§çµ¶å¯¾ã«ç¦æ­¢ã™ã‚‹ã“ã¨ âŒ

**1. ä½ç½®åŸ‹ã‚è¾¼ã¿ï¼ˆPositional Embeddingsï¼‰ã®ä½¿ç”¨**

```python
# âŒ çµ¶å¯¾ç¦æ­¢ - max_seq_lengthã«åˆ¶é™ã•ã‚Œã‚‹
self.position_embedding = nn.Embedding(max_seq_length, embed_dim)

# å•é¡Œç‚¹:
# - å­¦ç¿’æ™‚ã®max_seq_lengthä»¥ä¸Šã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’å‡¦ç†ã§ããªã„
# - New-LLMã®è¨­è¨ˆæ€æƒ³ï¼ˆä»»æ„é•·å¯¾å¿œï¼‰ã«åã™ã‚‹
```

**ç†ç”±**:
- RNN/LSTMã¨åŒæ§˜ã€ä½ç½®æƒ…å ±ã¯**é€æ¬¡å‡¦ç†ã®é †åºã‹ã‚‰æš—é»™çš„ã«å­¦ç¿’**ã•ã‚Œã‚‹
- `context[t] = f(context[t-1], input[t])` ã®æ›´æ–°é †åºè‡ªä½“ãŒä½ç½®æƒ…å ±ã‚’å†…åŒ…
- æ˜ç¤ºçš„ãªä½ç½®åŸ‹ã‚è¾¼ã¿ã¯ä¸è¦ã‹ã¤æœ‰å®³

**2. ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·ã«ä¾å­˜ã™ã‚‹æ“ä½œ**

```python
# âŒ ç¦æ­¢ - å…¨éš ã‚ŒçŠ¶æ…‹ã‚’ä¿å­˜
hidden_states = []
for t in range(seq_len):
    hidden_states.append(hidden[t])  # ãƒ¡ãƒ¢ãƒªãŒç·šå½¢å¢—åŠ 

# âœ… æ­£ã—ã„ - å›ºå®šã‚µã‚¤ã‚ºã®æ–‡è„ˆãƒ™ã‚¯ãƒˆãƒ«ã®ã¿ä¿æŒ
context = torch.zeros(batch_size, context_dim)  # å›ºå®šã‚µã‚¤ã‚º
for t in range(seq_len):
    context = update(context, input[t])  # ä¸Šæ›¸ãæ›´æ–°
```

### é–‹ç™ºæ™‚ã®ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

New-LLMã®å®Ÿè£…ãƒ»ä¿®æ­£æ™‚ã¯å¿…ãšç¢ºèªï¼š

- [ ] `nn.Embedding(max_seq_length, ...)` ã®ã‚ˆã†ãªä½ç½®åŸ‹ã‚è¾¼ã¿ã‚’ä½¿ã£ã¦ã„ãªã„ã‹ï¼Ÿ
- [ ] `hidden_states.append(...)` ã®ã‚ˆã†ãªå…¨çŠ¶æ…‹ä¿å­˜ã‚’ã—ã¦ã„ãªã„ã‹ï¼Ÿ
- [ ] ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·ã«ä¾å­˜ã™ã‚‹æ“ä½œã‚’ã—ã¦ã„ãªã„ã‹ï¼Ÿ
- [ ] ä»»æ„é•·ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’å‡¦ç†ã§ãã‚‹è¨­è¨ˆã«ãªã£ã¦ã„ã‚‹ã‹ï¼Ÿ

### ã“ã®åŸå‰‡ã‚’å®ˆã‚‹ç†ç”±

1. **New-LLMã®å­˜åœ¨æ„ç¾©**: Transformerã® O(nÂ²) å•é¡Œã‚’ O(1) ã§è§£æ±º
2. **ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£**: é•·ã„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ï¼ˆå°èª¬ã€ã‚³ãƒ¼ãƒ‰å…¨ä½“ãªã©ï¼‰ã‚’å‡¦ç†å¯èƒ½
3. **ãƒªã‚½ãƒ¼ã‚¹åŠ¹ç‡**: ãƒ¡ãƒ¢ãƒªãŒé™ã‚‰ã‚ŒãŸç’°å¢ƒã§ã‚‚å‹•ä½œ

**é•åã—ãŸå ´åˆ**: New-LLMãŒãŸã ã®ã€Œé‡ã„Transformerã€ã«ãªã‚Šã€ç ”ç©¶çš„ä¾¡å€¤ã‚’å¤±ã†

---

## Code and File Cleanup Policy - CRITICAL

**å¤ã„ã‚³ãƒ¼ãƒ‰ãƒ»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ®‹ã™ã“ã¨ã¯å³ç¦ã§ã™**

### é‡è¦ï¼šç„¡åŠ¹åŒ–ã§ã¯ãªãå‰Šé™¤

**ä¸è¦ãªã‚³ãƒ¼ãƒ‰ã¯å¿…ãšå‰Šé™¤ã™ã‚‹ã“ã¨ã€‚ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã‚„ç„¡åŠ¹åŒ–ã§ã¯ä¸ååˆ†ã§ã™ã€‚**

```python
# âŒ ç¦æ­¢ - ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã§æ®‹ã™
# old_function()

# âœ… æ­£ã—ã„ - å®Œå…¨ã«å‰Šé™¤
# ï¼ˆä¸è¦ãªã‚³ãƒ¼ãƒ‰ã¯ä½•ã‚‚æ®‹ã•ãªã„ï¼‰
```

### å‰Šé™¤å¯¾è±¡

- âœ— ä½¿ã‚ã‚Œãªããªã£ãŸãƒ¡ã‚½ãƒƒãƒ‰ãƒ»é–¢æ•°
- âœ— ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰
- âœ— ãƒ‡ãƒãƒƒã‚°ç”¨ã®ä¸€æ™‚ã‚³ãƒ¼ãƒ‰
- âœ— å¤ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ãƒ•ã‚¡ã‚¤ãƒ«
- âœ— ä¸è¦ã«ãªã£ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ»å¼•æ•°

### ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

ã‚³ãƒŸãƒƒãƒˆå‰ã«å¿…ãšç¢ºèªï¼š

- [ ] ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã¯å‰Šé™¤ã—ãŸã‹ï¼Ÿ
- [ ] æœªä½¿ç”¨ã®ãƒ¡ã‚½ãƒƒãƒ‰ãƒ»é–¢æ•°ã¯å‰Šé™¤ã—ãŸã‹ï¼Ÿ
- [ ] å¤ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯å‰Šé™¤ã—ãŸã‹ï¼Ÿ
- [ ] æœªä½¿ç”¨ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ–‡ã¯å‰Šé™¤ã—ãŸã‹ï¼Ÿ

---

## ã‚³ãƒŸãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ - CRITICAL

**ã‚³ãƒŸãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯1è¡Œã§ç°¡æ½”ã«è¨˜è¿°ã™ã‚‹ã“ã¨**

```bash
# âœ… æ­£ã—ã„ - 1è¡Œã§ç°¡æ½”ã«
git commit -m "Add WikiText dataset support"
git commit -m "Fix perplexity calculation bug"
git commit -m "Remove obsolete parameters from train.py"
```

**åŸå‰‡**:
- 1è¡Œã§ä½•ã‚’ã—ãŸã‹æ˜ç¢ºã«è¨˜è¿°
- 50æ–‡å­—ä»¥å†…ã‚’ç›®å®‰
- è‹±èªã§è¨˜è¿°
- å‹•è©ã§å§‹ã‚ã‚‹ï¼ˆAdd, Fix, Remove, Update ãªã©ï¼‰

---

## ãƒ•ã‚¡ã‚¤ãƒ«å‘½åè¦å‰‡ - å®Œå…¨å›ºå®šæ–¹é‡

**ãƒ•ã‚¡ã‚¤ãƒ«åã¯å®Œå…¨ã«å›ºå®šã—ã€å¸¸ã«åŒã˜åå‰ã§ä¸Šæ›¸ãã™ã‚‹**

### åŸºæœ¬åŸå‰‡

- âœ… **å›ºå®šãƒ•ã‚¡ã‚¤ãƒ«å**: åŒã˜ç¨®é¡ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯å¸¸ã«åŒã˜åå‰ã‚’ä½¿ã†
- âŒ **ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ¥å°¾è¾ç¦æ­¢**: `_v1`, `_v2`, `_old`, `_new`, `_fixed` ãªã©ã¯ä½¿ã‚ãªã„
- âŒ **æ—¥ä»˜æ¥å°¾è¾ç¦æ­¢**: `_20250117`, `_latest` ãªã©ã¯ä½¿ã‚ãªã„
- âœ… **ä¸Šæ›¸ã**: æ–°ã—ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯å¸¸ã«åŒã˜ãƒ•ã‚¡ã‚¤ãƒ«åã§ä¸Šæ›¸ã

### ä¾‹å¤–

å›ºå®šãƒ•ã‚¡ã‚¤ãƒ«åã®ä¾‹å¤–ï¼ˆè¤‡æ•°ä¿æŒãŒè¨±ã•ã‚Œã‚‹å ´åˆï¼‰:

- âœ… ç•°ãªã‚‹å®Ÿé¨“ã®çµæœï¼ˆä¾‹: `experiment1_results.md`, `experiment2_results.md`ï¼‰
- âœ… ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼ˆä¾‹: `new_llm_curves.png`, `transformer_curves.png`ï¼‰
- âœ… ç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆä¾‹: `wikitext_results.md`, `bookcorpus_results.md`ï¼‰

**é‡è¦**: åŒã˜ç¨®é¡ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯å¿…ãšå›ºå®šåã§ä¸Šæ›¸ã

---

## ğŸ”¬ CVFPTå®Ÿé¨“ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ - CRITICAL

**CVFPT (Context Vector Fixed Point Training) å®Ÿé¨“æ™‚ã®æ³¨æ„äº‹é …**

### æ­£ã—ã„ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ä½¿ç”¨

**âœ… CVFPTå®Ÿé¨“ã«ã¯ `scripts/train_repetition.py` ã‚’ä½¿ç”¨**

```bash
# âœ… æ­£ã—ã„ - ãƒˆãƒ¼ã‚¯ãƒ³IDã‚’ç›´æ¥ä½¿ç”¨
python3 scripts/train_repetition.py \
    --max-stage 1 \
    --epochs-per-stage 10 \
    --repetitions 10 \
    --device cpu
```

**âŒ `train.py` ã¯ä½¿ã‚ãªã„** - WikiTextè¨“ç·´ç”¨ï¼ˆãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ãŒå¿…è¦ï¼‰

### é‡è¦ãªé•ã„

| ã‚¹ã‚¯ãƒªãƒ—ãƒˆ | ç”¨é€” | ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ |
|----------|------|------------------|
| `train.py` | WikiTextè¨“ç·´ | âœ… å¿…è¦ï¼ˆå…¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼‰ |
| **`scripts/train_repetition.py`** | **CVFPTå®Ÿé¨“** | **âŒ ä¸è¦ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³IDç›´æ¥ä½¿ç”¨ï¼‰** |

### ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ä¿è­·

**`./cache/` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¯çµ¶å¯¾ã«å‰Šé™¤ã—ãªã„**

- âœ… ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ¥ (`tokenizer.json`)
- âœ… HuggingFace Datasetsã‚­ãƒ£ãƒƒã‚·ãƒ¥
- âœ… ãƒ¢ãƒ‡ãƒ«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ

**ç†ç”±**: å†å®Ÿé¨“æ™‚ã«æ¯å›ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ã™ã‚‹ç„¡é§„ã‚’é˜²ãï¼ˆæ•°åˆ†â†’0.1ç§’ï¼‰

---

## âš ï¸ ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¢ãƒˆãƒ©ã‚¯ã‚¿ãƒ¼å•é¡Œ - CRITICAL

**é€€åŒ–è§£ï¼šã™ã¹ã¦ã®ãƒˆãƒ¼ã‚¯ãƒ³ãŒåŒä¸€ã®å›ºå®šç‚¹ã«åæŸã™ã‚‹å•é¡Œ**

### å•é¡Œã®ç—‡çŠ¶

- âœ— ç•°ãªã‚‹ãƒˆãƒ¼ã‚¯ãƒ³é–“ã®L2è·é›¢ãŒç•°å¸¸ã«å°ã•ã„ï¼ˆ0.000002ãªã©ï¼‰
- âœ— ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ãŒç•°å¸¸ã«é«˜ã„ï¼ˆ0.999ä»¥ä¸Šï¼‰
- âœ— åæŸã‚¹ãƒ†ãƒƒãƒ—ãŒç•°å¸¸ã«å°‘ãªã„ï¼ˆ1ã‚¹ãƒ†ãƒƒãƒ—ï¼‰
- âœ— ã™ã¹ã¦ã®ãƒˆãƒ¼ã‚¯ãƒ³ãŒåŒã˜æ–‡è„ˆãƒ™ã‚¯ãƒˆãƒ«ã«åæŸ

### æ ¹æœ¬åŸå› 

**Simple Overwrite Updater** ãŒå•é¡Œï¼š

```python
# âŒ Simple Updater - ä»¥å‰ã®æ–‡è„ˆã‚’ç„¡è¦–
context_new = tanh(W @ hidden)

# å•é¡Œç‚¹:
# 1. ä»¥å‰ã® context ã‚’å®Œå…¨ã«ç„¡è¦–
# 2. LayerNorm + Clipping ã¨çµ„ã¿åˆã‚ã•ã‚‹ã¨å…¨ãƒˆãƒ¼ã‚¯ãƒ³ãŒåŒä¸€ç‚¹ã«åæŸ
# 3. ãƒˆãƒ¼ã‚¯ãƒ³å›ºæœ‰ã®æƒ…å ±ãŒå¤±ã‚ã‚Œã‚‹
```

### è§£æ±ºç­–ï¼šGated Context Updaterï¼ˆå¿…é ˆï¼‰

**âœ… Gated Updater - LSTMå‹ã®æ›´æ–°ï¼ˆæ¨™æº–è¨­å®šï¼‰**

```python
# âœ… Gated Updater - ä»¥å‰ã®æ–‡è„ˆã‚’ä¿æŒ
context_delta = tanh(W_delta @ hidden)
forget_gate = sigmoid(W_forget @ hidden)
input_gate = sigmoid(W_input @ hidden)
context_new = forget_gate * context + input_gate * context_delta
```

**`src/utils/config.py` ã§ã®è¨­å®š**:

```python
context_update_strategy = "gated"  # DEFAULTï¼ˆå¤‰æ›´ç¦æ­¢ï¼‰
```

### è¨ºæ–­ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¢ãƒˆãƒ©ã‚¯ã‚¿ãƒ¼å•é¡Œã‚’æ¤œå‡ºï¼š

```bash
# ç•°ãªã‚‹ãƒˆãƒ¼ã‚¯ãƒ³é–“ã®è·é›¢ã‚’ãƒã‚§ãƒƒã‚¯
python3 scripts/check_global_attractor.py

# æœŸå¾…ã•ã‚Œã‚‹çµæœ:
# - Gated Updater: å¹³å‡L2è·é›¢ > 2.0ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³å›ºæœ‰ï¼‰
# - Simple Updater: å¹³å‡L2è·é›¢ < 0.001ï¼ˆã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¢ãƒˆãƒ©ã‚¯ã‚¿ãƒ¼ï¼‰
```

### ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

CVFPTå®Ÿé¨“å‰ã«å¿…ãšç¢ºèªï¼š

- [ ] `config.context_update_strategy = "gated"` ã‚’ç¢ºèª
- [ ] å¤ã„ simple updater ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’å‰Šé™¤
- [ ] å®Ÿé¨“çµæœãŒã€Œè‰¯ã™ãã‚‹ã€å ´åˆã¯é€€åŒ–è§£ã‚’ç–‘ã†ï¼ˆcosine > 0.999, L2 < 0.001ï¼‰

---

## ğŸ“Š CVFPTåˆ†æçµæœã®è§£é‡ˆ

**ç¹°ã‚Šè¿”ã—è¨“ç·´ï¼ˆFixed-Pointï¼‰vs å˜ä¸€ãƒ‘ã‚¹ï¼ˆSingle-Passï¼‰ã®é•ã„**

### å®Ÿé¨“çµæœï¼ˆGated Updaterä½¿ç”¨æ™‚ï¼‰

| ãƒ¡ãƒˆãƒªã‚¯ã‚¹ | å€¤ | è§£é‡ˆ |
|----------|---|------|
| **L2è·é›¢** | 3.69 | ãƒãƒ«ãƒ ï¼ˆ~16ï¼‰ã®23% |
| **ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦** | 0.973 | æ–¹å‘ãŒ97.3%ä¸€è‡´ |
| **è§’åº¦å·®** | 13.2Â° | æ–¹å‘ã®ãšã‚Œã¯å°ã•ã„ |
| **ãƒãƒ«ãƒ å·®** | 0.03% | ã»ã¼åŒã˜å¤§ãã• |

### åˆ†è§£åˆ†æ

**L2è·é›¢ã®å†…è¨³**:
- **æ–¹å‘æˆåˆ†**: 100%ï¼ˆä¸»è¦ãªé•ã„ï¼‰
- **å¤§ãã•æˆåˆ†**: 0%ï¼ˆã»ã¼åŒã˜ï¼‰

### å®Ÿç”¨çš„ãªæ„å‘³

1. **æ–¹å‘ã¯é«˜ç²¾åº¦** - å˜ä¸€ãƒ‘ã‚¹ã§ã‚‚97.3%æ–¹å‘ãŒä¸€è‡´
2. **å¤§ãã•ã‚‚åŒç­‰** - ãƒãƒ«ãƒ ã®å·®ã¯ã‚ãšã‹0.03%
3. **ä¸»ãªé•ã„** - æ¬¡å…ƒã”ã¨ã®å¾®èª¿æ•´ï¼ˆrefinementï¼‰

**çµè«–**: å˜ä¸€ãƒ‘ã‚¹ã§ã€Œæœ¬è³ªï¼ˆessenceï¼‰ã€ã‚’æ‰ãˆã€ç¹°ã‚Šè¿”ã—è¨“ç·´ã§ã€Œç²¾ç·»åŒ–ï¼ˆrefinementï¼‰ã€ãŒé€²ã‚€

---

## ã¾ã¨ã‚

**é‰„å‰‡**:
- âœ… æ–°ã—ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ä½œã£ãŸã‚‰ã€å¤ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯å³åº§ã«å‰Šé™¤
- âœ… ãƒ•ã‚¡ã‚¤ãƒ«åã¯å®Œå…¨ã«å›ºå®šã—ã€å¸¸ã«ä¸Šæ›¸ã
- âŒ ã€Œå¿µã®ãŸã‚ã€æ®‹ã™ã“ã¨ã¯ç¦æ­¢
- âœ… Gitã®å±¥æ­´ã«æ®‹ã£ã¦ã„ã‚‹ã®ã§ã€å¿…è¦ãªã‚‰å¾©å…ƒå¯èƒ½
- âœ… **CVFPTå®Ÿé¨“ã¯ `scripts/train_repetition.py` ã‚’ä½¿ç”¨**
- âœ… **Gated Context Updater ãŒæ¨™æº–ï¼ˆå¤‰æ›´ç¦æ­¢ï¼‰**
- âœ… **`./cache/` ã¯ä¿è­·ï¼ˆå‰Šé™¤ç¦æ­¢ï¼‰**

**å¾¹åº•çš„ãªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã¨ãƒ•ã‚¡ã‚¤ãƒ«åã®çµ±ä¸€ãŒãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å“è³ªã‚’ä¿ã¡ã¾ã™ã€‚**
