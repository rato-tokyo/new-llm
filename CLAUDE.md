# New-LLM Project Guidelines

---

## ğŸ¯ MLA-Pythia Architecture (2025-12-05)

**Pythia-70Mã‚’ãƒ™ãƒ¼ã‚¹ã«MLAï¼ˆMulti-head Latent Attentionï¼‰ã§KVã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å¤§å¹…å‰Šæ¸›ã€‚**
**ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¯ALiBiï¼ˆçµ±ä¸€ã‚¹ãƒ­ãƒ¼ãƒ—ï¼‰ã‚’æ¡ç”¨ã€‚**

### ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```
MLA-Pythia (ALiBi):
Token Embedding (512-dim)
       â†“
MLALayer Ã— 6
  â”œâ”€ MLA Attention (ALiBi)
  â”‚    c_kv: 128-dim (KVå…±é€šåœ§ç¸®)
  â”‚    å¸åãƒ¢ãƒ¼ãƒ‰
  â””â”€ MLP
       â†“
Output Head (512 â†’ vocab)

KV Cache: c_kv(128) = 128
å‰Šæ¸›ç‡: 87.5%
```

### è¨­å®šå€¤

| é …ç›® | MLA-Pythia |
|------|------------|
| hidden_size | 512 |
| kv_dim | 128 |
| Layers | 6 |
| Attention Heads | 8 |
| intermediate_size | 2048 |
| Position Encoding | ALiBi (çµ±ä¸€ã‚¹ãƒ­ãƒ¼ãƒ—) |
| KV Cacheå‰Šæ¸› | 87.5% |

### å®Ÿé¨“ã®å®Ÿè¡Œ

```bash
# MLAå®Ÿé¨“
python3 scripts/experiment_mla.py --samples 10000 --epochs 30

# kv_dimå¤‰æ›´
python3 scripts/experiment_mla.py --kv-dim 256  # 75%å‰Šæ¸›
python3 scripts/experiment_mla.py --kv-dim 64   # 93.75%å‰Šæ¸›
```

---

## ğŸ¯ ALiBi (Attention with Linear Biases)

### ä»•æ§˜

```
score = Q @ K^T - m * distance_matrix

distance_matrix[i][j] = |i - j|  # ä½ç½®é–“ã®è·é›¢
m = slope (å…¨ãƒ˜ãƒƒãƒ‰çµ±ä¸€ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.0625)
```

### ä½¿ç”¨æ–¹æ³•

```python
from src.models import ALiBiPositionEncoding

pos_enc = ALiBiPositionEncoding(slope=0.0625)
attn_scores = pos_enc.apply_to_scores(attn_scores, seq_len)
```

---

## ğŸ“š DeepSeek MLA (Multi-head Latent Attention)

### å¸åãƒ¢ãƒ¼ãƒ‰ï¼ˆAbsorbed Projectionï¼‰

```
MLAï¼ˆå¸åãƒ¢ãƒ¼ãƒ‰ - å¾©å…ƒä¸è¦ï¼‰:
  c_kv = X @ W_DKV     # KVå…±é€šåœ§ç¸®: (seq, 512) â†’ (seq, 128)
  scores = Q @ W_UK^T @ c_kv^T

  # KVã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯ c_kv ã®ã¿ä¿å­˜ï¼ˆ87.5%å‰Šæ¸›ï¼‰
```

### å‚è€ƒãƒªãƒ³ã‚¯

- [DeepSeek-V2 Paper](https://arxiv.org/abs/2405.04434)
- [MLA Explanation (HuggingFace)](https://huggingface.co/blog/NormalUhr/mla-explanation)

---

## ğŸ“Š Reversal Curse è©•ä¾¡

### æ¦‚è¦

Reversal Curseã¯ã€ŒA is Bã€ã‚’å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ãŒã€ŒB is Aã€ã‚‚æ¨è«–ã§ãã‚‹ã‹ã‚’æ¸¬å®šã™ã‚‹æŒ‡æ¨™ã€‚

### æŒ‡æ¨™

| æŒ‡æ¨™ | å®šç¾© | è§£é‡ˆ |
|------|------|------|
| Forward PPL | é †æ–¹å‘æ–‡ã®PPL | è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«å«ã¾ã‚Œã‚‹ãŸã‚ä½ã„ |
| Backward PPL | é€†æ–¹å‘æ–‡ã®PPL | è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«å«ã¾ã‚Œãªã„ãŸã‚é«˜ã„ |
| Reversal Ratio | Forward / Backward | 1.0ã«è¿‘ã„ã»ã©è‰¯ã„ |
| Reversal Gap | Backward - Forward | 0ã«è¿‘ã„ã»ã©è‰¯ã„ |

### å®Ÿè£…

```python
from src.utils.evaluation import evaluate_reversal_curse
from src.data.reversal_pairs import get_reversal_pairs

tokenizer = get_tokenizer(config.tokenizer_name)
reversal_pairs = get_reversal_pairs()
reversal_result = evaluate_reversal_curse(model, tokenizer, reversal_pairs, device)
```

---

## ğŸš¨ CRITICAL: ã‚³ãƒ¼ãƒ‰å“è³ª

### å¾Œæ–¹äº’æ›æ€§ã‚³ãƒ¼ãƒ‰ç¦æ­¢

**å¤ã„æ©Ÿèƒ½ã‚’æ®‹ã™ã“ã¨ã¯å³ç¦ã€‚å¾Œæ–¹äº’æ›æ€§ã‚’æ„è­˜ã—ãŸã‚³ãƒ¼ãƒ‰ã¯çµ¶å¯¾ã«æ›¸ã‹ãªã„ã€‚**

### ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å³ç¦

**å…¨ã¦ã®å€¤ã¯configã‹ã‚‰èª­ã¿è¾¼ã‚€ã€‚**

### ãƒ©ãƒ³ãƒ€ãƒ ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨ç¦æ­¢

**å®Ÿé¨“ã§ãƒ©ãƒ³ãƒ€ãƒ ãƒ‡ãƒ¼ã‚¿ï¼ˆtorch.randintç­‰ï¼‰ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã¯çµ¶å¯¾ã«ç¦æ­¢ã€‚**
å¿…ãšå®Ÿãƒ‡ãƒ¼ã‚¿ï¼ˆPileï¼‰ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã€‚

### Reversal Curseè©•ä¾¡å¿…é ˆ

**ã™ã¹ã¦ã®å®Ÿé¨“ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ã€Reversal Curseè©•ä¾¡ã‚’å¿…ãšå®Ÿè¡Œã™ã‚‹ã“ã¨ã€‚**

---

## âš ï¸ éå»ã®ãƒã‚°ã¨æ•™è¨“

### 1. ALiBiå› æœãƒã‚¹ã‚¯ã®è¡Œåˆ—æ–¹å‘ãƒã‚°

```python
# âŒ ãƒã‚°: relative_pos[i][j] = j - i ï¼ˆæœªæ¥ãŒè¦‹ãˆã¦ã„ãŸï¼‰
relative_pos = positions.unsqueeze(0) - positions.unsqueeze(1)

# âœ… ä¿®æ­£: relative_pos[i][j] = i - j ï¼ˆæ­£ã—ã„å› æœãƒã‚¹ã‚¯ï¼‰
relative_pos = positions.unsqueeze(1) - positions.unsqueeze(0)
```

### 2. PPLç•°å¸¸å€¤ã®è¨ºæ–­åŸºæº–

| PPL | çŠ¶æ…‹ | å¯¾å‡¦ |
|-----|------|------|
| < 5 | **ç•°å¸¸** - ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯/å› æœãƒã‚¹ã‚¯ãƒã‚° | ã‚³ãƒ¼ãƒ‰ç‚¹æ¤œå¿…é ˆ |
| 5-30 | **ç–‘ã‚ã—ã„** - éå­¦ç¿’ã®å¯èƒ½æ€§ | ãƒ‡ãƒ¼ã‚¿é‡ãƒ»åˆ†å‰²ã‚’ç¢ºèª |
| 30-100 | æ­£å¸¸ï¼ˆå°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ï¼‰ | - |
| 100-500 | æ­£å¸¸ï¼ˆã‚¹ã‚¯ãƒ©ãƒƒãƒè¨“ç·´ï¼‰ | - |
| > 1000 | å­¦ç¿’ä¸è¶³ | epochå¢—åŠ /lrèª¿æ•´ |

---

## ğŸ“ File Structure

```
new-llm/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ pythia.py                   # PythiaConfig
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ experiment_mla.py           # MLAå®Ÿé¨“
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ reversal_pairs.py       # Reversal Curseè©•ä¾¡ãƒ‡ãƒ¼ã‚¿
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ mla_pythia.py           # MLAPythiaModel (ALiBi)
â”‚   â”‚   â”œâ”€â”€ mla.py                  # MLAAttention, MLALayer
â”‚   â”‚   â”œâ”€â”€ alibi.py                # ALiBiå®Ÿè£…
â”‚   â”‚   â””â”€â”€ position_encoding.py    # ALiBiPositionEncoding
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ training.py             # å…±é€šå­¦ç¿’ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
â”‚       â”œâ”€â”€ evaluation.py           # è©•ä¾¡é–¢æ•°
â”‚       â”œâ”€â”€ device.py               # ãƒ‡ãƒã‚¤ã‚¹ç®¡ç†
â”‚       â”œâ”€â”€ data_pythia.py          # Pileãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
â”‚       â””â”€â”€ seed.py                 # ã‚·ãƒ¼ãƒ‰è¨­å®š
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ experiments/                # å®Ÿé¨“çµæœ
â””â”€â”€ CLAUDE.md
```

---

## ğŸ“œ å¤‰æ›´å±¥æ­´

| æ—¥ä»˜ | å†…å®¹ |
|------|------|
| 2025-12-05 | **RoPEé–¢é€£ã‚³ãƒ¼ãƒ‰å‰Šé™¤**: ALiBiä¸€æœ¬åŒ–ã€ã‚·ãƒ³ãƒ—ãƒ«åŒ– |
| 2025-12-05 | **MLA-Pythiaå®Ÿè£…**: KVã‚­ãƒ£ãƒƒã‚·ãƒ¥87.5%å‰Šæ¸› |
| 2025-12-05 | **ALiBiæ¡ç”¨**: çµ±ä¸€ã‚¹ãƒ­ãƒ¼ãƒ—æ–¹å¼ |
| 2025-12-05 | **Reversal Curseè©•ä¾¡è¿½åŠ **: é †æ–¹å‘/é€†æ–¹å‘PPLæ¯”è¼ƒ |

---

Last Updated: 2025-12-05
