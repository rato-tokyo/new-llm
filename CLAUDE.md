# New-LLM Project Guidelines

## ğŸ“Š MANDATORY: æ•°å€¤å ±å‘Šãƒ«ãƒ¼ãƒ« - å…·ä½“çš„ãªæ•°å€¤ã§ã®å ±å‘Šç¾©å‹™

### çµ¶å¯¾éµå®ˆ: ã™ã¹ã¦ã®å®Ÿé¨“çµæœã¯å…·ä½“çš„ãªæ•°å€¤ã§å ±å‘Šã™ã‚‹

**ç¦æ­¢äº‹é …**:
- âŒ "GOOD", "EXCELLENT", "MODERATE" ãªã©ã®æŠ½è±¡çš„è¡¨ç¾ã§ã®å ±å‘Š
- âŒ "æ”¹å–„ã—ãŸ", "è‰¯å¥½", "é©åˆ‡" ãªã©ã®å®šæ€§çš„è©•ä¾¡ã®ã¿ã®å ±å‘Š
- âŒ æ•°å€¤ã‚’ä¼´ã‚ãªã„åˆ¤å®šçµæœã®å ±å‘Š

**å¿…é ˆå ±å‘Šé …ç›®**:
- âœ… **åæŸç‡ï¼ˆè¨“ç·´ãƒ»æ¤œè¨¼ä¸¡æ–¹ï¼‰**: **å…·ä½“çš„ãªãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ã¨åæŸãƒˆãƒ¼ã‚¯ãƒ³æ•°** (ä¾‹: è¨“ç·´ 0.0% (0/6400), æ¤œè¨¼ 0.0% (0/1280))
- âœ… Effective Rank: **å®Ÿæ•°å€¤/ç·æ¬¡å…ƒæ•°ã¨ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸** (ä¾‹: 627.29/768 = 81.7%)
- âœ… CVFPãƒ­ã‚¹: **å®Ÿæ•°å€¤** (ä¾‹: 0.001873)
- âœ… åæŸå·®åˆ†: **å®Ÿæ•°å€¤** (ä¾‹: final_diff = 0.000745)
- âœ… ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°: **å®Ÿæ•°** (ä¾‹: 10/10ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†)

**âš ï¸ åæŸç‡ã®å ±å‘Šã¯çµ¶å¯¾ã«çœç•¥ã—ã¦ã¯ã„ã‘ãªã„**:
- è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã®ä¸¡æ–¹ã®åæŸç‡ã‚’å¿…ãšå ±å‘Š
- åæŸç‡ = åæŸã—ãŸãƒˆãƒ¼ã‚¯ãƒ³æ•° / ç·ãƒˆãƒ¼ã‚¯ãƒ³æ•°
- 0.0%ã¯ã€ŒåæŸå¤±æ•—ã€ã§ã¯ãªãã€Œå…¨ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œèµ°ã€ã‚’æ„å‘³ã™ã‚‹

**å ±å‘Šãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä¾‹**:
```
è¨“ç·´çµæœ:
- åæŸç‡: 0.0% (0/6400ãƒˆãƒ¼ã‚¯ãƒ³) - 10ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œèµ°
- Effective Rank: 689.26/768 (89.7%)
- CVFPãƒ­ã‚¹: 0.001732

æ¤œè¨¼çµæœ:
- åæŸç‡: 0.0% (0/1280ãƒˆãƒ¼ã‚¯ãƒ³) - 10ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œèµ°
- Effective Rank: 627.29/768 (81.7%)

CVFPåæŸãƒã‚§ãƒƒã‚¯:
- final_diff = 0.000745 (é–¾å€¤ < 0.001ã‚¯ãƒªã‚¢)
```

---

## ğŸš¨ğŸš¨ğŸš¨ CRITICAL BUG FIX - CONTEXT CARRYOVER (2025-11-24) ğŸš¨ğŸš¨ğŸš¨

### è‡´å‘½çš„ãƒã‚°ä¿®æ­£: ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–“ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¼•ãç¶™ãï¼ˆçµ¶å¯¾ã«å¿˜ã‚Œã¦ã¯ã„ã‘ãªã„ï¼‰

**è‡´å‘½çš„ãªå•é¡Œ**:
- è¨“ç·´ãƒ»æ¤œè¨¼ã®ä¸¡æ–¹ã§å„ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã”ã¨ã«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒã‚¼ãƒ­ãƒªã‚»ãƒƒãƒˆã•ã‚Œã¦ã„ãŸ
- **ã“ã‚Œã¯CVFPå­¦ç¿’ã®æ ¹æœ¬ã‚’ç ´å£Šã™ã‚‹è‡´å‘½çš„ãƒã‚°**
- å›ºå®šç‚¹å­¦ç¿’ãŒå…¨ãæ©Ÿèƒ½ã—ã¦ã„ãªã‹ã£ãŸ

**ä¿®æ­£å†…å®¹**:
```python
# âŒâŒâŒ çµ¶å¯¾ã«ã‚„ã£ã¦ã¯ã„ã‘ãªã„é–“é•ã£ãŸå®Ÿè£…ï¼ˆå‰Šé™¤æ¸ˆã¿ï¼‰
# æ¯ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒªã‚»ãƒƒãƒˆ = CVFPå­¦ç¿’ã®ç ´å£Š
context = torch.zeros(1, self.model.context_dim, device=device)  # è‡´å‘½çš„ãƒã‚°

# âœ…âœ…âœ… å¿…é ˆã®æ­£ã—ã„å®Ÿè£…ï¼ˆä¿®æ­£æ¸ˆã¿ï¼‰
# ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–“ã§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å¿…ãšå¼•ãç¶™ã
if self.previous_contexts is None:
    # åˆå›ã®ã¿ã‚¼ãƒ­åˆæœŸåŒ–
    context = torch.zeros(1, self.model.context_dim, device=device)
else:
    # å‰ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®æœ€çµ‚ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å¿…ãšå¼•ãç¶™ãï¼ˆCVFPå­¦ç¿’ã®æ ¸å¿ƒï¼‰
    context = self.previous_contexts[-1].unsqueeze(0).detach()
```

**ãªãœã“ã‚ŒãŒè‡´å‘½çš„ã‹**:
1. **CVFP = Context Vector Fixed-Point**: å›ºå®šç‚¹ã¸ã®åæŸãŒç›®çš„
2. **å›ºå®šç‚¹å­¦ç¿’**: ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é‡ã­ã¦åŒã˜ç‚¹ã«åæŸã™ã‚‹ã“ã¨ãŒç›®æ¨™
3. **å¼•ãç¶™ãŒãªã„ = å­¦ç¿’ã—ã¦ã„ãªã„**: æ¯å›ãƒªã‚»ãƒƒãƒˆã§ã¯å›ºå®šç‚¹ã«åˆ°é”ä¸å¯èƒ½
4. **æ¤œè¨¼ãƒ­ã‚¹ã‚¼ãƒ­ã®è¬**: ãƒã‚°ã®ã›ã„ã§è¦‹ã‹ã‘ä¸Šè‰¯ã„çµæœã«è¦‹ãˆã¦ã„ãŸ

**äºŒåº¦ã¨åŒã˜é–“é•ã„ã‚’ã—ãªã„ãŸã‚ã«**:
- âš ï¸ ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–“ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¼•ãç¶™ãã¯**CVFPå­¦ç¿’ã®ç”Ÿå‘½ç·š**
- âš ï¸ `previous_contexts`ã®æœ€çµ‚å€¤ã‚’æ¬¡ã®åˆæœŸå€¤ã«ã™ã‚‹ã“ã¨ã¯**çµ¶å¯¾å¿…é ˆ**
- âš ï¸ ã“ã®ä¿®æ­£ãªã—ã§ã¯ã€ã™ã¹ã¦ã®å®Ÿé¨“çµæœãŒç„¡æ„å‘³ã«ãªã‚‹

---

## ğŸš¨ğŸš¨ğŸš¨ CRITICAL DESIGN FIX - PHASE 2 CONTEXT PROPAGATION (2025-11-24) ğŸš¨ğŸš¨ğŸš¨

### è‡´å‘½çš„è¨­è¨ˆãƒŸã‚¹: Phase 2ã§ã®å„ãƒˆãƒ¼ã‚¯ãƒ³ç‹¬ç«‹å‡¦ç†ï¼ˆçµ¶å¯¾ã«å¿˜ã‚Œã¦ã¯ã„ã‘ãªã„ï¼‰

**è‡´å‘½çš„ãªå•é¡Œï¼ˆä¿®æ­£å‰ã®å®Ÿè£…ï¼‰**:
- Phase 2ã§å„ãƒˆãƒ¼ã‚¯ãƒ³ãŒå®Œå…¨ã«ç‹¬ç«‹ã—ã¦å‡¦ç†ã•ã‚Œã¦ã„ãŸï¼ˆæ¯å›0ãƒ™ã‚¯ãƒˆãƒ«ã‹ã‚‰é–‹å§‹ï¼‰
- **ã“ã‚Œã¯Phase 1ã¨çŸ›ç›¾ã—ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦è‡´å‘½çš„ãªæ¬ é™¥**
- æ–‡è„ˆæƒ…å ±ãŒå…¨ãä¼ã‚ã‚‰ãšã€Phase 1ã®å­¦ç¿’ãŒç„¡é§„ã«ãªã£ã¦ã„ãŸ

**ä¿®æ­£å†…å®¹**:
```python
# âŒâŒâŒ çµ¶å¯¾ã«ã‚„ã£ã¦ã¯ã„ã‘ãªã„é–“é•ã£ãŸå®Ÿè£…ï¼ˆå‰Šé™¤æ¸ˆã¿ï¼‰
# å„ãƒˆãƒ¼ã‚¯ãƒ³ãŒç‹¬ç«‹ = æ–‡è„ˆä¼é”ãªã— = Phase 1ã¨ã®ä¸æ•´åˆ
for token_id in input_ids:
    context = torch.zeros(...)  # æ¯å›ãƒªã‚»ãƒƒãƒˆï¼è‡´å‘½çš„ãƒã‚°
    context = CVFP(token_embed, context)
    logits = predict(context)

# âœ…âœ…âœ… å¿…é ˆã®æ­£ã—ã„å®Ÿè£…ï¼ˆä¿®æ­£æ¸ˆã¿ï¼‰
# Contextä¼æ’­ + Token Embedäºˆæ¸¬
context = torch.zeros(...)  # æœ€åˆã®ãƒˆãƒ¼ã‚¯ãƒ³ã®ã¿0ã‹ã‚‰é–‹å§‹

for token_id in input_ids:
    context = context.detach()  # å‹¾é…é®æ–­ï¼ˆé‡è¦ï¼‰
    token_embed = embedding(token_id)

    # CVFPå‡¦ç†ï¼ˆæ–‡è„ˆã¨ãƒˆãƒ¼ã‚¯ãƒ³åŸ‹ã‚è¾¼ã¿ä¸¡æ–¹ã‚’ä¼æ’­ï¼‰
    for block in blocks:
        context, token_embed = block(token_embed, context)

    # Token embedã‹ã‚‰äºˆæ¸¬ï¼ˆcontextã‹ã‚‰ã§ã¯ãªã„ï¼‰
    logits = predict(token_embed)

    # Contextã¯æ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³ã«å¼•ãç¶™ãŒã‚Œã‚‹
```

### ãªãœã“ã‚ŒãŒè‡´å‘½çš„ã‹

1. **Phase 1ã¨ã®ä¸æ•´åˆ**: Phase 1ã§ã¯contextä¼æ’­ãŒå¿…é ˆã€Phase 2ã§ã‚‚åŒæ§˜ã§ã‚ã‚‹ã¹ã
2. **æ–‡è„ˆæƒ…å ±ã®æ¬ å¦‚**: å„ãƒˆãƒ¼ã‚¯ãƒ³ãŒç‹¬ç«‹ã§ã¯ç³»åˆ—å…¨ä½“ã®ç†è§£ãŒä¸å¯èƒ½
3. **Phase 1å­¦ç¿’ã®ç„¡é§„**: æ–‡è„ˆä¼é”ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ãŒPhase 2ã§æ´»ç”¨ã•ã‚Œãªã„
4. **è¨€èªãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ä¸å®Œå…¨**: å‰ã®ãƒˆãƒ¼ã‚¯ãƒ³æƒ…å ±ãŒå…¨ãä½¿ãˆãªã„

### æ­£ã—ã„è¨­è¨ˆã®é‡è¦ãƒã‚¤ãƒ³ãƒˆ

**1. Contextä¼æ’­ï¼ˆPhase 1ã¨åŒã˜ï¼‰**:
- æœ€åˆã®ãƒˆãƒ¼ã‚¯ãƒ³ã®ã¿0ãƒ™ã‚¯ãƒˆãƒ«ã‹ã‚‰é–‹å§‹
- ä»¥é™ã¯å‰ã®contextã‚’å¼•ãç¶™ã
- Phase 1ã§å­¦ç¿’ã—ãŸæ–‡è„ˆä¼é”ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’æ´»ç”¨

**2. Contextå‹¾é…é®æ–­**:
- `context = context.detach()` ã§å‹¾é…ã‚’é®æ–­
- ç†ç”±: ç³»åˆ—å…¨ä½“ã¸ã®å‹¾é…ä¼æ’­ã‚’é˜²ãã€å­¦ç¿’ã‚’å®‰å®šåŒ–

**3. Token Embedäºˆæ¸¬**:
- äºˆæ¸¬ã¯`token_embed`ã‹ã‚‰ï¼ˆ`context`ã‹ã‚‰ã§ã¯ãªã„ï¼‰
- Contextã¯æ–‡è„ˆè¨˜æ†¶ã€Token Embedã¯å‡ºåŠ›è¡¨ç¾ã¨ã—ã¦åˆ†é›¢

**4. å…¨ãƒˆãƒ¼ã‚¯ãƒ³ä¸€æ‹¬å‡¦ç†**:
- ãƒãƒƒãƒåˆ†å‰²ãªã—ï¼ˆcontextä¼æ’­ãŒã‚ã‚‹ãŸã‚ï¼‰
- Phase 1ã¨åŒã˜å‡¦ç†ãƒ•ãƒ­ãƒ¼

---

## âš ï¸ 89.4% Effective Rank Implementation - IMMUTABLE SPECIFICATION

### çµ¶å¯¾ä»•æ§˜: ã“ã®å®Ÿè£…ã¯å¤‰æ›´ç¦æ­¢ (ABSOLUTE: This implementation is IMMUTABLE)

**ã“ã®ä»•æ§˜ã¯æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§89.4% Effective Rankã‚’é”æˆã—ãŸæœ€çµ‚å®Ÿè£…ã§ã™ï¼ˆdist_reg_weight=0.5ï¼‰ã€‚**
**ä»¥ä¸‹ã®å®Ÿè£…ã¨çŸ›ç›¾ã™ã‚‹å†…å®¹ã¯å…¨ã¦ç„¡åŠ¹ã§ã™ã€‚**

---

## Core Implementation - Dimension Usage Statistics

### 1. Diversity Loss: Per-Dimension Usage Tracking

**âœ… æ­£ã—ã„å®Ÿè£… (ç¾åœ¨ã®phase1_trainer.py)**:

```python
# å„ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹æ™‚ã«ãƒªã‚»ãƒƒãƒˆ
dim_stats = torch.zeros(context_dim, device=device)

# å„ãƒˆãƒ¼ã‚¯ãƒ³å‡¦ç†æ™‚
dim_weights = 1.0 / (dim_stats + 1.0)  # ä½¿ç”¨é »åº¦ã®é€†æ•°ï¼ˆdetachedï¼‰
diversity_loss = -(dim_weights * context.abs().squeeze(0)).mean()  # è² ã®æå¤±ã§æ´»æ€§åŒ–æœ€å¤§åŒ–

# çµ±è¨ˆæ›´æ–°ï¼ˆå‹¾é…ãªã—ï¼‰ - æ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³ç”¨
with torch.no_grad():
    dim_stats += context.abs().squeeze(0)
```

**é‡è¦ãƒã‚¤ãƒ³ãƒˆ**:
- `dim_weights` ã¯ detachedï¼ˆå‹¾é…ãªã—ï¼‰
- `context` ã«ã¯å‹¾é…ãŒæµã‚Œã‚‹
- è² ã®æå¤±ã«ã‚ˆã‚Šã€ä½¿ç”¨é »åº¦ãŒä½ã„æ¬¡å…ƒã‚’å„ªå…ˆçš„ã«æ´»æ€§åŒ–

### 2. ãƒ‡ãƒ¼ã‚¿ä»•æ§˜ - çµ¶å¯¾å›ºå®š

**è¨“ç·´ãƒ‡ãƒ¼ã‚¿**:
- ã‚½ãƒ¼ã‚¹: UltraChat (HuggingFaceH4/ultrachat_200k)
- ã‚µãƒ³ãƒ—ãƒ«æ•°: 50
- ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 6400
- ã‚­ãƒ£ãƒƒã‚·ãƒ¥: `./cache/ultrachat_50samples_128len.pt`

**æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿** (çµ¶å¯¾ä»•æ§˜):
- ã‚½ãƒ¼ã‚¹: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®æœ€å¾Œ20%ã‹ã‚‰ç”Ÿæˆ
- ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 1280
- ãƒ•ã‚¡ã‚¤ãƒ«: `./data/example_val.txt`
- **å¿…é ˆæ¡ä»¶**: å…¨ãƒˆãƒ¼ã‚¯ãƒ³ãŒè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«å­˜åœ¨ã™ã‚‹ã“ã¨
- ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ: `scripts/create_val_from_train.py`

### 3. æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ«ãƒ¼ãƒ« - å³æ ¼

**ç¦æ­¢äº‹é …**:
- âŒ `val_data_source = "auto_split"` ã¯å³ç¦ï¼ˆã‚¨ãƒ©ãƒ¼ç™ºç”Ÿï¼‰
- âŒ è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«ãªã„ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å«ã‚€æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿
- âŒ æ‰‹å‹•ã§ä½œæˆã—ãŸãƒ©ãƒ³ãƒ€ãƒ ãªæ¤œè¨¼ãƒ†ã‚­ã‚¹ãƒˆ

**å¿…é ˆæ‰‹é †**:
```bash
# è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
python3 scripts/create_val_from_train.py

# config.pyã®è¨­å®šï¼ˆçµ¶å¯¾å›ºå®šï¼‰
val_data_source = "text_file"
val_text_file = "./data/example_val.txt"
```

### 4. é”æˆçµæœ - æœ€çµ‚ä»•æ§˜

**å®Ÿæ¸¬å€¤ (2025-11-24, dist_reg_weight=0.5)**:
- **è¨“ç·´ãƒ‡ãƒ¼ã‚¿**: 89.7% Effective Rank (689.26/768) - 6400ãƒˆãƒ¼ã‚¯ãƒ³
- **æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿**: **89.4% Effective Rank (686.90/768)** - 1280ãƒˆãƒ¼ã‚¯ãƒ³ âœ…
- **CVFPåæŸãƒã‚§ãƒƒã‚¯**: final_diff = 0.000745 < 0.001 âœ…

**ãªãœ89.4%ã‹**:
- `dist_reg_weight = 0.5` ã«ã‚ˆã‚Šã€CVFPå­¦ç¿’ã¨å¤šæ§˜æ€§ã®ä¸¡ç«‹ã‚’å®Ÿç¾
- è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§åŒç­‰ã®é«˜ã„å¤šæ§˜æ€§ï¼ˆ89.7% vs 89.4%ï¼‰
- 85%ç›®æ¨™ã‚’å¤§å¹…ã«è¶…ãˆã‚‹æˆæœ

---

## Architecture Configuration - Fixed

```python
# Model Architecture
num_layers = 6                  # 6-layer CVFP blocks
context_dim = 768               # GPT-2 aligned
embed_dim = 768                 # GPT-2 pretrained
hidden_dim = 1536               # 2 Ã— embed_dim
layernorm_mix = 1.0             # Full LayerNorm (CRITICAL)

# Diversity Regularization
dist_reg_weight = 0.5           # 50% diversity, 50% CVFP (balanced)

# Training
phase1_learning_rate = 0.002    # Fast convergence
phase1_max_iterations = 10      # Usually converges in 2 iterations
```

---

## Training Pipeline - Standard Workflow

### Phase 1: CVFP Learning

```bash
# Standard test (uses fixed train/val data)
python3 test.py
```

**å®Ÿè¡Œå†…å®¹**:
1. è¨“ç·´ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ (6400ãƒˆãƒ¼ã‚¯ãƒ³ from cache)
2. æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ (1280ãƒˆãƒ¼ã‚¯ãƒ³ from text file)
3. ãƒ¢ãƒ‡ãƒ«è¨“ç·´ (Phase1Trainer)
4. æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡
5. **3ã¤ã®å¿…é ˆãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ** (è©³ç´°ã¯ä¸‹è¨˜)

---

## 3 Critical Checks - ABSOLUTELY REQUIRED (çµ¶å¯¾å¿…è¦ãª3ã¤ã®ãƒã‚§ãƒƒã‚¯)

**ã“ã‚Œã‚‰ã®ãƒã‚§ãƒƒã‚¯ã‚’çœãã¨å•é¡ŒãŒå¤šç™ºã—ã¾ã™ã€‚test.pyã§å¿…ãšå®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚**

### Check 1: Effective Rank (å¤šæ§˜æ€§ç¢ºèª)

**ç›®çš„**: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ™ã‚¯ãƒˆãƒ«ãŒå¤šæ§˜ãªæ¬¡å…ƒã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ã‹ç¢ºèª

**å®Ÿè£…**: `analyze_fixed_points(contexts)` in `src/evaluation/metrics.py`

**åˆæ ¼åŸºæº–**:
- è¨“ç·´ãƒ‡ãƒ¼ã‚¿: 88-89% Effective Rank
- æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿: 81-82% Effective Rank

**å¤±æ•—ä¾‹**:
- âŒ Effective Rank < 30%: æ¬¡å…ƒãŒåã£ã¦ã„ã‚‹ï¼ˆå¤šæ§˜æ€§ãªã—ï¼‰
- âŒ Global attractor: å…¨ãƒˆãƒ¼ã‚¯ãƒ³ãŒåŒã˜ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«åæŸ

### Check 2: Identity Mapping Check (æ’ç­‰å†™åƒãƒã‚§ãƒƒã‚¯)

**ç›®çš„**: ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’ã§ãã¦ã„ã‚‹ã‹ã€å˜ãªã‚‹æ’ç­‰å†™åƒã§ãªã„ã‹ç¢ºèª

**å®Ÿè£…**: `check_identity_mapping(model, token_embeds, contexts, device)` in `src/evaluation/metrics.py`

**åˆæ ¼åŸºæº–**:
- âœ… Zero context ã¨ã®å·®åˆ† > 0.1
- âœ… Token embedding ã¨ã®é¡ä¼¼åº¦ < 0.95

**å¤±æ•—ä¾‹**:
- âŒ å­¦ç¿’å¾Œã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒã‚¼ãƒ­ãƒ™ã‚¯ãƒˆãƒ«ã¨åŒã˜ â†’ å­¦ç¿’ãªã—
- âŒ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒãƒˆãƒ¼ã‚¯ãƒ³åŸ‹ã‚è¾¼ã¿ã¨åŒä¸€ â†’ æ’ç­‰å†™åƒ

### Check 3: CVFP Convergence Check (å›ºå®šç‚¹åæŸãƒã‚§ãƒƒã‚¯)

**ç›®çš„**: å›ºå®šç‚¹å­¦ç¿’ãŒã§ãã¦ã„ã‚‹ã‹ã€åå¾©å®Ÿè¡Œã§å®‰å®šã—ãŸçµæœã«ãªã‚‹ã‹ç¢ºèª

**å®Ÿè£…**: `check_cvfp_convergence(trainer, token_ids, device)` in `src/evaluation/metrics.py`

**åˆæ ¼åŸºæº–**:
- âœ… Final diff < 1e-3 (GOODä»¥ä¸Š)
- âœ… ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–“ã®å¤‰åŒ–ãŒæ¸›å°‘å‚¾å‘

**å¤±æ•—ä¾‹**:
- âŒ Final diff > 1e-2: å›ºå®šç‚¹ã«åæŸã—ã¦ã„ãªã„
- âŒ ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–“ã§å¤‰åŒ–ãŒå¢—åŠ  â†’ ç™ºæ•£ã—ã¦ã„ã‚‹

---

## Reproducibility - å®Œå…¨ãªå†ç¾æ€§ä¿è¨¼

**ä¹±æ•°ã‚·ãƒ¼ãƒ‰å›ºå®š (å¿…é ˆ)**:

```python
def set_seed(seed=42):
    """å…¨ã¦ã®ä¹±æ•°ç”Ÿæˆå™¨ã®ã‚·ãƒ¼ãƒ‰ã‚’å›ºå®š"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

set_seed(42)
```

**ãªãœå¿…è¦ã‹**:
- åŒã˜ã‚³ãƒ¼ãƒ‰ã€åŒã˜ãƒ‡ãƒ¼ã‚¿ã§**å®Œå…¨ã«åŒã˜çµæœ**ã‚’ä¿è¨¼
- å®Ÿè£…ãŒç¶­æŒã•ã‚Œã¦ã„ã‚‹ã‹ã®ç¢ºèªã«ä¸å¯æ¬ 
- ãƒ‡ãƒãƒƒã‚°ã¨ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚’å®¹æ˜“ã«

**æœŸå¾…ã•ã‚Œã‚‹çµæœ**:
- è¨“ç·´ãƒ‡ãƒ¼ã‚¿ Effective Rank: **å®Œå…¨ã«åŒã˜å€¤** (å°æ•°ç‚¹ä»¥ä¸‹ã¾ã§ä¸€è‡´)
- æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ Effective Rank: **å®Œå…¨ã«åŒã˜å€¤** (å°æ•°ç‚¹ä»¥ä¸‹ã¾ã§ä¸€è‡´)
- 3ã¤ã®ãƒã‚§ãƒƒã‚¯çµæœ: æ¯å›åŒã˜

---

## File Structure - Final Organization

**Main Scripts**:
- `test.py` - æ¨™æº–ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆ6400è¨“ç·´ + 1280æ¤œè¨¼ï¼‰
- `train.py` - ãƒ•ãƒ«è¨“ç·´ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
- `config.py` - è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«

**Data Generation**:
- `scripts/create_val_from_train.py` - æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ï¼‰

**Core Implementation**:
- `src/training/phase1_trainer.py` - Phase 1è¨“ç·´ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆDimension Usage Statisticsï¼‰
- `src/models/new_llm_residual.py` - ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
- `src/data/loader.py` - ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ï¼ˆauto_splitç¦æ­¢ãƒ­ã‚¸ãƒƒã‚¯ï¼‰

---

## Validation Data Policy - CRITICAL

### å¿…é ˆä»•æ§˜

**æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã¯è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®éƒ¨åˆ†é›†åˆã§ãªã‘ã‚Œã°ãªã‚‰ãªã„**:
- å…¨ã¦ã®æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ãƒˆãƒ¼ã‚¯ãƒ³ãŒè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«å­˜åœ¨
- ãƒ©ãƒ³ãƒ€ãƒ ãªåˆ†å‰²ã¯ç¦æ­¢ï¼ˆ`auto_split` ä½¿ç”¨ã§ã‚¨ãƒ©ãƒ¼ï¼‰
- è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç›´æ¥ç”Ÿæˆï¼ˆ`create_val_from_train.py`ï¼‰

### ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿãƒ­ã‚¸ãƒƒã‚¯

`loader.py` ã§å®Ÿè£…æ¸ˆã¿:
```python
if config.val_data_source == "auto_split":
    raise ValueError(
        "âŒ CRITICAL ERROR: auto_split is STRICTLY FORBIDDEN!"
        "Use val_data_source='text_file' with data/example_val.txt"
    )
```

---

## Code Quality Standards

### Principles

1. **No Hardcoding**: All hyperparameters in config.py
2. **Single Responsibility**: Each module has one clear purpose
3. **Immutable Data**: Training/validation data are fixed
4. **Error Prevention**: Auto-split is forbidden with error

### Anti-Patterns to Avoid

- âŒ Changing train/val data without regeneration
- âŒ Using auto_split for validation
- âŒ Modifying diversity loss implementation
- âŒ Changing architecture without full retraining

---

## Performance Benchmarks

**CPU Performance (Apple Silicon/Intel)**:
- Training speed: 250-330 tok/s
- 6400 tokens: ~25 seconds per iteration
- Validation: ~4 seconds (1280 tokens)

**Expected Results**:
- Training Effective Rank: 89.7%
- Validation Effective Rank: 89.4%
- CVFP Convergence Check: final_diff < 0.001
- Convergence: Usually 10 iterations (all iterations complete)

---

## No Hardcoding Policy - Reinforced

**å…¨ã¦ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯config.pyã§å®šç¾©**:
```python
# âœ… Good
learning_rate = config.phase1_learning_rate
num_samples = config.num_samples

# âŒ Bad
learning_rate = 0.002  # Hardcoded!
num_samples = 50       # Hardcoded!
```

---

## Context Size Monitoring Policy

**Claude Codeã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç®¡ç†**:
- 100,000ãƒˆãƒ¼ã‚¯ãƒ³è¶…éæ™‚: åˆå›å ±å‘Š
- ä»¥é™10,000ãƒˆãƒ¼ã‚¯ãƒ³åˆ»ã¿ã§ç¶™ç¶šå ±å‘Š
- 190,000ãƒˆãƒ¼ã‚¯ãƒ³ä»¥ä¸Š: æ–°ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹ã‚’å¼·ãæ¨å¥¨

---

Last Updated: 2025-11-24 (89.4% Implementation with Phase 2)
