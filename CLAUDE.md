# New-LLM Project Guidelines

## ğŸ¯ Multi Contextæ–¹å¼ï¼ˆNåˆ†å‰²ï¼‰æ¡ç”¨ (2025-12-02)

**âš ï¸ é‡è¦: æˆåŠŸè¦å› ã¯ã€Œç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã€ã™ã‚‹ã“ã¨ã§ã™ã€‚**

### ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

| æ§‹æˆ | Val PPL | Val Acc | å‚™è€ƒ |
|------|---------|---------|------|
| **2-block (500Ã—2=1000)** | **111.9** | **25.6%** | **2åˆ†å‰²** |
| C1T1-500 | 127.2 | 24.7% | æ¨™æº–æ§‹æˆ |
| C2T2-500 | 132.2 | 24.4% | 2å±¤ã ãŒæ‚ªåŒ– |
| C1T1-1000 | 134.0 | 23.6% | context_dimå¢—åŠ ã¯éåŠ¹ç‡ |

### Nåˆ†å‰²æ–¹å¼ã®æ­£ã—ã„ç†è§£

**æ ¸å¿ƒ**: å„ContextBlockã¯**ç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿**ã§å­¦ç¿’ã™ã‚‹ã“ã¨ã§ã€**ç•°ãªã‚‹è¡¨ç¾**ã‚’ç²å¾—ã™ã‚‹ã€‚

```
Nåˆ†å‰²æ–¹å¼ï¼ˆ--num-blocks N ã§æŒ‡å®šï¼‰:

Phase 1[i]: ContextBlock[i] ã‚’ i ç•ªç›®ã®ãƒ‡ãƒ¼ã‚¿åŒºé–“ã§å­¦ç¿’
  â†’ åˆæœŸå…¥åŠ›: ã‚¼ãƒ­ãƒ™ã‚¯ãƒˆãƒ«
  â†’ ãƒ‡ãƒ¼ã‚¿: tokens[i*split:(i+1)*split]

Phase 2 Prep: é †æ¬¡å‡¦ç†ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥åé›†
  â†’ å…¨ãƒ‡ãƒ¼ã‚¿ã‚’é †æ¬¡å‡¦ç†ã—ã¦context_0, ..., context_{N-1}ã‚’åé›†

Phase 2: TokenBlock å­¦ç¿’
  â†’ å…¥åŠ›: concat(context_0[i-1], ..., context_{N-1}[i-1])
  â†’ äºˆæ¸¬: token[i]
```

### âŒ é–“é•ã£ãŸç†è§£

ä»¥ä¸‹ã¯**é–“é•ã„**ã§ã™:
- ã€Œå…¨ãƒ–ãƒ­ãƒƒã‚¯ãŒå…¨ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã€â†’ åŒã˜ã‚ˆã†ãªè¡¨ç¾ã«ãªã£ã¦ã—ã¾ã†
- ã€ŒInitial Context Inheritanceã§ç•°ãªã‚‹è¡¨ç¾ã‚’ç²å¾—ã§ãã‚‹ã€â†’ PPLæ‚ªåŒ–ï¼ˆ119.5 vs 111.9ï¼‰

**æˆåŠŸã®éµ**: ç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã™ã‚‹ã“ã¨ã€‚åˆæœŸå…¥åŠ›ã®é•ã„ã§ã¯ãªãã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®é•ã„ãŒé‡è¦ã€‚

### å®Ÿé¨“ã®å®Ÿè¡Œ

```bash
# Colabï¼ˆGPUï¼‰: 2ãƒ–ãƒ­ãƒƒã‚¯ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
python3 scripts/experiment_cascade_context.py -s 2000

# Colabï¼ˆGPUï¼‰: 4ãƒ–ãƒ­ãƒƒã‚¯
python3 scripts/experiment_cascade_context.py -s 2000 -n 4
```

### Phase 2 Prepã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥åé›†

Phase 2ã§ã¯**é †æ¬¡å‡¦ç†**ã§å…¨ãƒ‡ãƒ¼ã‚¿ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’åé›†ã—ã¾ã™ã€‚
ã“ã‚Œã¯dual_output.txtï¼ˆPPL=111.9ï¼‰ã¨åŒã˜æ–¹å¼ã§ã™ã€‚

**å‡¦ç†æ™‚é–“**: 2M tokens ã§ç´„983ç§’ï¼ˆç´„16åˆ†ï¼‰

**æ³¨æ„**: ä¸¦åˆ—å‡¦ç†ï¼ˆshifted_prev_contextæ–¹å¼ï¼‰ã¯ Phase 1 å­¦ç¿’å°‚ç”¨ã§ã™ã€‚
Phase 2 Prep ã§ã¯æ­£ç¢ºãªRNNå‹•ä½œã‚’å†ç¾ã™ã‚‹ãŸã‚ã€é †æ¬¡å‡¦ç†ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

---

## ğŸ¯ OACDã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ æ¡ç”¨ (2025-12-01)

**Phase 1ã§ã¯OACD (Origin-Anchored Centroid Dispersion) ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’æ¡ç”¨ã€‚**

### OACDã®ç‰¹å¾´

```python
def oacd_loss(contexts, centroid_weight=0.1):
    # Term 1: é‡å¿ƒã‹ã‚‰ã®åˆ†æ•£ã‚’æœ€å¤§åŒ–
    dispersion_loss = -||X - mean(X)|| / n

    # Term 2: é‡å¿ƒã‚’åŸç‚¹ã«å¼•ãå¯„ã›ã‚‹
    centroid_loss = ||mean(X)||Â²

    return dispersion_loss + centroid_weight * centroid_loss
```

**ç‰¹å¾´**:
- é‡å¿ƒã‚’åŸç‚¹ã«å›ºå®šã™ã‚‹ã“ã¨ã§ã€å®‰å®šã—ãŸå¹³è¡¡ç‚¹ã‚’å®Ÿç¾
- ã€Œè‡ªå·±å¹³è¡¡ã€åŠ¹æœã‚’ç¶­æŒï¼ˆç›¸å¯¾çš„ç›®æ¨™ï¼‰
- ã‚·ãƒ³ãƒ—ãƒ«ãªæå¤±é–¢æ•°ã§é«˜ã„Effective Rankï¼ˆ80%+ï¼‰ã‚’é”æˆ

---

## ğŸš¨ 1å±¤å›ºå®šã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ (2025-12-02)

**ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰é€£çµæ–¹å¼ã«ã‚ˆã‚Šã€è¤‡æ•°ãƒ¬ã‚¤ãƒ¤ãƒ¼ã¯ä¸è¦ã€‚**

```python
# å„ãƒ–ãƒ­ãƒƒã‚¯1å±¤å›ºå®š
ContextBlock: 1å±¤
TokenBlock: 1å±¤

# ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰é€£çµã§è¡¨ç¾åŠ›ã‚’ç¢ºä¿ï¼ˆå¯å¤‰ãƒ–ãƒ­ãƒƒã‚¯æ•°å¯¾å¿œï¼‰
combined_context = concat(context[0], context[1], ..., context[N-1])  # cd=context_dimÃ—N
```

**ç†ç”±**:
- C2T2ï¼ˆ2å±¤ï¼‰ãŒC1T1ï¼ˆ1å±¤ï¼‰ã‚ˆã‚Š**æ‚ªåŒ–**ã—ãŸå®Ÿé¨“çµæœ
- ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰é€£çµã§ååˆ†ãªè¡¨ç¾åŠ›ã‚’ç¢ºä¿
- ãƒ–ãƒ­ãƒƒã‚¯æ•°ã‚’å¢—ã‚„ã™ã“ã¨ã§è¡¨ç¾åŠ›ã‚’æ‹¡å¼µå¯èƒ½
- ã‚³ãƒ¼ãƒ‰ã®å¤§å¹…ãªç°¡ç´ åŒ–

---

## ğŸš¨ğŸš¨ Phase 1å­¦ç¿’ã§ã¯é †æ¬¡å‡¦ç†ç¦æ­¢ (CRITICAL) ğŸš¨ğŸš¨

**âš ï¸ ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯éå»ã«èª¤ã£ã¦å‰Šé™¤ã•ã‚ŒãŸã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚çµ¶å¯¾ã«å‰Šé™¤ã—ãªã„ã§ãã ã•ã„ã€‚**

**Phase 1å­¦ç¿’ã§ã¯ã€é †æ¬¡å‡¦ç†ï¼ˆ`for i in range(num_tokens)`ã§ãƒˆãƒ¼ã‚¯ãƒ³ã‚’1ã¤ãšã¤å‡¦ç†ï¼‰ã¯å³ç¦ã€‚å¿…ãšshifted_prev_contextæ–¹å¼ã§ä¸¦åˆ—å‡¦ç†ã™ã‚‹ã“ã¨ã€‚**

### Phase 1å­¦ç¿’ã§ã®ç¦æ­¢ãƒ‘ã‚¿ãƒ¼ãƒ³

```python
# âŒ ç¦æ­¢: Phase 1å­¦ç¿’ã§é †æ¬¡å‡¦ç†ï¼ˆéå¸¸ã«é…ã„ï¼‰
for i in range(num_tokens):
    token_embed = input_embeds[i:i+1].to(device)
    new_context = model.forward_context(prev_context, token_embed)
    prev_context = new_context
```

### Phase 1å­¦ç¿’ã§ã®æ¨å¥¨ãƒ‘ã‚¿ãƒ¼ãƒ³

```python
# âœ… æ¨å¥¨: shifted_prev_contextæ–¹å¼ï¼ˆä¸¦åˆ—å‡¦ç†ã€æ•°ç§’ã§å®Œäº†ï¼‰
previous_contexts = torch.randn(num_tokens, context_dim) * 0.01
zero_init = torch.zeros(1, context_dim)  # å¸¸ã«ã‚¼ãƒ­ãƒ™ã‚¯ãƒˆãƒ«ã‹ã‚‰é–‹å§‹

for iteration in range(max_iterations):
    shifted_prev_context = torch.cat([zero_init, previous_contexts[:-1]], dim=0)
    new_contexts = model.forward_context(shifted_prev_context, input_embeds)
    if converged:
        break
    previous_contexts = new_contexts
```

### Phase 2 Prepã§ã¯é †æ¬¡å‡¦ç†ã‚’ä½¿ç”¨

**Phase 2 Prepã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥åé›†ã§ã¯ã€æ­£ç¢ºãªRNNå‹•ä½œã‚’å†ç¾ã™ã‚‹ãŸã‚é †æ¬¡å‡¦ç†ã‚’ä½¿ç”¨ã™ã‚‹ã€‚**

```python
# âœ… Phase 2 Prep: é †æ¬¡å‡¦ç†ï¼ˆæ­£ç¢ºãªRNNå‹•ä½œï¼‰
for i in range(num_tokens):
    new_context_a = model.forward_context(0, prev_context_a, token_embed)
    new_context_b = model.forward_context(1, prev_context_b, token_embed)
    prev_context_a = new_context_a
    prev_context_b = new_context_b
```

**å‡¦ç†æ™‚é–“**: 2M tokens ã§ç´„983ç§’ï¼ˆç´„16åˆ†ï¼‰ã€‚æ™‚é–“ã¯ã‹ã‹ã‚‹ãŒæ­£ç¢ºãªçµæœã‚’å¾—ã‚‹ã€‚

---

## ğŸ’» ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿé¨“ã®æ³¨æ„äº‹é … - CPUç’°å¢ƒ (2025-12-01)

**ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒï¼ˆMac/CPUï¼‰ã§ã¯å‡¦ç†ãŒé…ã„ãŸã‚ã€ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’æœ€å°é™ã«æŠ‘ãˆã‚‹ã€‚**

```bash
# ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿé¨“ï¼ˆCPUï¼‰: 2-5ã‚µãƒ³ãƒ—ãƒ«ã§ååˆ†
python3 scripts/experiment_cascade_context.py -s 2

# Colabï¼ˆGPUï¼‰: 2000ã‚µãƒ³ãƒ—ãƒ«ã§æœ¬æ ¼å®Ÿé¨“
python3 scripts/experiment_cascade_context.py -s 2000
```

---

## ğŸš¨ CPU/GPUãƒ†ãƒ³ã‚½ãƒ«ç®¡ç† - é‡è¦æ•™è¨“ (2025-12-01)

**å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ï¼ˆ2000ã‚µãƒ³ãƒ—ãƒ«ä»¥ä¸Šï¼‰ã§OOMã‚’é˜²ããŸã‚ã€ãƒ†ãƒ³ã‚½ãƒ«ã®ãƒ‡ãƒã‚¤ã‚¹ç®¡ç†ã‚’å¾¹åº•ã€‚**

### ä¿®æ­£ãƒ‘ã‚¿ãƒ¼ãƒ³

```python
# âŒ ä¿®æ­£å‰: CPUãƒ†ãƒ³ã‚½ãƒ«ã‚’ãã®ã¾ã¾ä½¿ç”¨
batch_contexts = previous_contexts[start_idx:end_idx].detach()

# âœ… ä¿®æ­£å¾Œ: æ˜ç¤ºçš„ã«GPUè»¢é€
batch_contexts = previous_contexts[start_idx:end_idx].detach().to(self.device)
```

### ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆï¼ˆOOMå¯¾ç­–ã‚³ãƒ¼ãƒ‰å¤‰æ›´æ™‚ï¼‰

- [ ] CPUã«ä¿æŒã™ã‚‹ãƒ†ãƒ³ã‚½ãƒ«ã‚’ç‰¹å®š
- [ ] GPUæ¼”ç®—ã«æ¸¡ã™å‰ã«`.to(self.device)`ã‚’è¿½åŠ 
- [ ] ãƒ«ãƒ¼ãƒ—å†…ã®ã™ã¹ã¦ã®ãƒ†ãƒ³ã‚½ãƒ«è»¢é€ã‚’ç¢ºèª
- [ ] `torch.cat`ã‚„æ¼”ç®—ã®å…¥åŠ›ãƒ‡ãƒã‚¤ã‚¹ã‚’çµ±ä¸€

---

## ğŸš¨ğŸš¨ Phase 2 Prep: GPUãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯é˜²æ­¢ (CRITICAL) (2025-12-03) ğŸš¨ğŸš¨

**âš ï¸ Phase 2 Prepã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥åé›†ã§GPUãƒ¡ãƒ¢ãƒªãŒ15GB+æ¶ˆè²»ã•ã‚Œã‚‹å•é¡ŒãŒç™ºç”Ÿã—ãŸã€‚**

### å•é¡Œã®åŸå› 

```python
# âŒ ç¦æ­¢: å…¨token_embedsã‚’GPUã«ä¸€åº¦ã«ãƒ­ãƒ¼ãƒ‰
with torch.no_grad():
    token_embeds = model.token_embedding(token_ids.to(device))  # å…¨ãƒ‡ãƒ¼ã‚¿ã‚’GPUã«ï¼
    token_embeds = model.embed_norm(token_embeds)

for i in range(num_tokens - 1):
    token_embed = token_embeds[i:i+1]  # GPUãƒ¡ãƒ¢ãƒªã«å…¨ä½“ãŒæ®‹ã‚‹
    new_context = model.forward_context(prev_context, token_embed)
    prev_context = new_context  # è¨ˆç®—ã‚°ãƒ©ãƒ•ãŒè“„ç©
```

**å•é¡Œç‚¹**:
1. å…¨token_embedsï¼ˆ240ä¸‡ãƒˆãƒ¼ã‚¯ãƒ³Ã—768æ¬¡å…ƒÃ—4bytes â‰ˆ 7GBï¼‰ãŒGPUã«å¸¸é§
2. `prev_context = new_context` ã§è¨ˆç®—ã‚°ãƒ©ãƒ•ãŒè“„ç©
3. ãƒ«ãƒ¼ãƒ—ä¸­ã«ãƒ¡ãƒ¢ãƒªãŒå¢—åŠ ã—ç¶šã‘ã‚‹

### æ­£ã—ã„å®Ÿè£…ï¼ˆãƒãƒ£ãƒ³ã‚¯å‡¦ç†ï¼‰

```python
# âœ… æ¨å¥¨: ãƒãƒ£ãƒ³ã‚¯å˜ä½ã§GPUã«è»¢é€ã—ã€å³åº§ã«è§£æ”¾
# src/utils/cache.py ã® collect_context_cache_sequential ã‚’ä½¿ç”¨

with torch.no_grad():
    for chunk_start in range(0, num_tokens - 1, chunk_size):
        chunk_end = min(chunk_start + chunk_size, num_tokens - 1)

        # ãƒãƒ£ãƒ³ã‚¯åˆ†ã ã‘GPUã«è»¢é€
        chunk_token_ids = token_ids[chunk_start:chunk_end + 1].to(device)
        chunk_embeds = model.token_embedding(chunk_token_ids)
        chunk_embeds = model.embed_norm(chunk_embeds)

        for i in range(chunk_end - chunk_start):
            token_embed = chunk_embeds[i:i+1]
            new_context = model.forward_context(prev_context, token_embed)
            context_cache[chunk_start + i] = new_context.cpu()
            prev_context = new_context.detach()  # â† è¨ˆç®—ã‚°ãƒ©ãƒ•ã‚’åˆ‡æ–­ï¼

        # ãƒãƒ£ãƒ³ã‚¯å®Œäº†å¾Œã«GPUãƒ¡ãƒ¢ãƒªã‚’è§£æ”¾
        del chunk_token_ids, chunk_embeds
        clear_gpu_cache(device)
```

### å¿…é ˆãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆï¼ˆPhase 2 Prepå®Ÿè£…æ™‚ï¼‰

- [ ] **å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€åº¦ã«GPUã«ãƒ­ãƒ¼ãƒ‰ã—ã¦ã„ãªã„ã‹**
- [ ] **ãƒãƒ£ãƒ³ã‚¯å˜ä½ã§å‡¦ç†ã—ã¦ã„ã‚‹ã‹**ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 10,000ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰
- [ ] **`.detach()`ã§è¨ˆç®—ã‚°ãƒ©ãƒ•ã‚’åˆ‡æ–­ã—ã¦ã„ã‚‹ã‹**
- [ ] **ãƒãƒ£ãƒ³ã‚¯å®Œäº†å¾Œã«`del`ã¨`clear_gpu_cache()`ã‚’å‘¼ã‚“ã§ã„ã‚‹ã‹**
- [ ] **å…±é€šã‚³ãƒ¼ãƒ‰`src/utils/cache.py`ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ã‹**

### å…±é€šã‚³ãƒ¼ãƒ‰ã®ä½¿ç”¨

```python
# ã‚¹ã‚¯ãƒªãƒ—ãƒˆå›ºæœ‰ã®å®Ÿè£…ã§ã¯ãªãã€å…±é€šã‚³ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨
from src.utils.cache import collect_context_cache_sequential

# å˜ä¸€ãƒ–ãƒ­ãƒƒã‚¯ç”¨
context_cache = collect_context_cache_sequential(model, token_ids, device)

# è¤‡æ•°ãƒ–ãƒ­ãƒƒã‚¯ç”¨
from src.utils.cache import collect_context_cache_sequential_multiblock
context_caches = collect_context_cache_sequential_multiblock(model, token_ids, device, num_blocks)
```

---

## âš ï¸ COLABç’°å¢ƒãƒªã‚»ãƒƒãƒˆå¯¾ç­– (2025-11-29)

**Colabã¯é »ç¹ã«ç’°å¢ƒãŒãƒªã‚»ãƒƒãƒˆã•ã‚Œã‚‹ãŸã‚ã€ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ¶ˆå¤±ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚**

### è‡ªå‹•ç”Ÿæˆã•ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ«

| ãƒ•ã‚¡ã‚¤ãƒ« | ç”¨é€” | è‡ªå‹•ç”Ÿæˆå…ƒ |
|----------|------|----------|
| `./data/example_val.txt` | æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ | `MemoryDataProvider._generate_val_file()` |
| `./cache/ultrachat_*samples_full.pt` | è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥ | `MemoryDataProvider._load_train_data()` |

### Colabã§ã®æ¨å¥¨æ‰‹é †

```bash
# 1. ãƒªãƒã‚¸ãƒˆãƒªæ›´æ–°
!cd /content/new-llm && git pull

# 2. å®Ÿé¨“å®Ÿè¡Œ
!cd /content/new-llm && python3 scripts/experiment_cascade_context.py -s 2000
```

---

## ğŸ”§ é–‹ç™ºç’°å¢ƒã®Lint/Type Check (2025-11-29)

**pyenvç’°å¢ƒã§ã¯ruffã‚„mypyã‚’ç›´æ¥å®Ÿè¡Œã§ããªã„ãŸã‚ã€`python3 -m` ã§å®Ÿè¡Œã™ã‚‹ã€‚**

```bash
# Lint (ruff)
python3 -m ruff check src/

# Type check (mypy)
python3 -m mypy src/ --ignore-missing-imports

# å®Ÿé¨“ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
python3 -m ruff check scripts/experiment_cascade_context.py
python3 -m mypy scripts/experiment_cascade_context.py --ignore-missing-imports
```

---

## ğŸš¨ CRITICAL: å¾Œæ–¹äº’æ›æ€§ã‚³ãƒ¼ãƒ‰ç¦æ­¢ (2025-11-29)

**å¤ã„æ©Ÿèƒ½ã‚’æ®‹ã™ã“ã¨ã¯å³ç¦ã€‚å¾Œæ–¹äº’æ›æ€§ã‚’æ„è­˜ã—ãŸã‚³ãƒ¼ãƒ‰ã¯çµ¶å¯¾ã«æ›¸ã‹ãªã„ã€‚**

### ç¦æ­¢äº‹é …

1. **ã‚ªãƒ—ã‚·ãƒ§ãƒ³å¼•æ•°ã§ã®åˆ†å²ç¦æ­¢**
2. **å¤ã„ãƒ¡ã‚½ãƒƒãƒ‰ã®æ®‹å­˜ç¦æ­¢**
3. **ã€Œå¿µã®ãŸã‚ã€ã§æ®‹ã•ãªã„**

---

## ğŸ§Š EMBEDDING FREEZE ADOPTED - Embeddingå‡çµæ¡ç”¨ (2025-11-27)

**Phase 2ã§Embeddingå‡çµã‚’æ¨™æº–æ¡ç”¨ã€‚**

| æŒ‡æ¨™ | Embeddingå­¦ç¿’ | Embeddingå‡çµ | æ”¹å–„ç‡ |
|------|--------------|--------------|--------|
| Val PPL | 1189.15 | **334.31** | **-71.9%** |
| Val Acc | 11.58% | **18.88%** | **+63.0%** |

---

## ğŸ”— WEIGHT TYING ADOPTED - é‡ã¿å…±æœ‰æ¡ç”¨ (2025-11-27)

**Weight Tyingã‚’æ¨™æº–æ¡ç”¨ã€‚ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚’ç´„38Må‰Šæ¸›ã€‚**

| é …ç›® | Without Weight Tying | With Weight Tying |
|------|---------------------|-------------------|
| å…¨ä½“ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | 91.43M | **52.78M** (-42%) |
| Output Head | 38.65M | **0** (å…±æœ‰) |

---

## ğŸ“Š MANDATORY: æ•°å€¤å ±å‘Šãƒ«ãƒ¼ãƒ«

### çµ¶å¯¾éµå®ˆ: ã™ã¹ã¦ã®å®Ÿé¨“çµæœã¯å…·ä½“çš„ãªæ•°å€¤ã§å ±å‘Šã™ã‚‹

**å¿…é ˆå ±å‘Šé …ç›®**:
- âœ… **åæŸç‡**: å…·ä½“çš„ãªãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ (ä¾‹: 92%)
- âœ… Effective Rank: **å®Ÿæ•°å€¤/ç·æ¬¡å…ƒæ•°ã¨ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸** (ä¾‹: 736/1000 = 73.6%)
- âœ… Val PPL: **å®Ÿæ•°å€¤** (ä¾‹: 111.9)
- âœ… Val Acc: **å®Ÿæ•°å€¤** (ä¾‹: 25.6%)

---

## ğŸ“ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ä»•æ§˜

### Core Componentsï¼ˆ1å±¤å›ºå®šï¼‰

**1. ContextLayer / TokenLayer**
- ContextLayer: æ–‡è„ˆå‡¦ç†å°‚ç”¨ï¼ˆå˜ä¸€ãƒ¬ã‚¤ãƒ¤ãƒ¼ï¼‰
- TokenLayer: ãƒˆãƒ¼ã‚¯ãƒ³å‡¦ç†å°‚ç”¨ï¼ˆå˜ä¸€ãƒ¬ã‚¤ãƒ¤ãƒ¼ï¼‰

**2. ContextBlock / TokenBlock**
- ContextBlock: 1å±¤å›ºå®šã€Phase 1ã§å­¦ç¿’ã€Phase 2ã§freeze
- TokenBlock: 1å±¤å›ºå®šã€Phase 2ã§å­¦ç¿’

**3. CascadeContextLLMï¼ˆå®Ÿé¨“ç”¨ãƒ¢ãƒ‡ãƒ«ï¼‰**
- ContextBlock[0..N-1]ï¼ˆã‚«ã‚¹ã‚±ãƒ¼ãƒ‰é€£çµã€å¯å¤‰ãƒ–ãƒ­ãƒƒã‚¯æ•°å¯¾å¿œï¼‰
- TokenBlockï¼ˆé€£çµã•ã‚ŒãŸcontextå…¥åŠ›ï¼‰
- Token Embedding: GPT-2 pretrained (768-dim, frozen)
- Weight Tying: token_output shares weights with token_embedding

### Phase 1: å¤šæ§˜æ€§å­¦ç¿’ï¼ˆOACDï¼‰

- **å­¦ç¿’å¯¾è±¡**: ContextBlockã®ã¿
- **æå¤±**: OACDï¼ˆå¤šæ§˜æ€§æå¤±ï¼‰

### Phase 2: ãƒˆãƒ¼ã‚¯ãƒ³äºˆæ¸¬

- **ContextBlock**: frozenï¼ˆé‡ã¿å›ºå®šï¼‰
- **TokenBlock**: å­¦ç¿’
- **æå¤±**: CrossEntropyï¼ˆæ¬¡ãƒˆãƒ¼ã‚¯ãƒ³äºˆæ¸¬ï¼‰

---

## Code Quality Standards

### Principles

1. **No Hardcoding**: All hyperparameters in config.py
2. **Single Responsibility**: Each module has one clear purpose
3. **Error Prevention**: Strict validation
4. **Type Hints Required**: é–¢æ•°ãƒ»ãƒ¡ã‚½ãƒƒãƒ‰ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«ã¯å‹æ³¨é‡ˆã‚’å¿…é ˆ

### ğŸš¨ å‹æ³¨é‡ˆãƒãƒªã‚·ãƒ¼ - é‡è¦ (2025-12-02)

**å‹•çš„ãªå±æ€§ã‚¢ã‚¯ã‚»ã‚¹ã«ã‚ˆã‚‹AttributeErrorã‚’é˜²ããŸã‚ã€å‹æ³¨é‡ˆã‚’å¾¹åº•ã™ã‚‹ã€‚**

```python
# âŒ å‹æ³¨é‡ˆãªã— â†’ mypy ã§å±æ€§ä¸è¶³ã‚’æ¤œå‡ºã§ããªã„
def __init__(self, base, context_dim):
    self.value = base.some_attribute

# âœ… å‹æ³¨é‡ˆã‚ã‚Š â†’ mypy ã§å±æ€§ä¸è¶³ã‚’æ¤œå‡ºå¯èƒ½
def __init__(self, base: Config, context_dim: int):
    self.value = base.some_attribute
```

### Anti-Patterns to Avoid

- âŒ Changing architecture without full retraining
- âŒ Using deprecated features
- âŒ Leaving backward compatibility code
- âŒ å‹æ³¨é‡ˆãªã—ã§ã®Configå±æ€§ã‚¢ã‚¯ã‚»ã‚¹

---

## File Structure

**Main Scripts**:
- `scripts/experiment_cascade_context.py` - ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰é€£çµå®Ÿé¨“ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

**Core Implementation**:
- `src/trainers/phase1/memory.py` - Phase 1è¨“ç·´ãƒ­ã‚¸ãƒƒã‚¯
- `src/models/blocks.py` - ContextBlock/TokenBlockï¼ˆ1å±¤å›ºå®šï¼‰
- `src/models/layers.py` - ContextLayer/TokenLayer
- `src/models/llm.py` - åŸºæœ¬LLMãƒ¢ãƒ‡ãƒ«
- `src/losses/diversity.py` - OACDã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 

---

Last Updated: 2025-12-03 (Phase 2 Prepã®GPUãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯é˜²æ­¢ã€å…±é€šã‚³ãƒ¼ãƒ‰src/utils/cache.pyè¿½åŠ )
