# New-LLM: Context Vector Fixed-Point Property

A novel language model architecture based on the hypothesis that context vectors converge to fixed points with high dimensional diversity.

## Core Concept: CVFP (Context Vector Fixed-Point Property)

New-LLM explores the idea that meaningful context representations emerge through iterative refinement to fixed points, rather than traditional recurrent or transformer-based approaches.

## Features

- **Two-Phase Training**: Separate fixed-point learning and token prediction
- **High Dimensional Diversity**: Achieves **89.3% Effective Rank** using LayerNorm + EMA-based variance tracking
- **True Online Learning (æŒ‡æ•°å¹³å‡çš„)**: Fixed 6KB memory usage, no history storage required
- **Diversity Regularization**: Per-dimension variance tracking with exponential moving average
- **Clean Architecture**: Object-oriented design with CVFPLayer encapsulation
- **Flexible Data Loading**: Supports UltraChat, text files, and custom datasets
- **GPU-Ready**: 10-20x speedup available with CUDA

## Quick Start

### Installation

```bash
pip install -r requirements.txt
```

### Basic Training

```bash
# Quick test with 10 tokens (for development)
python3 tests/test_refactored.py

# Full training with configuration
python3 train.py
```

### Configuration

Edit `config.py` to adjust:
- Model architecture (layers, dimensions)
- Training parameters (learning rates, iterations)
- Data sources and preprocessing
- Distribution regularization settings

## Project Structure

```
new-llm/
â”œâ”€â”€ train.py              # Main training script
â”œâ”€â”€ config.py             # Configuration
â”œâ”€â”€ CLAUDE.md             # Design guidelines and architecture decisions
â”œâ”€â”€ CONTEXT.md            # Development history and insights
â”œâ”€â”€ README.md             # This file
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ cvfp/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py        # CVFP module exports
â”‚   â”‚   â”‚   â”œâ”€â”€ layer.py           # CVFPLayer (basic unit)
â”‚   â”‚   â”‚   â””â”€â”€ block.py           # CVFPBlock (multi-layer)
â”‚   â”‚   â””â”€â”€ new_llm_residual.py    # Main model architecture
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ phase1.py              # Fixed-point learning
â”‚   â”‚   â””â”€â”€ phase2.py              # Token prediction
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ loader.py              # Data loading utilities
â”‚   â””â”€â”€ evaluation/
â”‚       â””â”€â”€ metrics.py             # Analysis and metrics
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_refactored.py         # Quick development test (10 tokens)
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ (experimental scripts)     # Future experiments and utilities
â””â”€â”€ data/
    â”œâ”€â”€ example_train.txt          # Example training data
    â””â”€â”€ example_val.txt            # Example validation data
```

## Architecture Highlights

### Diversity Regularization: LayerNorm + Per-Dimension Variance Tracking (EMA-based)

Our breakthrough approach combines two complementary techniques:

**1. LayerNorm (Value Explosion Prevention)**
```python
# Prevents residual connection value explosion
if layernorm_mix > 0:
    new_context = (1 - mix) * new_context + mix * layer_norm(new_context)
```

**2. Per-Dimension Variance Tracking (Diversity Enforcement)**
```python
# EMA-based variance tracking (æŒ‡æ•°å¹³å‡çš„ - True Online Learning)
if self.context_mean_ema is None:
    # Initialize
    self.context_mean_ema = new_context_flat.detach()
    self.context_var_ema = torch.ones_like(new_context_flat)
else:
    # Update mean (EMA)
    self.context_mean_ema = (
        self.ema_momentum * self.context_mean_ema +
        (1 - self.ema_momentum) * new_context_flat
    )

    # Update variance (EMA)
    deviation = new_context_flat - self.context_mean_ema
    self.context_var_ema = (
        self.ema_momentum * self.context_var_ema +
        (1 - self.ema_momentum) * (deviation ** 2)
    )

    # Diversity loss: penalize low variance
    diversity_loss = 1.0 / (self.context_var_ema.mean() + 1e-6)
```

Benefits:
- **High Effective Rank**: Achieves **686.09/768 (89.3%)** on 5000-token training data
- **True Online Learning**: Only 6KB memory (mean + variance), no history storage
- **Fast**: 1.55x faster than covariance matrix approach
- **Memory Efficient**: 384x less memory than covariance matrix (6KB vs 2,307KB)
- **Scalable**: Performance independent of sequence length

### Two-Phase Training

**Phase 1: Fixed-Point Learning with Diversity Regularization**
- Contexts converge through iterative refinement
- LayerNorm prevents value explosion in residual connections
- **Per-dimension variance tracking** enforces high dimensional diversity (89.3% Effective Rank)
- **EMA-based (æŒ‡æ•°å¹³å‡çš„)** - true online learning with O(1) memory
- Gradient clipping ensures training stability
- Early stopping based on convergence rate (95% of tokens)

**Phase 2: Token Prediction** (Optional)
- Standard next-token prediction
- Uses fixed contexts from Phase 1
- Optional context freezing

## Development Guidelines

See `CLAUDE.md` for:
- Design principles and philosophy
- Token-wise vs batch normalization rationale
- Object-oriented architecture patterns
- Code quality standards

## Current Status

**Recent Breakthrough (2025-11-24):**
- âœ… **89.3% Effective Rank achieved** using LayerNorm + per-dimension variance tracking (EMA)
- âœ… **True online learning** implemented - only 6KB memory, no history storage
- âœ… **384x memory reduction** compared to covariance matrix approach
- âœ… **1.55x faster** than covariance matrix approach
- âœ… Stable training with no value explosion
- âœ… Comparative study completed: variance tracking > covariance matrix

**Design Evolution:**
1. **Past 10 Contexts** (2025-11-23): 80-90% Effective Rank, but O(n) memory
2. **Covariance Matrix EMA** (2025-11-24): Theoretically rigorous but heavy (2,307KB, slower)
3. **Per-Dimension Variance EMA** (2025-11-24, **ADOPTED**): Best of all worlds

**Working:**
- âœ… High dimensional diversity (Effective Rank: 686.09/768 = 89.3%)
- âœ… Clean CVFPLayer architecture with LayerNorm
- âœ… EMA-based variance tracking for diversity enforcement
- âœ… True online learning (æŒ‡æ•°å¹³å‡çš„)
- âœ… Two-phase training pipeline
- âœ… Flexible data loading
- âœ… Gradient clipping for stability
- âœ… GPT-2 pre-trained embeddings (768-dim, frozen)

**Next Steps:**
- ğŸ¯ Scale to larger datasets (10k+ tokens)
- ğŸ¯ Phase 2 token prediction evaluation with multi-output architecture
- ğŸ¯ Perplexity and generation quality assessment
- ğŸ¯ GPU acceleration (10-20x speedup available with CUDA)

## License

MIT
