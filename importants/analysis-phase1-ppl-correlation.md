# Phase 1 指標から Phase 2 PPL を予測する分析 (2025-11-30)

## 概要

Phase 1（CVFP固定点学習）の指標から、Phase 2（トークン予測）の最終PPLを予測できるかを分析。

## 収集データ

26件の実験データを分析（v1, v2, v3, v4, matrix実験）

### データ一覧（α値付き）

**注**: α値は各設定の全サンプルサイズからのスケーリング係数（設定ごとに1つ）

| Config | Samples | α | P1 Iter | Train ER | Val ER | Train PPL | Val PPL | Val Acc |
|--------|---------|------|---------|----------|--------|-----------|---------|---------|
| 1L_768d_1tok (v1) | 50-500 | **-0.546** | 40 | 77.9-78.6% | 77.5-77.6% | 108-171 | 198-684 | 17-23% |
| 1L_768d_1tok (v2) | 50-500 | -0.476 | 23-25 | 79.7-80.3% | 79.1-79.3% | 66-94 | 196-576 | 18-23% |
| 1L_768d_2tok (v3) | 50-800 | -0.466 | 23-28 | 81.9-82.5% | 81.3-81.5% | 75-92 | 168-592 | 18-24% |
| 1L_1200d_1tok (v1) | 50-500 | -0.513 | 40 | 73.2-73.9% | 72.4-72.6% | 101-155 | 199-639 | 17-23% |
| 1L_1200d_1tok (v2) | 50-500 | -0.485 | 29-31 | 76.2-76.9% | 75.4-75.7% | 81-101 | 201-601 | 18-23% |
| 1L_1537d_1tok (v1) | 50-500 | -0.510 | 40 | 69.6-70.5% | 68.6-68.9% | 98-161 | 198-633 | 17-23% |
| 1L_1537d_1tok (v2) | 50-500 | -0.472 | 32-34 | 73.4-74.1% | 72.4-72.8% | 79-98 | 202-589 | 18-23% |
| 1L_1085d_1tok (v4) | 50-800 | -0.440 | 60 | 71.7-72.2% | 70.8-71.0% | 91-106 | 180-599 | 18-24% |

### 設定別サマリー（α値とVal ERの関係）

| Config | α | Best Val ER | Best PPL | 備考 |
|--------|------|-------------|----------|------|
| 1L_768d_1tok (v1) | **-0.546** | 77.5% | 198.2 | α最良、ER中程度 |
| 1L_768d_1tok (v2) | -0.476 | **79.2%** | 196.3 | ER向上、α緩和 |
| 1L_768d_2tok (v3) | -0.466 | **81.3%** | **168.0** | ER最高、PPL最良 |
| 1L_1200d_1tok (v1) | -0.513 | 72.4% | 199.5 | - |
| 1L_1200d_1tok (v2) | -0.485 | 75.6% | 201.1 | - |
| 1L_1537d_1tok (v1) | -0.510 | 68.6% | 198.3 | ER最低 |
| 1L_1537d_1tok (v2) | -0.472 | 72.6% | 202.3 | - |
| 1L_1085d_1tok (v4) | -0.440 | 70.8% | 180.0 | 次元増加効果薄い |

## 観察された傾向

### 0. α値と Val ER の関係（重要な発見）

**散布図データ**:

| Config | α | Val ER | 相関パターン |
|--------|------|--------|-------------|
| 1L_768d_1tok (v1) | -0.546 | 77.5% | α急峻・ER中 |
| 1L_768d_1tok (v2) | -0.476 | 79.2% | α緩和・ER向上 |
| 1L_768d_2tok (v3) | -0.466 | 81.3% | α緩和・ER最高 |
| 1L_1200d_1tok (v1) | -0.513 | 72.4% | α中・ER低 |
| 1L_1200d_1tok (v2) | -0.485 | 75.6% | α緩和・ER向上 |
| 1L_1537d_1tok (v1) | -0.510 | 68.6% | α中・ER最低 |
| 1L_1537d_1tok (v2) | -0.472 | 72.6% | α緩化・ER向上 |
| 1L_1085d_1tok (v4) | -0.440 | 70.8% | α最緩・ER低 |

**相関分析**:

```
α値とVal ERの相関: 正の相関（ERが高いほどαが緩やか）

  Val ER ↑ → α が 0 に近づく（緩やかなスケーリング）
  Val ER ↓ → α が負に大きくなる（急峻なスケーリング）
```

**解釈**:

1. **v1→v2の変化**: 同一context_dimで dist_reg_weight を 0.8→0.9 に変更
   - Val ER: +1.7~4.0% 向上
   - α値: +0.04~0.07 緩和（悪化）
   - **トレードオフ**: 多様性↑ ↔ スケーリング効率↓

2. **768d vs 1200d/1537d**:
   - 768d: ER高い（77-81%）、α値は設定依存
   - 1200d/1537d: ER低い（69-76%）、α値も中程度
   - **768dが最もバランスが良い**

3. **2トークン入力の効果**:
   - Val ER: 79.2% → 81.3%（+2.1%）
   - α値: -0.476 → -0.466（+0.01、ほぼ同等）
   - **ERを上げてもαを維持できている**

**結論**:
- **αとERはトレードオフの関係にある**（多様性を上げるとスケーリング効率が下がる傾向）
- **ただし、2トークン入力はこのトレードオフを緩和**できている
- **最終PPLで評価すると、ER高い設定が有利**（αの緩和より絶対性能が重要）

### 0.5 αのデータ量依存性（スライディングウィンドウ分析）

**v3実験（1L_768d_2tok）でのα推移**:

サンプル数を増やしたときのα値の変化を4点ウィンドウで分析。

| Window | Samples | Tokens | α | Val ER (平均) | Val PPL範囲 |
|--------|---------|--------|------|---------------|-------------|
| 1 | 50-400 | 63K-473K | **-0.504** | 81.4% | 211-592 |
| 2 | 100-800 | 123K-949K | **-0.432** | 81.3% | 168-400 |

**各サンプルサイズでの詳細**:

| Samples | Tokens | Val ER | Val PPL | ウィンドウ |
|---------|--------|--------|---------|-----------|
| 50 | 62,891 | 81.5% | 591.7 | W1のみ |
| 100 | 122,795 | 81.3% | 400.3 | W1, W2 |
| 200 | 240,132 | 81.3% | 296.8 | W1, W2 |
| 400 | 473,429 | 81.4% | 211.0 | W1, W2 |
| 800 | 948,524 | 81.3% | 168.0 | W2のみ |

**α値の変化**:
```
Window 1 → Window 2:
  α: -0.504 → -0.432
  変化: +0.072 (+14.3%)
  傾向: ↑ DEGRADING（スケーリング効率悪化）
```

**重要な発見**:

1. **Val ERはほぼ一定（81.3-81.5%）**: サンプル数が増えてもERは安定
2. **αは悪化（-0.504 → -0.432）**: データ量増加でスケーリング効率が低下
3. **PPLは改善（592 → 168）**: 絶対性能は向上

**解釈**:
- ERが一定なのにαが悪化 → **モデルキャパシティの限界**を示唆
- 1層・768次元では、データ量増加の恩恵を十分に受けられない
- **対策案**: レイヤー数増加（2L, 3L）でキャパシティ拡大

### 1. Val ER と Val PPL の関係（最重要）

**同一サンプル数での比較（500サンプル以上）**:

| Config | Val ER | Val PPL | 相関 |
|--------|--------|---------|------|
| 768d (v1) | 77.5% | 198.2 | 基準 |
| 768d (v2) | 79.2% | 196.3 | ER↑ → PPL↓ |
| 768d 2tok (v3, 800samples) | 81.3% | 168.0 | ER↑↑ → PPL↓↓ |
| 1200d (v2) | 75.6% | 201.1 | ER↓ → PPL↑ |
| 1537d (v2) | 72.6% | 202.3 | ER↓↓ → PPL↑ |

**結論**: **Val ER が高いほど Val PPL が低い（良い）**

### 2. P1 収束イテレーション数と性能

| P1 Iter | 設定例 | Val PPL | 傾向 |
|---------|--------|---------|------|
| 23-25 | 768d v2/v3 | 168-196 | 最良 |
| 29-32 | 1200d/1537d v2 | 201-202 | やや悪い |
| 40 | v1全般（打ち切り） | 198-199 | 中程度 |

**結論**: **早く収束するほど良い結果になる傾向**
- ただし v1 は max_iterations=40 で打ち切りのため単純比較は困難

### 3. context_dim と Val ER の関係

| context_dim | Val ER (v2) | 変化 |
|-------------|-------------|------|
| 768 | 79.2% | 最高 |
| 1200 | 75.6% | -3.6% |
| 1537 | 72.6% | -6.6% |

**結論**: **context_dim が大きいほど Val ER が低下**
- 次元を有効活用できていない
- 768d が最も効率的

### 4. num_input_tokens と Val ER の関係

| input_tokens | Val ER | Val PPL |
|--------------|--------|---------|
| 1 | 79.2% | 196.3 |
| 2 | 81.3% | 168.0 |

**結論**: **2トークン入力で ER と PPL が両方改善**

## 予測可能性の評価

### 強い相関が見られる指標

1. **Val ER → Val PPL**: 負の相関（ER高い→PPL低い）
   - 同一設定内で特に強い相関
   - 異なる設定間でも傾向は維持
   - **最も信頼できる予測指標**

2. **Train ER → Val ER**: 強い正の相関
   - 差は常に1-2%程度
   - Train ER で Val ER を予測可能

### 弱い/複雑な相関

1. **P1 Iter → Val PPL**: 単純な相関なし
   - 早期収束は良い傾向だが、打ち切りの影響で解釈困難

2. **Train PPL → Val PPL**: サンプル数に依存
   - 同一設定・サンプル数では相関あり
   - 異なるサンプル数では汎化ギャップが変動

## 予測式の候補

### 単純モデル: Val ER ベース

観察データから近似:
```
Val PPL ≈ 500 - 4 × Val_ER (%)

例: Val ER = 81% → PPL ≈ 500 - 324 = 176 (実測: 168)
例: Val ER = 79% → PPL ≈ 500 - 316 = 184 (実測: 196)
```

誤差は約10-15%程度

### より精密なモデル（スケーリング則込み）

```
log(Val PPL) = α × log(tokens) + β × Val_ER + γ

推定係数:
- α ≈ -0.46 ~ -0.55（スケーリング指数）
- β ≈ -0.02（ER 1%あたりの効果）
- γ ≈ 定数項（設定依存）
```

## 結論

### Phase 1 から予測可能なこと

| 予測対象 | 予測指標 | 信頼度 |
|----------|----------|--------|
| Val ER | Train ER | 高（差は1-2%） |
| Val PPL相対順位 | Val ER | 高（ER高い→PPL低い） |
| 収束品質 | P1 Iter | 中（早い=良い傾向） |

### 予測困難なこと

1. 異なるサンプル数間のPPL絶対値比較（スケーリング則が必要）
2. 異なる設定間の絶対値比較（context_dim, layers等）

### 実用的な判断基準

**Phase 1 完了時点での品質判定**:

| Val ER | 判定 | 期待される結果 |
|--------|------|---------------|
| > 80% | 🟢 良好 | 良好な結果が期待できる |
| 75-80% | 🟡 中程度 | 標準的な結果 |
| < 75% | 🔴 要検討 | 設定見直しを推奨 |

**収束速度の目安**:

| P1 Iter | 判定 | 解釈 |
|---------|------|------|
| 23-25 | 🟢 最適 | 効率的な収束 |
| 26-30 | 🟡 普通 | 許容範囲 |
| 30+ | 🔴 遅い | 設定改善の余地あり |

## 活用例

### Phase 1 完了時のチェックリスト

1. **Val ER を確認**
   - 80%以上なら Phase 2 に進む
   - 75%未満なら設定見直し

2. **収束イテレーション数を確認**
   - 25以下なら良好
   - 30以上なら `dist_reg_weight` や `phase1_max_iterations` を調整

3. **Train ER と Val ER の差を確認**
   - 2%以内なら汎化良好
   - 5%以上なら過学習の兆候

### 早期打ち切りの判断

Phase 1 の途中で以下の兆候があれば打ち切り検討:
- Iter 20 で Val ER < 70%
- 収束率が Iter 15 以降も上昇しない
- CVFP loss が減少しない

## ログファイル参照

- v1実験: `importants/logs/1130_context_dim/`
- v2実験: `importants/logs/1130_v2/`
- v3実験: `importants/logs/1130_v3/`
- v4実験: `importants/logs/1130_v4/`
- Matrix実験: `importants/logs/summary.json`
