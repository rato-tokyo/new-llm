# Scaling Law Analysis

**最終更新**: 2025-12-03

---

## 結論サマリー

### ベストフィットモデル: 飽和モデル（Saturation Model）

```
PPL = PPL_min + A × n^(-a)
```

| 構成 | PPL_min | 1600 samples PPL | R² |
|------|---------|------------------|-----|
| 2-block (p=0) | **95.4** | 127.4 | 0.9995 |
| 2-block (p=1) | ~85-90 | 118.2 | - |
| 2-block (p=2) | **87.3** | 114.7 | 0.9985 |

**重要な発見**:
1. **飽和モデルが最適**（AIC最小、R²最高）
2. **理論限界値 PPL_min が存在**（データ増加では改善不可）
3. **prev_context_steps で限界値自体が改善**

---

## 1. スケーリングモデル比較

### 3つのモデル

| Model | 式 | パラメータ数 | 特徴 |
|-------|-----|------------|------|
| Power Law | `PPL = A × n^(-a)` | 2 | 理論限界なし（非現実的） |
| **Saturation** | `PPL = PPL_min + A × n^(-a)` | 3 | **有限の理論限界** |
| Exp Decay | `PPL = PPL_min + A × exp(-b × n^c)` | 4 | 過学習しやすい |

### AIC比較（2-block, p=0, 5点データ）

| Rank | Model | AIC | PPL_min | R² |
|------|-------|-----|---------|-----|
| **1** | **Saturation** | **7.12** | **95.4** | **0.9995** |
| 2 | Exp Decay | 11.83 | 109.7 | 0.9992 |
| 3 | Power Law | 26.65 | N/A | 0.9652 |

**AICが最も低い飽和モデルが最適**

---

## 2. 飽和モデルの詳細

### パラメータ（2-block, p=0）

```
PPL = 95.4 + 10000 × n^(-0.778)

PPL_min = 95.4   # 理論限界値
A = 10000        # スケール係数
a = 0.778        # 減衰指数
```

### 予測精度

| Samples | Actual | Predicted | Error |
|---------|--------|-----------|-------|
| 200 | 258.3 | 257.1 | -0.5% |
| 400 | 187.6 | 189.7 | +1.1% |
| 800 | 150.5 | 150.3 | -0.1% |
| 1600 | 127.4 | 127.4 | +0.0% |
| 3200 | 114.8 | 114.0 | -0.7% |

**全サンプルサイズで誤差1.1%以内**

### 外挿予測検証

4点データ（200-1600）のみでフィッティングし、3200サンプルを予測：

| Model | 予測値 | 実績値 | 誤差 |
|-------|--------|--------|------|
| **Saturation** | **113.4** | **114.8** | **-1.2%** |
| Exp Decay | 119.2 | 114.8 | +3.8% |

**飽和モデルは外挿でも高精度**

---

## 3. 構成別の理論限界値

### prev_context_steps の効果

| 構成 | combined_dim | 1600 PPL | PPL_min | PPL_min改善 |
|------|--------------|----------|---------|-------------|
| 2-block (p=0) | 512 | 127.4 | **95.4** | baseline |
| 2-block (p=1) | 1024 | 118.2 | ~85-90 | ~-10% |
| 2-block (p=2) | 1536 | 114.7 | **87.3** | -8.5% |

**prev_contextで理論限界値自体が低下**

### 将来予測（2-block, p=0）

| Samples | 予測 PPL | PPL_min との差 |
|---------|---------|---------------|
| 3,200 | 114.0 | 18.6 |
| 6,400 | 107.1 | 11.7 |
| 12,800 | 101.4 | 6.0 |
| 25,600 | 97.9 | 2.5 |
| ∞ | 95.4 | 0 |

---

## 4. 飽和モデルの物理的解釈

飽和モデルは以下の物理的解釈を持つ：

1. **モデル容量の限界**: ContextBlock + TokenBlock の表現力には上限がある
2. **データの本質的複雑性**: 言語モデルには予測不可能な部分がある
3. **Effective Rankの飽和**: コンテキスト空間の有効次元に上限がある

これらの要因により、データ量を増やしても特定の値以下にはPPLが下がらない。

---

## 5. 実験データ

### 2-block (p=0) 構成

| Samples | Tokens | Val PPL | Val Acc | ER% |
|---------|--------|---------|---------|-----|
| 200 | 240,132 | 258.3 | 20.5% | 78.0% |
| 400 | 473,429 | 187.6 | 22.0% | 78.4% |
| 800 | 948,524 | 150.5 | 23.5% | 77.2% |
| 1600 | 1,920,992 | 127.4 | 24.5% | 78.1% |
| 3200 | 3,864,746 | 114.8 | 25.0% | 77.9% |

### 2-block (p=2) 構成

| Samples | Tokens | Val PPL | Val Acc | ER% |
|---------|--------|---------|---------|-----|
| 200 | 240,132 | 256.0 | 21.0% | 70.7% |
| 400 | 473,429 | 178.7 | 22.9% | 70.8% |
| 800 | 948,524 | 142.4 | 24.6% | 70.4% |
| 1600 | 1,920,992 | 114.7 | 25.7% | 70.9% |

---

## 6. 改善の方向性

### PPL < 100 達成の条件

現在のPPL_min（p=2で87.3）から考えると：

1. **データ増加**: 6400+ samplesで~96に到達可能
2. **prev_context_steps増加**: p=3以上で限界値さらに低下の可能性
3. **ブロック数増加**: 3-block, 4-blockで表現力向上
4. **アーキテクチャ変更**: 新しい構造の探索

### 注意: 効果のない設定

- **interval=8 などの大きなinterval**: 悪化（PPL +7.7%）
- **context_dim増加のみ**: 効率が低い（ER%低下）

---

## 分析スクリプト

```bash
# サンプルサイズ探索
python3 scripts/experiment_multiblock_sample_search.py --start 200 --end 3200

# スケーリングモデル分析
python3 scripts/analyze_scaling_models.py
```

---

*Last Updated: 2025-12-03*
