# New-LLM Algorithm Summary

**å¤–éƒ¨Claudeç›¸è«‡ç”¨ã‚µãƒãƒªãƒ¼ - å‰æçŸ¥è­˜ä¸è¦ç‰ˆ**

---

## ğŸ¯ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦

New-LLMã¯ã€**CVFP (Context Vector Fixed-Point)** ã¨ã„ã†æ–°ã—ã„æ‰‹æ³•ã‚’ç”¨ã„ãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã™ã€‚å¾“æ¥ã®Transformerã¨ã¯ç•°ãªã‚Šã€å›ºå®šç‚¹å­¦ç¿’ã«ã‚ˆã‚‹æ–‡è„ˆãƒ™ã‚¯ãƒˆãƒ«ã®åæŸã‚’åˆ©ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆç†è§£ã¨ç”Ÿæˆã‚’è¡Œã„ã¾ã™ã€‚

---

## ğŸ§  æ ¸å¿ƒã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ : CVFP (Context Vector Fixed-Point)

### åŸºæœ¬åŸç†

**å›ºå®šç‚¹ (Fixed-Point) ã¨ã¯ï¼Ÿ**
- é–¢æ•° f ã«ãŠã„ã¦ã€f(x) = x ã¨ãªã‚‹ç‚¹ã‚’ã€Œå›ºå®šç‚¹ã€ã¨å‘¼ã¶
- New-LLMã§ã¯ã€æ–‡è„ˆãƒ™ã‚¯ãƒˆãƒ« c ãŒç¹°ã‚Šè¿”ã—å‡¦ç†ã§åæŸã™ã‚‹ç‚¹ã‚’å­¦ç¿’

**æ•°å¼è¡¨ç¾**:
```
c_{t+1} = c_t + FNN(concat(c_t, token_embed))
```
- c_t: ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ t ã§ã®æ–‡è„ˆãƒ™ã‚¯ãƒˆãƒ«
- token_embed: ãƒˆãƒ¼ã‚¯ãƒ³ã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ï¼ˆGPT-2äº‹å‰å­¦ç¿’æ¸ˆã¿ã€768æ¬¡å…ƒï¼‰
- FNN: Feed-Forward Networkï¼ˆæ®‹å·®æ¥ç¶šä»˜ãï¼‰

---

## ğŸ“ ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼ˆåˆ†é›¢ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ Eæ¡ˆ - ãƒ¬ã‚¤ãƒ¤ãƒ¼å¯¾å¿œç‰ˆï¼‰

### ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¦‚è¦

ContextBlockã¨TokenBlockã‚’**ç‰©ç†çš„ã«åˆ†é›¢**ã—ã€**TokenBlock Layer i ãŒ ContextBlock Layer i ã®å‡ºåŠ›ã‚’å‚ç…§**ã™ã‚‹ã€‚

```
ContextBlock (Phase 1ã§å­¦ç¿’ã€Phase 2ã§freeze):
  Layer 1: [context_0, token_embed] â†’ context_1
  Layer 2: [context_1, token_embed] â†’ context_2
  Layer 3: [context_2, token_embed] â†’ context_3 (= C*)

TokenBlock (Phase 2ã§å­¦ç¿’):
  Layer 1: [context_1, token_embed] â†’ token_1
  Layer 2: [context_2, token_1]     â†’ token_2
  Layer 3: [context_3, token_2]     â†’ token_3 (= token_out)
```

**é‡è¦**: TokenBlock Layer i ã¯ ContextBlock Layer i ã®å‡ºåŠ›ã‚’å‚ç…§ã™ã‚‹

### æ¯”è¼ƒè¡¨

| æ¡ˆ | TokenBlockã¸ã®contextå…¥åŠ› | ç‰¹å¾´ |
|----|--------------------------|------|
| **Aæ¡ˆï¼ˆæ—§å®Ÿè£…ï¼‰** | å…¨ãƒ¬ã‚¤ãƒ¤ãƒ¼ã§åŒã˜ context_3 (C*) | ã‚·ãƒ³ãƒ—ãƒ« |
| **Dæ¡ˆ** | TokenBlockå†…ã§contextã‚‚æ®‹å·®æ›´æ–° | è¡¨ç¾åŠ›é«˜ã„ãŒã€C*ãŒå¤‰è³ª |
| **Eæ¡ˆï¼ˆæ¡ç”¨ï¼‰** | Layer i ã§ ContextBlock Layer i ã®å‡ºåŠ› | æ®µéšçš„æ–‡è„ˆã€C*ç¶­æŒ |

### 1. ContextLayerï¼ˆæ–‡è„ˆå‡¦ç†å°‚ç”¨ï¼‰

```
Input: context [768-dim] + token_embed [768-dim] (å…¥åŠ›ã®ã¿)
       â†“
FNN: Linear(context_dim + embed_dim â†’ context_dim) + ReLU
       â†“
delta_context [768-dim]
       â†“
Residual: new_context = context + delta_context
       â†“
Output: new_context [768-dim] (contextã®ã¿å‡ºåŠ›)
```

### 2. TokenLayerï¼ˆãƒˆãƒ¼ã‚¯ãƒ³å‡¦ç†å°‚ç”¨ï¼‰

```
Input: context_i [768-dim] (ContextBlock Layer i ã®å‡ºåŠ›) + token [768-dim]
       â†“
FNN: Linear(context_dim + embed_dim â†’ embed_dim) + ReLU
       â†“
delta_token [768-dim]
       â†“
Residual: new_token = token + delta_token
       â†“
Output: new_token [768-dim] (tokenã®ã¿å‡ºåŠ›)
```

### 3. LLMãƒ¢ãƒ‡ãƒ«å…¨ä½“æ§‹é€ ï¼ˆEæ¡ˆï¼‰

```
Token IDs
    â†“
Token Embedding (GPT-2 pretrained, frozen)
    â†“ [embedding normalized]
Context = zero-vector (åˆæœŸåŒ–)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ContextBlock (Phase 1ã§å­¦ç¿’ã€Phase 2ã§freeze)                      â”‚
â”‚    Layer 1: context_0 + token_embed â†’ context_1 â”€â”€â”€â”€â”€â”             â”‚
â”‚    Layer 2: context_1 + token_embed â†’ context_2 â”€â”€â”€â”€â”â”‚             â”‚
â”‚    Layer 3: context_2 + token_embed â†’ context_3 â”€â”€â”€â”â”‚â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”¼â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                     â”‚â”‚â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”¼â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TokenBlock (Phase 2ã§å­¦ç¿’)                        â”‚â”‚â”‚             â”‚
â”‚    Layer 1: context_1 + token_embed â†’ token_1  â†â”€â”€â”€â”˜â”‚â”‚             â”‚
â”‚    Layer 2: context_2 + token_1     â†’ token_2  â†â”€â”€â”€â”€â”˜â”‚             â”‚
â”‚    Layer 3: context_3 + token_2     â†’ token_3  â†â”€â”€â”€â”€â”€â”˜             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“ token_3 (= token_out)
Output Head: Linear(embed_dim â†’ vocab_size)
    â†“
Next Token Prediction
```

### Eæ¡ˆã®åˆ©ç‚¹

1. **æ®µéšçš„ãªæ–‡è„ˆæƒ…å ±**: æµ…ã„ãƒ¬ã‚¤ãƒ¤ãƒ¼ã§ã¯æµ…ã„æ–‡è„ˆã€æ·±ã„ãƒ¬ã‚¤ãƒ¤ãƒ¼ã§ã¯æ·±ã„æ–‡è„ˆã‚’ä½¿ç”¨
2. **C*ã®ä¿æŒ**: ContextBlockã¯frozenãªã®ã§ã€Phase 1ã§å­¦ç¿’ã—ãŸæ–‡è„ˆè¡¨ç¾ãŒç¶­æŒã•ã‚Œã‚‹
3. **Transformerã¨ã®é¡ä¼¼æ€§**: å„ãƒ¬ã‚¤ãƒ¤ãƒ¼ã§ç•°ãªã‚‹æ·±ã•ã®è¡¨ç¾ã‚’å‚ç…§
4. **ç‰©ç†çš„åˆ†é›¢ç¶­æŒ**: ContextBlockã¨TokenBlockã¯åˆ¥ã®é‡ã¿è¡Œåˆ—ã®ã¾ã¾

### åˆ¶ç´„æ¡ä»¶

- `context_layers == token_layers` ãŒ**å¿…é ˆ**ï¼ˆãƒ¬ã‚¤ãƒ¤ãƒ¼æ•°ãŒä¸€è‡´ã—ã¦ã„ãªã„ã¨å¯¾å¿œã§ããªã„ï¼‰
- ç¾åœ¨ã®è¨­å®š: `context_layers = 3`, `token_layers = 3` â†’ OK

---

## ğŸ”„ 2æ®µéšå­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹

### Phase 1: CVFPå›ºå®šç‚¹å­¦ç¿’ï¼ˆä¸¦åˆ—å‡¦ç†ç‰ˆï¼‰

**ç›®çš„**: æ–‡è„ˆãƒ™ã‚¯ãƒˆãƒ«ãŒåæŸã™ã‚‹ã€Œå›ºå®šç‚¹ã€ã‚’å­¦ç¿’

**ãƒ—ãƒ­ã‚»ã‚¹**:

1. **Iteration 0ï¼ˆã‚·ãƒ¼ã‚±ãƒ³ã‚·ãƒ£ãƒ«å‡¦ç†ï¼‰**:
   - ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¼ãƒ­ã‹ã‚‰é–‹å§‹ã—ã€å…¨ãƒˆãƒ¼ã‚¯ãƒ³ã‚’é †æ¬¡å‡¦ç†
   - å‡ºåŠ›ã‚’ `previous_contexts` ã¨ã—ã¦ä¿å­˜
   - **å­¦ç¿’ãªã—**ï¼ˆé †ä¼æ’­ã®ã¿ï¼‰

2. **Iteration 1ï½10ï¼ˆä¸¦åˆ—å‡¦ç†ï¼‰**:
   - ç›®çš„: å›ºå®šç‚¹ã¸ã®åæŸï¼ˆ23å€é«˜é€ŸåŒ–ï¼‰
   - Token i ã«ã¯ `previous_contexts[i-1]` ã‚’ä½¿ç”¨ï¼ˆ1ãƒˆãƒ¼ã‚¯ãƒ³åˆ†ã®ãšã‚Œï¼‰
   - å…¨ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ãƒãƒƒãƒå‡¦ç†ã§ä¸¦åˆ—è¨ˆç®—
   - CVFPæå¤±ã§å­¦ç¿’ã—ã€`previous_contexts`ã‚’æ›´æ–°

**æå¤±é–¢æ•°**:

```python
# CVFPæå¤±: å‰å›ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã®å·®ï¼ˆå›ºå®šç‚¹ã¸ã®åæŸï¼‰
cvfp_loss = MSE(contexts, previous_contexts)

# å¤šæ§˜æ€§æå¤±: å…¨ãƒˆãƒ¼ã‚¯ãƒ³ã®å¹³å‡ã‹ã‚‰ã®åå·®ã‚’æœ€å¤§åŒ–
diversity_loss = -â€–contexts - mean(contexts)â€–â‚‚ / num_tokens

# ç·åˆæå¤±ï¼ˆä¸¦åˆ—ç‰ˆæœ€é©è¨­å®š: dist_reg_weight=0.9ï¼‰
total_loss = 0.1 * cvfp_loss + 0.9 * diversity_loss

# æ›´æ–°
previous_contexts = contexts.detach()
```

**é‡è¦ãƒã‚¤ãƒ³ãƒˆ**:
- âœ… **CVFPæå¤±ã¯å‰å›ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨æ¯”è¼ƒ**: å›ºå®šç‚¹ = å¤‰åŒ–ãŒãªããªã‚‹ç‚¹
- âœ… **previous_contextsã¯æ¯ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ›´æ–°**: ã“ã‚ŒãŒæ­£ã—ã„å®Ÿè£…
- âœ… **å¿…é ˆ**: ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–“ã§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å¼•ãç¶™ã
  - `context = previous_contexts[-1]` ï¼ˆã‚¼ãƒ­ãƒªã‚»ãƒƒãƒˆç¦æ­¢ï¼‰

**æ€§èƒ½ï¼ˆä¸¦åˆ—ç‰ˆï¼‰**:
- Effective Rank: 55.9% (429/768æ¬¡å…ƒ) - æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿
- å‡¦ç†æ™‚é–“: ç´„11ç§’ï¼ˆã‚·ãƒ¼ã‚±ãƒ³ã‚·ãƒ£ãƒ«ç‰ˆ265ç§’ã®23å€é«˜é€Ÿï¼‰
- åæŸç‡: 27.2%ï¼ˆå¤šæ§˜æ€§å„ªå…ˆã®ãŸã‚ä½ã‚ã ãŒæ­£å¸¸ï¼‰

### Phase 2: Next-Token Predictionï¼ˆãƒˆãƒ¼ã‚¯ãƒ³äºˆæ¸¬ï¼‰- Eæ¡ˆ

**ç›®çš„**: Phase 1ã§å­¦ç¿’ã—ãŸæ–‡è„ˆè¡¨ç¾ã‚’ä½¿ç”¨ã—ã¦æ¬¡ãƒˆãƒ¼ã‚¯ãƒ³äºˆæ¸¬

#### Eæ¡ˆã®ç‰¹å¾´

- **ContextBlock**: frozenï¼ˆé‡ã¿å›ºå®šï¼‰
- **TokenBlock**: å­¦ç¿’
- **token_output**: å­¦ç¿’
- **æå¤±**: CrossEntropyï¼ˆæ¬¡ãƒˆãƒ¼ã‚¯ãƒ³äºˆæ¸¬ï¼‰ã®ã¿
- **Eæ¡ˆ**: TokenBlock Layer i ã¯ ContextBlock Layer i ã®å‡ºåŠ›ã‚’å‚ç…§

**ãªãœ`context_i`ãŒä¿è¨¼ã•ã‚Œã‚‹ã‹**:
- ContextBlockã®é‡ã¿ãŒfrozenã•ã‚Œã¦ã„ã‚‹
- åŒã˜å…¥åŠ› = åŒã˜å‡ºåŠ›ï¼ˆæ±ºå®šçš„ãªé–¢æ•°ï¼‰
- C*ã®äº‹å‰è¨ˆç®—ã¯**ä¸è¦**
- context_stability_lossã‚‚**ä¸è¦**

#### å‡¦ç†ãƒ•ãƒ­ãƒ¼ï¼ˆEæ¡ˆï¼‰

```python
# Phase 2ã®è¨“ç·´ãƒ«ãƒ¼ãƒ—ï¼ˆEæ¡ˆï¼‰
context = torch.zeros(...)  # åˆæœŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ

for token_id in token_ids:
    token_embed = get_embedding(token_id)

    # Step 1: ContextBlockï¼ˆfrozenï¼‰- å„ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®å‡ºåŠ›ã‚’å–å¾—
    with torch.no_grad():
        context_outputs = context_block.forward_with_intermediates(context, token_embed)
        # context_outputs = [context_1, context_2, context_3]

    # Step 2: TokenBlockï¼ˆå­¦ç¿’ï¼‰- å¯¾å¿œã™ã‚‹ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®contextã‚’ä½¿ç”¨
    token_out = token_block.forward_with_contexts(context_outputs, token_embed)

    # Step 3: äºˆæ¸¬
    logits = token_output(token_out)
    loss = CrossEntropy(logits, target)

    # Step 4: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ›´æ–°ï¼ˆæœ€çµ‚ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®å‡ºåŠ›ã‚’ä½¿ç”¨ï¼‰
    context = context_outputs[-1].detach()
```

**å‹¾é…ãƒ•ãƒ­ãƒ¼ï¼ˆEæ¡ˆï¼‰**:
```
å…¥åŠ›: [context_0, token_embed]
         â†“
    ContextBlock Layer 1ï¼ˆfrozenï¼‰â†’ context_1
         â†“                              â†“
    ContextBlock Layer 2ï¼ˆfrozenï¼‰â†’ context_2  â†’  TokenBlock Layer 1ï¼ˆå­¦ç¿’ï¼‰â†’ token_1
         â†“                              â†“                                        â†“
    ContextBlock Layer 3ï¼ˆfrozenï¼‰â†’ context_3  â†’  TokenBlock Layer 2ï¼ˆå­¦ç¿’ï¼‰â†’ token_2
                                        â†“                                        â†“
                                   TokenBlock Layer 3ï¼ˆå­¦ç¿’ï¼‰â†’ token_3
                                                                  â†“
                                                         token_outputï¼ˆå­¦ç¿’ï¼‰
                                                                  â†“
                                                    logits â†’ CrossEntropy
```

**å‹¾é…ã®æµã‚Œ**:
- âŒ `context_i` â†’ ContextBlockï¼ˆfrozenã€å‹¾é…ãªã—ï¼‰
- âœ… `token_i` â†’ TokenBlockï¼ˆå­¦ç¿’ï¼‰
- âœ… `token_output`å±¤ï¼ˆå­¦ç¿’ï¼‰

---

## ğŸ“Š è©•ä¾¡æŒ‡æ¨™

### 1. Effective Rankï¼ˆå¤šæ§˜æ€§æŒ‡æ¨™ï¼‰

**å®šç¾©**: ç‰¹ç•°å€¤åˆ†å¸ƒã®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã‹ã‚‰è¨ˆç®—ã•ã‚Œã‚‹ã€Œå®ŸåŠ¹çš„ãªæ¬¡å…ƒæ•°ã€

```python
# ç‰¹ç•°å€¤ã‹ã‚‰è¨ˆç®—
singular_values = svd(context_matrix)
probabilities = (singular_values / sum(singular_values))
entropy = -sum(p * log(p) for p in probabilities)
effective_rank = exp(entropy) / total_dimensions
```

**è§£é‡ˆ**:
- 100%: å…¨æ¬¡å…ƒãŒå‡ç­‰ã«ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ï¼ˆç†æƒ³çš„ï¼‰
- 55.9%: 768æ¬¡å…ƒä¸­ã€ç´„429æ¬¡å…ƒãŒå®ŸåŠ¹çš„ã«ä½¿ç”¨ï¼ˆä¸¦åˆ—ç‰ˆï¼‰
- <30%: æ¬¡å…ƒãŒåã£ã¦ã„ã‚‹ï¼ˆå¤šæ§˜æ€§ä¸è¶³ï¼‰

### 2. åæŸç‡ï¼ˆConvergence Rateï¼‰

**å®šç¾©**: MSE < threshold ã¨ãªã£ãŸãƒˆãƒ¼ã‚¯ãƒ³ã®å‰²åˆ

```python
token_losses = MSE(context_t, context_{t-1}) per token
converged_tokens = count(token_losses < 0.1)
convergence_rate = converged_tokens / total_tokens
```

**è§£é‡ˆ**:
- ä¸¦åˆ—ç‰ˆ: 27.2% - å¤šæ§˜æ€§å„ªå…ˆã®ãŸã‚ä½ã‚ã ãŒæ­£å¸¸
- 100%: å…¨ãƒˆãƒ¼ã‚¯ãƒ³ãŒåæŸï¼ˆå¤šæ§˜æ€§ã¨ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ï¼‰

### 3. CVFPæå¤±

**å®šç¾©**: å›ºå®šç‚¹ç›®æ¨™ã¨ã®å¹³å‡äºŒä¹—èª¤å·®

```python
cvfp_loss = MSE(contexts, target_contexts)
```

---

## âš¡ ä¸¦åˆ—å‡¦ç†æœ€é©åŒ–

### æ€§èƒ½æ¯”è¼ƒ

| æŒ‡æ¨™ | ã‚·ãƒ¼ã‚±ãƒ³ã‚·ãƒ£ãƒ«ç‰ˆ | ä¸¦åˆ—ç‰ˆ |
|------|----------------|--------|
| Effective Rank | 66.6% | 55.9% |
| å‡¦ç†æ™‚é–“ | 265ç§’ | 11ç§’ |
| é«˜é€ŸåŒ–ç‡ | 1x | **23x** |
| åæŸç‡ | 30.0% | 27.2% |

### ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•

**ä¸¦åˆ—ç‰ˆã®ç‰¹å¾´**:
- âœ… 23å€é«˜é€ŸåŒ–ã«ã‚ˆã‚Šå®Ÿç”¨æ€§ãŒå¤§å¹…å‘ä¸Š
- âœ… 55.9% ERã¯å®Ÿç”¨çš„ãªå¤šæ§˜æ€§ã‚’ç¶­æŒ
- âš ï¸ 1ãƒˆãƒ¼ã‚¯ãƒ³åˆ†ã®æƒ…å ±é…å»¶ï¼ˆToken i ã¯ previous_contexts[i-1] ã‚’ä½¿ç”¨ï¼‰
- âœ… dist_reg_weight=0.9 ã«ã‚ˆã‚Šå¤šæ§˜æ€§å¼·åŒ–ã§è£œå„Ÿ

---

## ğŸš¨ éå»ã®è‡´å‘½çš„ãƒã‚°ã¨æ•™è¨“

### Bug 1: å›ºå®šç‚¹ç›®æ¨™ã®ä¸Šæ›¸ãï¼ˆ2025-11-25ä¿®æ­£ï¼‰

**å•é¡Œ**:
```python
# âŒ é–“é•ã„
Iteration 1: CVFPæå¤± = MSE(contexts_1, contexts_0)
             target = contexts_1  # ç›®æ¨™ã‚’ä¸Šæ›¸ãï¼
Iteration 2: CVFPæå¤± = MSE(contexts_2, contexts_1)  # ç›®æ¨™ãŒå¤‰ã‚ã£ã¦ã„ã‚‹
```

**æ­£ã—ã„å®Ÿè£…**:
```python
# âœ… æ­£è§£
Iteration 0: target = contexts_0  # å›ºå®šä¿å­˜
Iteration 1: CVFPæå¤± = MSE(contexts_1, target)  # å›ºå®šç›®æ¨™
Iteration 2: CVFPæå¤± = MSE(contexts_2, target)  # åŒã˜ç›®æ¨™
```

### Bug 2: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ã‚¼ãƒ­ãƒªã‚»ãƒƒãƒˆï¼ˆ2025-11-24ä¿®æ­£ï¼‰

**å•é¡Œ**:
```python
# âŒ é–“é•ã„: æ¯ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã‚¼ãƒ­ãƒªã‚»ãƒƒãƒˆ
for iteration in range(10):
    context = torch.zeros(...)  # å›ºå®šç‚¹å­¦ç¿’ãŒæ©Ÿèƒ½ã—ãªã„ï¼
```

**æ­£ã—ã„å®Ÿè£…**:
```python
# âœ… æ­£è§£: ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–“ã§å¼•ãç¶™ã
context = torch.zeros(...)  # åˆå›ã®ã¿
for iteration in range(10):
    if iteration > 0:
        context = previous_contexts[-1]  # å‰å›ã®æœ€çµ‚å€¤ã‚’å¼•ãç¶™ã
```

### Bug 3: Phase 2ã§ã®ç‹¬ç«‹å‡¦ç†ï¼ˆ2025-11-24ä¿®æ­£ï¼‰

**å•é¡Œ**:
```python
# âŒ é–“é•ã„: å„ãƒˆãƒ¼ã‚¯ãƒ³ãŒç‹¬ç«‹
for token in tokens:
    context = torch.zeros(...)  # æ–‡è„ˆæƒ…å ±ãŒä¼ã‚ã‚‰ãªã„
```

**æ­£ã—ã„å®Ÿè£…**:
```python
# âœ… æ­£è§£: æ–‡è„ˆä¼æ’­
context = torch.zeros(...)  # æœ€åˆã®ã¿
for token in tokens:
    context = cvfp_forward(token, context)  # æ–‡è„ˆã‚’å¼•ãç¶™ã
```

---

## ğŸ”§ ãƒ‡ãƒ¼ã‚¿ä»•æ§˜

**è¨“ç·´ãƒ‡ãƒ¼ã‚¿**:
- ã‚½ãƒ¼ã‚¹: UltraChat (HuggingFaceH4/ultrachat_200k)
- ã‚µãƒ³ãƒ—ãƒ«æ•°: 50
- ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 6400
- ã‚­ãƒ£ãƒƒã‚·ãƒ¥: `./cache/ultrachat_50samples_128len.pt`

**æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿**:
- ã‚½ãƒ¼ã‚¹: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®æœ€å¾Œ20%ã‹ã‚‰ç”Ÿæˆ
- ãƒˆãƒ¼ã‚¯ãƒ³æ•°: 1280
- ãƒ•ã‚¡ã‚¤ãƒ«: `./data/ultrachat_50samples_val.txt`
- **å¿…é ˆæ¡ä»¶**: å…¨ãƒˆãƒ¼ã‚¯ãƒ³ãŒè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«å­˜åœ¨ã™ã‚‹ã“ã¨

**é‡è¦**: `auto_split` ã¯å³ç¦ï¼ˆã‚¨ãƒ©ãƒ¼ç™ºç”Ÿï¼‰

---

## ğŸ’¡ æ ¸å¿ƒçš„ãªè¨­è¨ˆåŸå‰‡

1. **å›ºå®šç‚¹å­¦ç¿’ã®æœ¬è³ª**:
   - ç›®æ¨™ï¼ˆtarget_contextsï¼‰ã¯çµ¶å¯¾ã«ä¸å¤‰
   - ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–“ã§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¼•ãç¶™ãå¿…é ˆ

2. **Phase 1ã¨Phase 2ã®ä¸€è²«æ€§**:
   - ä¸¡æ–¹ã§æ–‡è„ˆä¼æ’­ãŒå¿…é ˆ
   - Phase 2ã§ã‚¼ãƒ­ãƒªã‚»ãƒƒãƒˆã¯ç¦æ­¢

3. **å¤šæ§˜æ€§ã¨åæŸã®ãƒãƒ©ãƒ³ã‚¹**:
   - ä¸¦åˆ—ç‰ˆ: dist_reg_weight=0.9ï¼ˆå¤šæ§˜æ€§90%, CVFP 10%ï¼‰
   - Effective Rankç¶­æŒãŒæœ€å„ªå…ˆ

4. **å‹¾é…ç®¡ç†**:
   - ãƒˆãƒ¼ã‚¯ãƒ³é–“: `context.detach()`ï¼ˆå‹¾é…é®æ–­ï¼‰
   - Phase 2: Contextå®‰å®šæ€§æå¤±ã§å›ºå®š

---

## ğŸ“ˆ ç¾åœ¨ã®æ€§èƒ½ï¼ˆä¸¦åˆ—ç‰ˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼‰

**Phase 1ï¼ˆæ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ï¼‰**:
- Effective Rank: **55.9%** (429/768æ¬¡å…ƒ)
- å‡¦ç†æ™‚é–“: **ç´„11ç§’** (23å€é«˜é€ŸåŒ–)
- åæŸç‡: 27.2%

**Phase 2ï¼ˆå®Ÿè£…å®Œäº†ï¼‰**:
- æ–‡è„ˆä¼æ’­ã«ã‚ˆã‚‹ä¸€è²«æ€§ç¢ºä¿
- Context + Token Embedäºˆæ¸¬
- æ–‡è„ˆå®‰å®šæ€§æå¤±ã«ã‚ˆã‚‹å›ºå®š

---

## ğŸ“ ã“ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ç‹¬è‡ªæ€§

1. **å›ºå®šç‚¹å­¦ç¿’**: å¾“æ¥ã®Attentionã§ã¯ãªãã€åå¾©åæŸã«ã‚ˆã‚‹æ–‡è„ˆç†è§£
2. **æ®‹å·®æ¥ç¶š**: ResNetã‚¹ã‚¿ã‚¤ãƒ«ã®å®‰å®šã—ãŸå­¦ç¿’
3. **å¤šæ§˜æ€§æ­£å‰‡åŒ–**: æ¬¡å…ƒä½¿ç”¨ã®åã‚Šã‚’é˜²ãæ–°ã—ã„æ‰‹æ³•
4. **2æ®µéšå­¦ç¿’**: æ–‡è„ˆå­¦ç¿’ã¨äºˆæ¸¬ã‚’åˆ†é›¢ã—ãŸåŠ¹ç‡çš„ãªè¨“ç·´
5. **ä¸¦åˆ—å‡¦ç†æœ€é©åŒ–**: 23å€é«˜é€ŸåŒ–ã«ã‚ˆã‚Šå®Ÿç”¨æ€§ã‚’å®Ÿç¾

---

## ğŸ“ ç›¸è«‡æ™‚ã®é‡è¦æƒ…å ±

- **ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**: Eæ¡ˆ - åˆ†é›¢ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼ˆContextBlock 3å±¤ + TokenBlock 3å±¤ã€ãƒ¬ã‚¤ãƒ¤ãƒ¼å¯¾å¿œç‰ˆï¼‰
- **æ¬¡å…ƒ**: context_dim=768, embed_dim=768ï¼ˆGPT-2äº‹å‰å­¦ç¿’åŸ‹ã‚è¾¼ã¿ï¼‰
- **ä¸¦åˆ—ç‰ˆæ€§èƒ½**: 55.9% ERã€11ç§’å‡¦ç†æ™‚é–“ã€23å€é«˜é€ŸåŒ–
- **æœ€é‡è¦è¨­å®š**: dist_reg_weight=0.9ï¼ˆå¤šæ§˜æ€§å„ªå…ˆï¼‰
- **ãƒ‡ãƒ¼ã‚¿è¦æ¨¡**: è¨“ç·´6400ãƒˆãƒ¼ã‚¯ãƒ³ã€æ¤œè¨¼1280ãƒˆãƒ¼ã‚¯ãƒ³
- **å†ç¾æ€§**: ä¹±æ•°ã‚·ãƒ¼ãƒ‰å›ºå®šã«ã‚ˆã‚Šå®Œå…¨ãªå†ç¾æ€§ä¿è¨¼
- **Eæ¡ˆã®ç‰¹å¾´**: TokenBlock Layer i ã¯ ContextBlock Layer i ã®å‡ºåŠ›ã‚’å‚ç…§

### è¨­å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

```python
# config.py
use_separated_architecture = True  # åˆ†é›¢ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ä½¿ç”¨
context_layers = 3                 # ContextBlockã®ãƒ¬ã‚¤ãƒ¤ãƒ¼æ•°
token_layers = 3                   # TokenBlockã®ãƒ¬ã‚¤ãƒ¤ãƒ¼æ•°ï¼ˆcontext_layersã¨åŒã˜å¿…é ˆï¼‰
```

### Eæ¡ˆã®å®Ÿè£…ãƒ¡ã‚½ãƒƒãƒ‰

```python
# ContextBlock
forward_with_intermediates(context, token_embed)  # å„ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®å‡ºåŠ›ã‚’è¿”ã™

# TokenBlock
forward_with_contexts(context_list, token)  # å„ãƒ¬ã‚¤ãƒ¤ãƒ¼ãŒå¯¾å¿œã™ã‚‹contextã‚’ä½¿ç”¨

# LLM
forward_context_with_intermediates(context, token_embed)  # Eæ¡ˆç”¨ContextBlockå‘¼ã³å‡ºã—
forward_token_e(context_list, token_embed)  # Eæ¡ˆç”¨TokenBlockå‘¼ã³å‡ºã—
```

---

**ä½œæˆæ—¥**: 2025-11-26
**Eæ¡ˆæ¡ç”¨**: 2025-11-26
**åˆ†é›¢ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¡ç”¨**: 2025-11-26
**ä¸¦åˆ—å‡¦ç†ç‰ˆ**: å®Œå…¨æ¡ç”¨ï¼ˆ2025-11-25ï¼‰
**ä¸»è¦ãƒ•ã‚¡ã‚¤ãƒ«**: src/models/llm.py, src/trainers/phase1.py, src/trainers/phase2.py
