# アーキテクチャ比較実験結果 (2025-11-29)

## 実験概要

4つのアーキテクチャ設定で、複数サンプル数（50, 100, 200, 500）での性能を比較し、スケーリング則（α値）を算出。

**実験環境**: NVIDIA L4 GPU (22.2GB), Colab

## 結果サマリー

| Config | Phase1 Params | α (slope) | R² | Best PPL | Best Acc | Val ER |
|--------|---------------|-----------|-----|----------|----------|--------|
| baseline | 7.09M | -0.4860 | 0.9895 | 249.3 | 21.3% | 75.2% |
| **input_tokens_2** | 10.63M | -0.4702 | 0.9870 | **198.1** | **22.5%** | **82.4%** |
| context_dim_1152 | 13.29M | **-0.4988** | **0.9963** | 246.9 | 21.4% | 71.0% |
| layers_9 | 10.64M | -0.4818 | 0.9915 | 256.8 | 21.1% | 73.7% |

## 設定詳細

| Config | num_layers | context_dim | num_input_tokens | embed_dim |
|--------|------------|-------------|------------------|-----------|
| baseline | 6 | 768 | 1 | 768 |
| input_tokens_2 | 6 | 768 | 2 | 768 |
| context_dim_1152 | 6 | 1152 | 1 | 768 |
| layers_9 | 9 | 768 | 1 | 768 |

## 詳細結果

### 1. Baseline (6層/768dim/1トークン)

| Samples | Tokens | Val PPL | Val Acc | Val ER |
|---------|--------|---------|---------|--------|
| 50 | 62,891 | 751.4 | 16.8% | 75.2% |
| 100 | 122,795 | 489.8 | 18.5% | 75.2% |
| 200 | 240,132 | 364.6 | 19.3% | 75.5% |
| 500 | 587,970 | 249.3 | 21.3% | 75.2% |

**Scaling Law**: α = -0.4860 (R² = 0.9895)

### 2. Input Tokens 2 (6層/768dim/2トークン)

| Samples | Tokens | Val PPL | Val Acc | Val ER |
|---------|--------|---------|---------|--------|
| 50 | 62,891 | 587.0 | 17.7% | 82.5% |
| 100 | 122,795 | 400.2 | 19.0% | 82.5% |
| 200 | 240,132 | 329.3 | 19.7% | 82.8% |
| 500 | 587,970 | 198.1 | 22.5% | 82.4% |

**Scaling Law**: α = -0.4702 (R² = 0.9870)

### 3. Context Dim 1152 (6層/1152dim/1トークン)

| Samples | Tokens | Val PPL | Val Acc | Val ER |
|---------|--------|---------|---------|--------|
| 50 | 62,891 | 756.0 | 16.6% | 71.1% |
| 100 | 122,795 | 514.9 | 18.5% | 71.1% |
| 200 | 240,132 | 367.3 | 19.5% | 71.8% |
| 500 | 587,970 | 246.9 | 21.4% | 71.0% |

**Scaling Law**: α = -0.4988 (R² = 0.9963)

### 4. Layers 9 (9層/768dim/1トークン)

| Samples | Tokens | Val PPL | Val Acc | Val ER |
|---------|--------|---------|---------|--------|
| 50 | 62,891 | 768.5 | 16.6% | 73.8% |
| 100 | 122,795 | 505.4 | 17.3% | 73.7% |
| 200 | 240,132 | 381.6 | 18.6% | 74.0% |
| 500 | 587,970 | 256.8 | 21.1% | 73.7% |

**Scaling Law**: α = -0.4818 (R² = 0.9915)

## α値の解釈

スケーリング則: `PPL = A × tokens^α`

- α = -0.49: トークン数が10倍になるとPPLは約31%に減少 (10^(-0.49) ≈ 0.32)
- α = -0.47: トークン数が10倍になるとPPLは約34%に減少 (10^(-0.47) ≈ 0.34)

**α = -0.49 vs -0.47 の差**:
- 100万トークン時点で約6%のPPL差
- 1000万トークン時点で約13%のPPL差
- データ量が増えるほど差が拡大

## 主要な発見

### 1. 最良の絶対性能: `input_tokens_2`

- 500サンプルで **PPL 198.1** を達成（baselineより20%低い）
- Accuracy **22.5%**（baselineより+1.2%）
- Effective Rank **82%**（baselineの75%より高い）

**理由**: 直近2トークンの情報を使うことで、コンテキストベクトルの表現力が向上

### 2. 最良のスケーリング効率: `context_dim_1152`

- α = **-0.4988** で最もデータ効率が良い
- R² = 0.9963 で最も高い適合度
- 大規模データでは最も性能向上が期待できる

### 3. レイヤー数増加（9層）は効果薄

- baselineとほぼ同じ性能
- パラメータ数が1.5倍になるが、PPL改善は微小
- コスパが悪い

### 4. Effective Rankとの相関

- `input_tokens_2`: ER 82% → 最良PPL
- `baseline`: ER 75% → 良好PPL
- `context_dim_1152`: ER 71% → 良好PPL（次元増加でER低下）
- `layers_9`: ER 74% → 普通PPL

## 結論

| 観点 | 最良設定 | 理由 |
|------|---------|------|
| **絶対性能** | `input_tokens_2` | PPL 198.1（最低）、Acc 22.5%（最高） |
| **データ効率** | `context_dim_1152` | α = -0.4988（最も負） |
| **コストパフォーマンス** | `input_tokens_2` | Phase1 10.63M で最高性能 |

**推奨**: `num_input_tokens=2` を標準設定として採用

## 実行時間

- 総実行時間: 34.9分
- 4アーキテクチャ × 4サンプルサイズ = 16実験

## ログファイル

- 生ログ: [importants/logs/1129.txt](logs/1129.txt)
- JSON結果: `results/architecture_comparison_20251129_141133/summary.json`
