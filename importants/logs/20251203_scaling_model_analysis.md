# Sample Size Scaling Model Analysis

**Date**: 2025-12-03
**Context Dim**: 256 (fixed)
**Device**: NVIDIA L4 (22.2GB)

## 実験データ

| Samples | Tokens | Val PPL | Val Acc | Effective Rank |
|---------|--------|---------|---------|----------------|
| 100 | 122,795 | 321.4 | 19.1% | 68.4% |
| 200 | 240,132 | 253.1 | 19.9% | 68.1% |
| 400 | 473,429 | 186.0 | 21.4% | 68.9% |
| 800 | 948,524 | 155.8 | 22.6% | 68.1% |
| 1600 | 1,920,992 | 134.7 | 23.6% | 67.0% |

## 問題提起

単純なべき乗則 `PPL = A × n^(-a)` では、区間ごとにスケーリング係数 a が変化する：

| 区間 | a (スケーリング係数) |
|------|---------------------|
| 100-400 | 0.395 |
| 200-800 | 0.350 |
| 400-1600 | 0.233 |

**観察**: サンプル数が増えるほど、改善率が低下している（収穫逓減）

→ 単純なべき乗則以外のモデルを検討する必要がある

## 比較した5つのモデル

### Model 1: 単純べき乗則
```
PPL = A × n^(-a)
```

### Model 2: 飽和モデル
```
PPL = PPL_min + A × n^(-a)
```
PPL_min は理論的な下限値（モデル容量の限界）

### Model 3: 対数補正べき乗則
```
PPL = A × n^(-a) × log(n)^b
```

### Model 4: 指数減衰
```
PPL = PPL_min + A × exp(-b × n^c)
```

### Model 5: 変動指数
```
PPL = A × n^(-(a0 - a1×log(n)))
```
スケーリング係数自体がサンプル数の関数

## フィッティング結果

| Model | R² | 残差二乗和 | パラメータ数 | AIC |
|-------|-----|----------|------------|-----|
| 1. 単純べき乗則 | 0.9847 | 358.88 | 2 | 25.37 |
| 2. 飽和モデル | 0.9952 | 111.86 | 3 | 21.54 |
| 3. 対数補正べき乗則 | 0.9940 | 140.93 | 3 | 22.69 |
| **4. 指数減衰** | **0.9982** | **41.17** | 4 | **18.54** |
| 5. 変動指数 | 0.9950 | 117.23 | 3 | 21.77 |

**AIC (Akaike Information Criterion)**: 低いほど良いモデル。パラメータ数のペナルティを含む。

## ベストモデル: 指数減衰 (Model 4)

```
PPL = 132.5 + 473.4 × exp(-0.0576 × n^0.60)
```

### パラメータ
- **PPL_min = 132.5**: 理論的下限値
- **A = 473.4**: 初期振幅
- **b = 0.0576**: 減衰率
- **c = 0.60**: 指数

### 予測精度
| Samples | Actual | Predicted | Error |
|---------|--------|-----------|-------|
| 100 | 321.4 | 322.0 | +0.2% |
| 200 | 253.1 | 250.6 | -1.0% |
| 400 | 186.0 | 190.2 | +2.2% |
| 800 | 155.8 | 151.9 | -2.5% |
| 1600 | 134.7 | 136.2 | +1.1% |

全ての点で ±2.5% 以内の誤差。

### 解釈

指数減衰モデルが示唆すること：
1. **飽和傾向**: PPL は無限にデータを増やしても PPL_min ≈ 132.5 より下がらない
2. **現在地**: 1600 samples (PPL=134.7) は既に理論限界に近い
3. **モデル容量の限界**: context_dim=256 の表現力の上限を反映

## 次点: 飽和モデル (Model 2)

```
PPL = 80.5 + 3167.7 × n^(-0.558)
```

### パラメータ
- **PPL_min = 80.5**: より楽観的な下限値
- **A = 3167.7**
- **a = 0.558**

### 外挿予測
| Samples | Predicted PPL |
|---------|---------------|
| 3,200 | 115.7 |
| 6,400 | 104.4 |
| 10,000 | 99.1 |
| 50,000 | 88.1 |

### 解釈

飽和モデルが示唆すること：
1. **まだ改善余地あり**: PPL_min ≈ 80.5 まで改善可能
2. **必要なデータ量**: PPL < 100 を達成するには約1万 samples が必要

## 2つのモデルの比較

| 観点 | 指数減衰 (Model 4) | 飽和モデル (Model 2) |
|------|-------------------|---------------------|
| R² | 0.9982 (最良) | 0.9952 |
| PPL_min | 132.5 (保守的) | 80.5 (楽観的) |
| 外挿の信頼性 | 低（急速な収束を予測） | 中程度 |
| 物理的解釈 | 急速な飽和 | 緩やかな漸近 |

### どちらが正しいか？

**現時点では判断困難**。理由：
1. データ点が5つしかない
2. 最大サンプル数（1600）が少ない
3. 両モデルともフィットは良好

**検証方法**:
- 3200, 6400 samples での追加実験
- context_dim=320 での比較実験（進行中）

## 重要な発見

### 1. 単純べき乗則は不適切

R² = 0.985 と一見良さそうだが、400 samples で +7.4% の系統的誤差がある。
スケーリング係数が区間ごとに変化することからも、単純べき乗則は不適切。

### 2. 飽和/収束傾向が存在

全てのモデル（単純べき乗則以外）が、PPL に下限が存在することを示唆。
これは **モデル容量の限界** を反映している。

### 3. Effective Rank の飽和

サンプル数に関わらず ER ≈ 67-69% で安定。
context_dim=256 の表現空間の約2/3しか活用されていない。
これが PPL_min の原因の一つと考えられる。

### 4. 変動指数モデルの洞察

Model 5 のフィッティング結果：
```
a(n) = 0.768 - 0.037 × log(n)
```

| Samples | 実効指数 a(n) |
|---------|--------------|
| 100 | 0.597 |
| 400 | 0.545 |
| 1600 | 0.494 |

スケーリング係数が対数的に減少していることを定量的に確認。

## 今後の実験計画

1. **context_dim=320 での実験**（進行中）
   - PPL_min が context_dim に依存するか確認
   - モデル容量と飽和点の関係を分析

2. **3200, 6400 samples での追加実験**
   - 指数減衰 vs 飽和モデルの判別
   - 外挿予測の検証

3. **Effective Rank の分析**
   - ER と PPL_min の関係
   - ER 向上のための手法検討

## 結論

1. **現在のベストモデル**: 指数減衰 (AIC最小、R²最大)
2. **PPL_min の推定**: 80.5〜132.5 の範囲
3. **実用的含意**: context_dim=256 では、大量データを投入しても PPL < 80 は困難
4. **次のステップ**: context_dim 増加、またはアーキテクチャ改善が必要

## 分析スクリプト

```bash
# モデル比較分析
python3 scripts/analyze_scaling_models.py

# 単純べき乗則分析
python3 scripts/analyze_sample_size_scaling.py
```

## グラフ

![Model Comparison](scaling_model_comparison.png)
