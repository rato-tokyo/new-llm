# 2-Block + prev_context_steps=1 実験結果

**Date**: 2025-12-03
**構成**: 2 ContextBlocks (カスケード連結) + 1つ前のcontext
**context_dim per block**: 256
**combined_dim**: 1024 (256 × 2 blocks × 2 steps)
**Device**: NVIDIA L4 (22.2GB)

## 実験結果

| Samples | Tokens | Val PPL | Val Acc | ER% | Time |
|---------|--------|---------|---------|-----|------|
| 200 | 240,132 | 246.5 | 21.0% | 72.8% | 327.4s |
| 400 | 473,429 | 178.6 | 22.8% | 73.1% | 496.9s |
| 800 | 948,524 | 142.5 | 24.1% | 72.7% | 942.5s |
| **1600** | **1,920,992** | **118.2** | **25.3%** | **72.5%** | **1832.7s** |

## 指数減衰モデルフィッティング

```
PPL = PPL_min + A × exp(-b × n^c)

PPL_min = 106.5
A = 2000.0
b = 0.5186
c = 0.3088
R² = 0.9989
```

**予測精度**:
| Samples | Actual | Predicted | Error |
|---------|--------|-----------|-------|
| 200 | 246.5 | 246.0 | -0.2% |
| 400 | 178.6 | 180.4 | +1.0% |
| 800 | 142.5 | 140.1 | -1.6% |
| 1600 | 118.2 | 119.2 | +0.9% |

## p=0 vs p=1 比較

| 構成 | combined_dim | 1600 samples PPL | PPL_min | ER% |
|------|--------------|------------------|---------|-----|
| **2-block (p=0)** | 512 | 127.4 | 117.6 | 78% |
| **2-block (p=1)** | 1024 | **118.2** | **106.5** | 73% |
| 差 | +512 (+100%) | **-9.2 (-7.2%)** | **-11.1 (-9.4%)** | -5% |

### 重要な発見

1. **prev_context_steps=1で大幅改善**
   - PPL: 127.4 → 118.2 (**-7.2%**)
   - PPL_min: 117.6 → 106.5 (**-9.4%**)
   - 1つ前のcontextを連結することで情報量増加

2. **Effective Rankは若干低下**
   - p=0: ~78% (400/512)
   - p=1: ~73% (745/1024)
   - 次元効率は下がるが、絶対的な有効次元は 400 → 745 に増加

3. **処理時間への影響**
   - p=0: 1987.0s
   - p=1: 1832.7s
   - 若干高速化（キャッシュ効率？）

## スケーリングモデル比較（p=1データ）

### 3つのモデルでフィッティング

| Model | 式 | AIC | PPL_min |
|-------|-----|-----|---------|
| Power Law | PPL = A × n^(-a) | - | N/A |
| **Saturation** | PPL = PPL_min + A × n^(-a) | **最良** | **~95** |
| Exp Decay | PPL = PPL_min + A × exp(-b × n^c) | 良好 | 106.5 |

**注**: 4点のみのデータではモデル選択の信頼性は限定的。
3200サンプルでの実験結果で判断すべき。

## 外挿予測（指数減衰モデル）

| Samples | 予測 PPL |
|---------|---------|
| 3,200 | ~112 |
| 6,400 | ~109 |
| ∞ | 106.5 |

## 構成比較まとめ

| 構成 | combined_dim | 1600 samples PPL | PPL_min |
|------|--------------|------------------|---------|
| 1-block (dim=256) | 256 | 134.7 | 132.5 |
| 2-block (p=0) | 512 | 127.4 | 117.6 |
| **2-block (p=1)** | **1024** | **118.2** | **106.5** |

## Phase 1 収束状況

| Samples | Block 0 | Block 1 |
|---------|---------|---------|
| 200 | 92% (18 iter) | 94% (17 iter) |
| 400 | 91% (18 iter) | 91% (18 iter) |
| 800 | 92% (19 iter) | 91% (17 iter) |
| 1600 | 93% (17 iter) | 91% (17 iter) |

両ブロックとも安定して90%以上の収束率を達成。

## 結論

1. **prev_context_steps=1は有効**
   - PPLが7%以上改善
   - PPL_minも9%以上改善
   - 1つ前のcontextを連結することで時系列情報を活用

2. **次元効率とのトレードオフ**
   - combined_dimは2倍になるが、ERは若干低下
   - ただし絶対的な有効次元数は増加

3. **PPL_min = 106.5 が現在の理論限界**
   - 2-block (p=0) の 117.6 から11ポイント改善
   - さらなる改善にはアーキテクチャ変更が必要

4. **次のステップ**
   - 3200サンプルで飽和モデル vs 指数減衰を判定
   - prev_context_steps=2 での実験
   - 3-block, 4-block での実験
