remote: Enumerating objects: 8, done.
remote: Counting objects: 100% (8/8), done.
remote: Compressing objects: 100% (4/4), done.
remote: Total 6 (delta 4), reused 4 (delta 2), pack-reused 0 (from 0)
Unpacking objects: 100% (6/6), 580 bytes | 290.00 KiB/s, done.
From https://github.com/rato-tokyo/new-llm
   7bb1343..681f00b  main       -> origin/main
HEAD is now at 681f00b user update
======================================================================
ALPHA SCALING EXPERIMENT (Data Amount Dependency)
======================================================================
Configurations: 1
Sample sizes: [50, 100, 200, 400, 800]
Window size: 4 points
Number of windows: 2
Multiplier: 2.0x
Total experiments: 5
Output: importants/logs/1130_v6
Device: cuda (NVIDIA L4, 23.8GB)

Configurations:
  1. 1L_1085d_1tok
Device: cuda (NVIDIA L4, 22.2GB)

======================================================================
Config: 1L_1085d_1tok
  num_layers=1, context_dim=1085, num_input_tokens=1
======================================================================

  --- 50 samples ---

--- Experiment: 50 samples, 1L, 1085d, 1tok ---
Loading training data...
  Loading from cache: ./cache/ultrachat_50samples_full.pt
Loading validation data...
Token indices sequence length is longer than the specified maximum sequence length for this model (31024 > 1024). Running this sequence through the model will result in indexing errors
  Train: 62891 tokens (50 samples)
  Val:   31024 tokens
  Data: 62,891 train, 31,024 val tokens
2025-11-30 12:57:51.200834: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-11-30 12:57:51.216251: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1764507471.236505   38343 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1764507471.242938   38343 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1764507471.259052   38343 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1764507471.259081   38343 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1764507471.259084   38343 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1764507471.259087   38343 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-30 12:57:51.263939: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
Loading GPT-2 pretrained embeddings...
✓ Loaded GPT-2 embeddings: torch.Size([50257, 768])
Using E案 architecture: ContextBlock(1 layers) + TokenBlock(1 layers)
  num_input_tokens: 1
  token継ぎ足し方式: 全レイヤーでtoken入力
✓ Weight Tying: token_output shares weights with token_embedding
  → Saved ~38.60M parameters

[Phase 1] Train: 62,891 tokens, 100 iterations
  Iter 1: random init
  Iter 2: conv=0% loss=-0.2709 [1.1s]
  Iter 3: conv=0% loss=-0.2843 [0.7s]
  Iter 4: conv=0% loss=-0.3136 [0.6s]
  Iter 5: conv=0% loss=-0.3373 [0.6s]
  Iter 6: conv=0% loss=-0.3538 [0.6s]
  Iter 7: conv=0% loss=-0.3645 [0.6s]
  Iter 8: conv=0% loss=-0.3718 [0.7s]
  Iter 9: conv=0% loss=-0.3780 [0.7s]
  Iter 10: conv=0% loss=-0.3841 [0.6s]
  Iter 11: conv=1% loss=-0.3902 [0.7s]
  Iter 12: conv=1% loss=-0.3961 [0.7s]
  Iter 13: conv=1% loss=-0.4014 [0.7s]
  Iter 14: conv=2% loss=-0.4061 [0.7s]
  Iter 15: conv=2% loss=-0.4103 [0.6s]
  Iter 16: conv=2% loss=-0.4140 [0.7s]
  Iter 17: conv=2% loss=-0.4173 [0.6s]
  Iter 18: conv=3% loss=-0.4203 [0.7s]
  Iter 19: conv=3% loss=-0.4231 [0.7s]
  Iter 20: conv=4% loss=-0.4258 [0.6s]
  Iter 21: conv=6% loss=-0.4282 [0.6s]
  Iter 22: conv=7% loss=-0.4304 [0.6s]
  Iter 23: conv=8% loss=-0.4323 [0.7s]
  Iter 24: conv=9% loss=-0.4339 [0.6s]
  Iter 25: conv=11% loss=-0.4353 [0.6s]
  Iter 26: conv=13% loss=-0.4368 [0.7s]
  Iter 27: conv=15% loss=-0.4382 [0.7s]
  Iter 28: conv=18% loss=-0.4396 [0.6s]
  Iter 29: conv=21% loss=-0.4410 [0.7s]
  Iter 30: conv=25% loss=-0.4423 [0.6s]
  Iter 31: conv=28% loss=-0.4435 [0.7s]
  Iter 32: conv=32% loss=-0.4447 [0.6s]
  Iter 33: conv=36% loss=-0.4458 [0.6s]
  Iter 34: conv=40% loss=-0.4468 [0.6s]
  Iter 35: conv=43% loss=-0.4479 [0.7s]
  Iter 36: conv=46% loss=-0.4489 [0.7s]
  Iter 37: conv=49% loss=-0.4500 [0.7s]
  Iter 38: conv=52% loss=-0.4510 [0.6s]
  Iter 39: conv=55% loss=-0.4520 [0.6s]
  Iter 40: conv=57% loss=-0.4530 [0.7s]
  Iter 41: conv=60% loss=-0.4540 [0.7s]
  Iter 42: conv=62% loss=-0.4550 [0.7s]
  Iter 43: conv=64% loss=-0.4560 [0.6s]
  Iter 44: conv=65% loss=-0.4570 [0.7s]
  Iter 45: conv=67% loss=-0.4580 [0.6s]
  Iter 46: conv=69% loss=-0.4589 [0.7s]
  Iter 47: conv=70% loss=-0.4599 [0.7s]
  Iter 48: conv=72% loss=-0.4608 [0.7s]
  Iter 49: conv=73% loss=-0.4618 [0.7s]
  Iter 50: conv=74% loss=-0.4628 [0.6s]
  Iter 51: conv=75% loss=-0.4637 [0.7s]
  Iter 52: conv=76% loss=-0.4647 [0.7s]
  Iter 53: conv=77% loss=-0.4656 [0.6s]
  Iter 54: conv=78% loss=-0.4666 [0.7s]
  Iter 55: conv=79% loss=-0.4675 [0.6s]
  Iter 56: conv=80% loss=-0.4684 [0.7s]
  Iter 57: conv=81% loss=-0.4694 [0.6s]
  Iter 58: conv=81% loss=-0.4703 [0.6s]
  Iter 59: conv=82% loss=-0.4713 [0.7s]
  Iter 60: conv=82% loss=-0.4722 [0.7s]
  Iter 61: conv=83% loss=-0.4732 [0.7s]
  Iter 62: conv=83% loss=-0.4741 [0.6s]
  Iter 63: conv=84% loss=-0.4750 [0.6s]
  Iter 64: conv=85% loss=-0.4759 [0.7s]
  Iter 65: conv=85% loss=-0.4768 [0.6s]
  Iter 66: conv=86% loss=-0.4777 [0.7s]
  Iter 67: conv=86% loss=-0.4786 [0.6s]
  Iter 68: conv=87% loss=-0.4796 [0.7s]
  Iter 69: conv=87% loss=-0.4805 [0.6s]
  Iter 70: conv=88% loss=-0.4814 [0.6s]
  Iter 71: conv=88% loss=-0.4823 [0.7s]
  Iter 72: conv=89% loss=-0.4832 [0.7s]
  Iter 73: conv=89% loss=-0.4842 [0.6s]
  Iter 74: conv=89% loss=-0.4851 [0.6s]
  Iter 75: conv=90% loss=-0.4860 [0.7s]
  Iter 76: conv=90% loss=-0.4869 [0.7s]
  Iter 77: conv=90% loss=-0.4878 [0.7s]
  Iter 78: conv=91% loss=-0.4887 [0.6s]
  Iter 79: conv=91% loss=-0.4896 [0.6s]
  Iter 80: conv=91% loss=-0.4905 [0.6s]
  Iter 81: conv=92% loss=-0.4914 [0.7s]
  Iter 82: conv=92% loss=-0.4923 [0.6s]
  Iter 83: conv=92% loss=-0.4933 [0.6s]
  Iter 84: conv=92% loss=-0.4942 [0.6s]
  Iter 85: conv=92% loss=-0.4951 [0.7s]
  Iter 86: conv=93% loss=-0.4960 [0.7s]
  Iter 87: conv=93% loss=-0.4969 [0.6s]
  Iter 88: conv=93% loss=-0.4978 [0.7s]
  Iter 89: conv=93% loss=-0.4987 [0.6s]
  Iter 90: conv=94% loss=-0.4996 [0.6s]
  Iter 91: conv=94% loss=-0.5005 [0.7s]
  Iter 92: conv=94% loss=-0.5014 [0.7s]
  Iter 93: conv=94% loss=-0.5023 [0.7s]
  Iter 94: conv=94% loss=-0.5032 [0.7s]
  Iter 95: conv=94% loss=-0.5041 [0.7s]
  Iter 96: conv=94% loss=-0.5050 [0.6s]
  Iter 97: conv=95% loss=-0.5059 [0.6s]
  Iter 98: conv=95% loss=-0.5068 [0.7s]
  Iter 99: conv=95% loss=-0.5077 [0.6s]
  Iter 100: conv=95% loss=-0.5086 [0.6s]
  Done: 95% converged
  Collecting cache (parallel)...
  Cache collected (parallel) [0.5s]
  ER: train=67.6%, val=66.9%
✓ ContextBlock frozen
✓ Embedding frozen (Weight Tying: Output Head also frozen)
  → Only TokenBlock will be trained
✓ Training TokenBlock only: 1,426,944/42,038,080 parameters

[Phase 2] 62,891 train / 31,024 val tokens, 20 epochs
  Epoch 1: train_ppl=1559649.4 val_ppl=19938.1 acc=7.9% [1.8s] ★
  Epoch 2: train_ppl=6204.4 val_ppl=3940.5 acc=10.0% [1.9s] ★
  Epoch 3: train_ppl=1846.6 val_ppl=2102.9 acc=12.9% [1.9s] ★
  Epoch 4: train_ppl=937.6 val_ppl=1486.9 acc=13.7% [1.9s] ★
  Epoch 5: train_ppl=628.6 val_ppl=1186.6 acc=14.6% [1.9s] ★
  Epoch 6: train_ppl=450.6 val_ppl=1000.1 acc=15.1% [1.9s] ★
  Epoch 7: train_ppl=353.8 val_ppl=881.7 acc=15.8% [1.9s] ★
  Epoch 8: train_ppl=281.2 val_ppl=794.2 acc=16.3% [1.9s] ★
  Epoch 9: train_ppl=234.4 val_ppl=735.1 acc=16.7% [1.9s] ★
  Epoch 10: train_ppl=196.1 val_ppl=687.5 acc=17.0% [1.9s] ★
  Epoch 11: train_ppl=168.4 val_ppl=655.4 acc=17.2% [1.9s] ★
  Epoch 12: train_ppl=144.9 val_ppl=629.7 acc=17.4% [1.8s] ★
  Epoch 13: train_ppl=126.8 val_ppl=613.4 acc=17.6% [1.8s] ★
  Epoch 14: train_ppl=111.2 val_ppl=602.2 acc=17.6% [1.8s] ★
  Epoch 15: train_ppl=98.4 val_ppl=595.4 acc=17.7% [1.8s] ★
  Epoch 16: train_ppl=88.0 val_ppl=592.6 acc=17.8% [1.8s] ★
  Epoch 17: train_ppl=78.3 val_ppl=594.3 acc=17.9% [1.8s]
  → Early stop at epoch 17
  Best: epoch 16, ppl=592.6, acc=17.8%
  Result: PPL=592.6, Acc=17.8%
    → PPL: 592.6, Acc: 17.8%, ER: 66.9%

  --- 100 samples ---

--- Experiment: 100 samples, 1L, 1085d, 1tok ---
Loading training data...
  Loading from cache: ./cache/ultrachat_100samples_full.pt
Loading validation data...
Token indices sequence length is longer than the specified maximum sequence length for this model (31024 > 1024). Running this sequence through the model will result in indexing errors
  Train: 122795 tokens (100 samples)
  Val:   31024 tokens
  Data: 122,795 train, 31,024 val tokens
Loading GPT-2 pretrained embeddings...
✓ Loaded GPT-2 embeddings: torch.Size([50257, 768])
Using E案 architecture: ContextBlock(1 layers) + TokenBlock(1 layers)
  num_input_tokens: 1
  token継ぎ足し方式: 全レイヤーでtoken入力
✓ Weight Tying: token_output shares weights with token_embedding
  → Saved ~38.60M parameters

[Phase 1] Train: 122,795 tokens, 100 iterations
  Iter 1: random init
  Iter 2: conv=0% loss=-0.2682 [1.4s]
  Iter 3: conv=0% loss=-0.2811 [1.2s]
  Iter 4: conv=0% loss=-0.3103 [1.2s]
  Iter 5: conv=0% loss=-0.3338 [1.2s]
  Iter 6: conv=0% loss=-0.3503 [1.2s]
  Iter 7: conv=0% loss=-0.3611 [1.2s]
  Iter 8: conv=0% loss=-0.3685 [1.2s]
  Iter 9: conv=0% loss=-0.3746 [1.2s]
  Iter 10: conv=0% loss=-0.3807 [1.2s]
  Iter 11: conv=0% loss=-0.3869 [1.2s]
  Iter 12: conv=0% loss=-0.3929 [1.2s]
  Iter 13: conv=0% loss=-0.3983 [1.2s]
  Iter 14: conv=1% loss=-0.4031 [1.2s]
  Iter 15: conv=1% loss=-0.4072 [1.2s]
  Iter 16: conv=1% loss=-0.4110 [1.2s]
  Iter 17: conv=1% loss=-0.4143 [1.2s]
  Iter 18: conv=1% loss=-0.4174 [1.3s]
  Iter 19: conv=2% loss=-0.4202 [1.2s]
  Iter 20: conv=3% loss=-0.4229 [1.2s]
  Iter 21: conv=4% loss=-0.4253 [1.2s]
  Iter 22: conv=6% loss=-0.4275 [1.2s]
  Iter 23: conv=7% loss=-0.4293 [1.2s]
  Iter 24: conv=8% loss=-0.4309 [1.2s]
  Iter 25: conv=10% loss=-0.4324 [1.2s]
  Iter 26: conv=12% loss=-0.4338 [1.2s]
  Iter 27: conv=15% loss=-0.4352 [1.2s]
  Iter 28: conv=18% loss=-0.4366 [1.2s]
  Iter 29: conv=22% loss=-0.4380 [1.2s]
  Iter 30: conv=26% loss=-0.4393 [1.2s]
  Iter 31: conv=30% loss=-0.4405 [1.2s]
  Iter 32: conv=34% loss=-0.4416 [1.2s]
  Iter 33: conv=38% loss=-0.4427 [1.2s]
  Iter 34: conv=42% loss=-0.4438 [1.2s]
  Iter 35: conv=45% loss=-0.4448 [1.2s]
  Iter 36: conv=48% loss=-0.4459 [1.2s]
  Iter 37: conv=51% loss=-0.4469 [1.2s]
  Iter 38: conv=54% loss=-0.4479 [1.2s]
  Iter 39: conv=57% loss=-0.4489 [1.2s]
  Iter 40: conv=59% loss=-0.4499 [1.2s]
  Iter 41: conv=61% loss=-0.4509 [1.2s]
  Iter 42: conv=64% loss=-0.4519 [1.2s]
  Iter 43: conv=65% loss=-0.4528 [1.2s]
  Iter 44: conv=67% loss=-0.4538 [1.2s]
  Iter 45: conv=68% loss=-0.4548 [1.2s]
  Iter 46: conv=70% loss=-0.4558 [1.2s]
  Iter 47: conv=72% loss=-0.4567 [1.3s]
  Iter 48: conv=73% loss=-0.4577 [1.2s]
  Iter 49: conv=74% loss=-0.4586 [1.2s]
  Iter 50: conv=75% loss=-0.4596 [1.2s]
  Iter 51: conv=76% loss=-0.4605 [1.2s]
  Iter 52: conv=77% loss=-0.4615 [1.2s]
  Iter 53: conv=78% loss=-0.4624 [1.2s]
  Iter 54: conv=79% loss=-0.4634 [1.2s]
  Iter 55: conv=80% loss=-0.4643 [1.2s]
  Iter 56: conv=81% loss=-0.4652 [1.2s]
  Iter 57: conv=82% loss=-0.4662 [1.2s]
  Iter 58: conv=82% loss=-0.4671 [1.2s]
  Iter 59: conv=83% loss=-0.4681 [1.2s]
  Iter 60: conv=83% loss=-0.4690 [1.2s]
  Iter 61: conv=84% loss=-0.4699 [1.2s]
  Iter 62: conv=85% loss=-0.4708 [1.3s]
  Iter 63: conv=85% loss=-0.4717 [1.2s]
  Iter 64: conv=86% loss=-0.4726 [1.2s]
  Iter 65: conv=86% loss=-0.4735 [1.2s]
  Iter 66: conv=87% loss=-0.4744 [1.2s]
  Iter 67: conv=87% loss=-0.4754 [1.2s]
  Iter 68: conv=88% loss=-0.4763 [1.2s]
  Iter 69: conv=88% loss=-0.4772 [1.2s]
  Iter 70: conv=88% loss=-0.4781 [1.2s]
  Iter 71: conv=89% loss=-0.4790 [1.2s]
  Iter 72: conv=89% loss=-0.4800 [1.2s]
  Iter 73: conv=90% loss=-0.4809 [1.2s]
  Iter 74: conv=90% loss=-0.4818 [1.2s]
  Iter 75: conv=90% loss=-0.4827 [1.2s]
  Iter 76: conv=91% loss=-0.4836 [1.2s]
  Iter 77: conv=91% loss=-0.4845 [1.2s]
  Iter 78: conv=91% loss=-0.4854 [1.2s]
  Iter 79: conv=92% loss=-0.4863 [1.2s]
  Iter 80: conv=92% loss=-0.4872 [1.2s]
  Iter 81: conv=92% loss=-0.4881 [1.2s]
  Iter 82: conv=92% loss=-0.4890 [1.2s]
  Iter 83: conv=92% loss=-0.4899 [1.2s]
  Iter 84: conv=93% loss=-0.4908 [1.2s]
  Iter 85: conv=93% loss=-0.4917 [1.2s]
  Iter 86: conv=93% loss=-0.4926 [1.2s]
  Iter 87: conv=93% loss=-0.4935 [1.2s]
  Iter 88: conv=93% loss=-0.4944 [1.2s]
  Iter 89: conv=94% loss=-0.4953 [1.2s]
  Iter 90: conv=94% loss=-0.4962 [1.2s]
  Iter 91: conv=94% loss=-0.4971 [1.2s]
  Iter 92: conv=94% loss=-0.4980 [1.2s]
  Iter 93: conv=94% loss=-0.4989 [1.2s]
  Iter 94: conv=94% loss=-0.4998 [1.2s]
  Iter 95: conv=95% loss=-0.5007 [1.2s]
  Iter 96: conv=95% loss=-0.5016 [1.2s]
  Iter 97: conv=95% loss=-0.5025 [1.2s]
  Iter 98: conv=95% loss=-0.5033 [1.2s]
  Iter 99: conv=95% loss=-0.5042 [1.2s]
  Iter 100: conv=95% loss=-0.5051 [1.2s]
  Done: 95% converged
  Collecting cache (parallel)...
  Cache collected (parallel) [1.0s]
  ER: train=67.6%, val=66.4%
✓ ContextBlock frozen
✓ Embedding frozen (Weight Tying: Output Head also frozen)
  → Only TokenBlock will be trained
✓ Training TokenBlock only: 1,426,944/42,038,080 parameters

[Phase 2] 122,795 train / 31,024 val tokens, 20 epochs
  Epoch 1: train_ppl=125674.0 val_ppl=4193.9 acc=10.3% [3.2s] ★
  Epoch 2: train_ppl=2047.5 val_ppl=1513.0 acc=13.9% [3.2s] ★
  Epoch 3: train_ppl=930.6 val_ppl=981.4 acc=15.3% [3.2s] ★
  Epoch 4: train_ppl=587.5 val_ppl=758.0 acc=16.2% [3.2s] ★
  Epoch 5: train_ppl=426.7 val_ppl=633.7 acc=16.9% [3.3s] ★
  Epoch 6: train_ppl=332.4 val_ppl=556.6 acc=17.4% [3.2s] ★
  Epoch 7: train_ppl=270.3 val_ppl=506.5 acc=17.7% [3.2s] ★
  Epoch 8: train_ppl=226.2 val_ppl=472.1 acc=18.0% [3.2s] ★
  Epoch 9: train_ppl=193.0 val_ppl=448.3 acc=18.3% [3.2s] ★
  Epoch 10: train_ppl=167.1 val_ppl=432.1 acc=18.6% [3.2s] ★
  Epoch 11: train_ppl=146.2 val_ppl=421.2 acc=18.9% [3.2s] ★
  Epoch 12: train_ppl=129.1 val_ppl=414.4 acc=19.1% [3.2s] ★
  Epoch 13: train_ppl=114.9 val_ppl=410.7 acc=19.3% [3.2s] ★
  Epoch 14: train_ppl=103.0 val_ppl=409.8 acc=19.4% [3.2s] ★
  Epoch 15: train_ppl=92.8 val_ppl=411.4 acc=19.4% [3.2s]
  → Early stop at epoch 15
  Best: epoch 14, ppl=409.8, acc=19.4%
  Result: PPL=409.8, Acc=19.4%
    → PPL: 409.8, Acc: 19.4%, ER: 66.4%

  --- 200 samples ---

--- Experiment: 200 samples, 1L, 1085d, 1tok ---
Loading training data...
  Loading from cache: ./cache/ultrachat_200samples_full.pt
Loading validation data...
Token indices sequence length is longer than the specified maximum sequence length for this model (31024 > 1024). Running this sequence through the model will result in indexing errors
  Train: 240132 tokens (200 samples)
  Val:   31024 tokens
  Data: 240,132 train, 31,024 val tokens
Loading GPT-2 pretrained embeddings...
✓ Loaded GPT-2 embeddings: torch.Size([50257, 768])
Using E案 architecture: ContextBlock(1 layers) + TokenBlock(1 layers)
  num_input_tokens: 1
  token継ぎ足し方式: 全レイヤーでtoken入力
✓ Weight Tying: token_output shares weights with token_embedding
  → Saved ~38.60M parameters

[Phase 1] Train: 240,132 tokens, 100 iterations
  Iter 1: random init
  Iter 2: conv=0% loss=-0.2662 [2.3s]
  Iter 3: conv=0% loss=-0.2795 [2.3s]
  Iter 4: conv=0% loss=-0.3085 [2.2s]
  Iter 5: conv=0% loss=-0.3317 [2.2s]
  Iter 6: conv=0% loss=-0.3480 [2.2s]
  Iter 7: conv=0% loss=-0.3587 [2.2s]
  Iter 8: conv=0% loss=-0.3660 [2.2s]
  Iter 9: conv=0% loss=-0.3720 [2.2s]
  Iter 10: conv=0% loss=-0.3780 [2.2s]
  Iter 11: conv=1% loss=-0.3840 [2.2s]
  Iter 12: conv=1% loss=-0.3898 [2.2s]
  Iter 13: conv=1% loss=-0.3951 [2.2s]
  Iter 14: conv=1% loss=-0.3997 [2.2s]
  Iter 15: conv=1% loss=-0.4038 [2.2s]
  Iter 16: conv=2% loss=-0.4074 [2.2s]
  Iter 17: conv=2% loss=-0.4106 [2.2s]
  Iter 18: conv=2% loss=-0.4136 [2.2s]
  Iter 19: conv=2% loss=-0.4164 [2.2s]
  Iter 20: conv=3% loss=-0.4192 [2.2s]
  Iter 21: conv=4% loss=-0.4219 [2.2s]
  Iter 22: conv=6% loss=-0.4242 [2.2s]
  Iter 23: conv=7% loss=-0.4263 [2.2s]
  Iter 24: conv=8% loss=-0.4280 [2.2s]
  Iter 25: conv=9% loss=-0.4295 [2.2s]
  Iter 26: conv=11% loss=-0.4309 [2.3s]
  Iter 27: conv=12% loss=-0.4324 [2.2s]
  Iter 28: conv=14% loss=-0.4339 [2.2s]
  Iter 29: conv=17% loss=-0.4353 [2.2s]
  Iter 30: conv=19% loss=-0.4366 [2.2s]
  Iter 31: conv=22% loss=-0.4379 [2.2s]
  Iter 32: conv=25% loss=-0.4391 [2.2s]
  Iter 33: conv=29% loss=-0.4402 [2.2s]
  Iter 34: conv=32% loss=-0.4412 [2.2s]
  Iter 35: conv=36% loss=-0.4423 [2.2s]
  Iter 36: conv=39% loss=-0.4434 [2.2s]
  Iter 37: conv=42% loss=-0.4444 [2.2s]
  Iter 38: conv=45% loss=-0.4455 [2.2s]
  Iter 39: conv=48% loss=-0.4465 [2.2s]
  Iter 40: conv=50% loss=-0.4475 [2.2s]
  Iter 41: conv=53% loss=-0.4484 [2.2s]
  Iter 42: conv=55% loss=-0.4494 [2.3s]
  Iter 43: conv=58% loss=-0.4504 [2.2s]
  Iter 44: conv=60% loss=-0.4514 [2.2s]
  Iter 45: conv=62% loss=-0.4524 [2.2s]
  Iter 46: conv=64% loss=-0.4533 [2.2s]
  Iter 47: conv=66% loss=-0.4543 [2.3s]
  Iter 48: conv=67% loss=-0.4552 [2.2s]
  Iter 49: conv=69% loss=-0.4562 [2.2s]
  Iter 50: conv=71% loss=-0.4571 [2.2s]
  Iter 51: conv=72% loss=-0.4581 [2.2s]
  Iter 52: conv=73% loss=-0.4590 [2.2s]
  Iter 53: conv=75% loss=-0.4600 [2.2s]
  Iter 54: conv=76% loss=-0.4609 [2.2s]
  Iter 55: conv=77% loss=-0.4618 [2.2s]
  Iter 56: conv=78% loss=-0.4628 [2.2s]
  Iter 57: conv=79% loss=-0.4637 [2.2s]
  Iter 58: conv=80% loss=-0.4646 [2.2s]
  Iter 59: conv=81% loss=-0.4656 [2.2s]
  Iter 60: conv=81% loss=-0.4665 [2.2s]
  Iter 61: conv=82% loss=-0.4674 [2.2s]
  Iter 62: conv=83% loss=-0.4683 [2.2s]
  Iter 63: conv=83% loss=-0.4692 [2.2s]
  Iter 64: conv=84% loss=-0.4701 [2.2s]
  Iter 65: conv=85% loss=-0.4710 [2.2s]
  Iter 66: conv=85% loss=-0.4719 [2.2s]
  Iter 67: conv=86% loss=-0.4728 [2.2s]
  Iter 68: conv=86% loss=-0.4737 [2.2s]
  Iter 69: conv=87% loss=-0.4747 [2.2s]
  Iter 70: conv=87% loss=-0.4756 [2.2s]
  Iter 71: conv=88% loss=-0.4765 [2.2s]
  Iter 72: conv=88% loss=-0.4774 [2.2s]
  Iter 73: conv=89% loss=-0.4783 [2.2s]
  Iter 74: conv=89% loss=-0.4792 [2.2s]
  Iter 75: conv=90% loss=-0.4801 [2.2s]
  Iter 76: conv=90% loss=-0.4810 [2.2s]
  Iter 77: conv=90% loss=-0.4819 [2.2s]
  Iter 78: conv=91% loss=-0.4828 [2.2s]
  Iter 79: conv=91% loss=-0.4837 [2.2s]
  Iter 80: conv=91% loss=-0.4846 [2.2s]
  Iter 81: conv=91% loss=-0.4855 [2.2s]
  Iter 82: conv=92% loss=-0.4864 [2.2s]
  Iter 83: conv=92% loss=-0.4873 [2.2s]
  Iter 84: conv=92% loss=-0.4882 [2.2s]
  Iter 85: conv=92% loss=-0.4891 [2.3s]
  Iter 86: conv=92% loss=-0.4900 [2.2s]
  Iter 87: conv=93% loss=-0.4908 [2.2s]
  Iter 88: conv=93% loss=-0.4917 [2.2s]
  Iter 89: conv=93% loss=-0.4926 [2.2s]
  Iter 90: conv=93% loss=-0.4935 [2.2s]
  Iter 91: conv=93% loss=-0.4944 [2.2s]
  Iter 92: conv=94% loss=-0.4953 [2.2s]
  Iter 93: conv=94% loss=-0.4962 [2.2s]
  Iter 94: conv=94% loss=-0.4971 [2.3s]
  Iter 95: conv=94% loss=-0.4980 [2.2s]
  Iter 96: conv=94% loss=-0.4989 [2.2s]
  Iter 97: conv=94% loss=-0.4997 [2.2s]
  Iter 98: conv=95% loss=-0.5006 [2.2s]
  Iter 99: conv=95% loss=-0.5015 [2.3s]
  Iter 100: conv=95% loss=-0.5024 [2.3s]
  Done: 95% converged
  Collecting cache (parallel)...
  Cache collected (parallel) [2.1s]
  ER: train=67.9%, val=66.7%
✓ ContextBlock frozen
✓ Embedding frozen (Weight Tying: Output Head also frozen)
  → Only TokenBlock will be trained
✓ Training TokenBlock only: 1,426,944/42,038,080 parameters

[Phase 2] 240,132 train / 31,024 val tokens, 20 epochs
  Epoch 1: train_ppl=20071.6 val_ppl=1568.5 acc=13.8% [5.9s] ★
  Epoch 2: train_ppl=995.5 val_ppl=769.5 acc=16.3% [5.9s] ★
  Epoch 3: train_ppl=546.1 val_ppl=549.5 acc=17.3% [5.9s] ★
  Epoch 4: train_ppl=380.2 val_ppl=451.4 acc=18.0% [5.9s] ★
  Epoch 5: train_ppl=294.2 val_ppl=396.2 acc=18.6% [5.9s] ★
  Epoch 6: train_ppl=240.6 val_ppl=362.7 acc=19.2% [5.9s] ★
  Epoch 7: train_ppl=203.5 val_ppl=340.7 acc=19.6% [5.8s] ★
  Epoch 8: train_ppl=176.0 val_ppl=326.0 acc=19.9% [5.8s] ★
  Epoch 9: train_ppl=154.8 val_ppl=316.2 acc=20.1% [5.8s] ★
  Epoch 10: train_ppl=137.7 val_ppl=309.9 acc=20.4% [5.8s] ★
  Epoch 11: train_ppl=123.7 val_ppl=306.5 acc=20.5% [5.8s] ★
  Epoch 12: train_ppl=112.0 val_ppl=305.4 acc=20.5% [5.8s] ★
  Epoch 13: train_ppl=102.1 val_ppl=306.1 acc=20.7% [5.8s]
  → Early stop at epoch 13
  Best: epoch 12, ppl=305.4, acc=20.5%
  Result: PPL=305.4, Acc=20.5%
    → PPL: 305.4, Acc: 20.5%, ER: 66.7%

  --- 400 samples ---

--- Experiment: 400 samples, 1L, 1085d, 1tok ---
Loading training data...
  Loading from cache: ./cache/ultrachat_400samples_full.pt
Loading validation data...
Token indices sequence length is longer than the specified maximum sequence length for this model (31024 > 1024). Running this sequence through the model will result in indexing errors
  Train: 473429 tokens (400 samples)
  Val:   31024 tokens
  Data: 473,429 train, 31,024 val tokens
Loading GPT-2 pretrained embeddings...
✓ Loaded GPT-2 embeddings: torch.Size([50257, 768])
Using E案 architecture: ContextBlock(1 layers) + TokenBlock(1 layers)
  num_input_tokens: 1
  token継ぎ足し方式: 全レイヤーでtoken入力
✓ Weight Tying: token_output shares weights with token_embedding
  → Saved ~38.60M parameters

[Phase 1] Train: 473,429 tokens, 100 iterations
  Iter 1: random init
  Iter 2: conv=0% loss=-0.2658 [4.6s]
  Iter 3: conv=0% loss=-0.2790 [4.3s]
  Iter 4: conv=0% loss=-0.3081 [4.3s]
  Iter 5: conv=0% loss=-0.3314 [4.3s]
  Iter 6: conv=0% loss=-0.3478 [4.3s]
  Iter 7: conv=0% loss=-0.3585 [4.3s]
  Iter 8: conv=0% loss=-0.3658 [4.3s]
  Iter 9: conv=0% loss=-0.3719 [4.4s]
  Iter 10: conv=0% loss=-0.3780 [4.3s]
  Iter 11: conv=0% loss=-0.3841 [4.3s]
  Iter 12: conv=1% loss=-0.3900 [4.3s]
  Iter 13: conv=1% loss=-0.3954 [4.3s]
  Iter 14: conv=1% loss=-0.4000 [4.3s]
  Iter 15: conv=1% loss=-0.4041 [4.3s]
  Iter 16: conv=2% loss=-0.4078 [4.3s]
  Iter 17: conv=2% loss=-0.4112 [4.3s]
  Iter 18: conv=2% loss=-0.4142 [4.3s]
  Iter 19: conv=3% loss=-0.4170 [4.3s]
  Iter 20: conv=4% loss=-0.4197 [4.4s]
  Iter 21: conv=5% loss=-0.4221 [4.3s]
  Iter 22: conv=6% loss=-0.4243 [4.3s]
  Iter 23: conv=7% loss=-0.4261 [4.3s]
  Iter 24: conv=8% loss=-0.4277 [4.3s]
  Iter 25: conv=10% loss=-0.4292 [4.4s]
  Iter 26: conv=12% loss=-0.4306 [4.3s]
  Iter 27: conv=15% loss=-0.4321 [4.3s]
  Iter 28: conv=17% loss=-0.4335 [4.3s]
  Iter 29: conv=21% loss=-0.4349 [4.3s]
  Iter 30: conv=24% loss=-0.4361 [4.4s]
  Iter 31: conv=28% loss=-0.4373 [4.3s]
  Iter 32: conv=32% loss=-0.4385 [4.3s]
  Iter 33: conv=35% loss=-0.4395 [4.3s]
  Iter 34: conv=39% loss=-0.4406 [4.3s]
  Iter 35: conv=43% loss=-0.4417 [4.3s]
  Iter 36: conv=46% loss=-0.4427 [4.3s]
  Iter 37: conv=49% loss=-0.4438 [4.3s]
  Iter 38: conv=51% loss=-0.4448 [4.3s]
  Iter 39: conv=54% loss=-0.4457 [4.3s]
  Iter 40: conv=57% loss=-0.4467 [4.3s]
  Iter 41: conv=59% loss=-0.4477 [4.3s]
  Iter 42: conv=61% loss=-0.4487 [4.4s]
  Iter 43: conv=63% loss=-0.4497 [4.3s]
  Iter 44: conv=65% loss=-0.4507 [4.4s]
  Iter 45: conv=66% loss=-0.4516 [4.3s]
  Iter 46: conv=68% loss=-0.4526 [4.3s]
  Iter 47: conv=69% loss=-0.4536 [4.4s]
  Iter 48: conv=71% loss=-0.4545 [4.3s]
  Iter 49: conv=72% loss=-0.4554 [4.3s]
  Iter 50: conv=73% loss=-0.4564 [4.3s]
  Iter 51: conv=75% loss=-0.4573 [4.3s]
  Iter 52: conv=75% loss=-0.4583 [4.3s]
  Iter 53: conv=76% loss=-0.4592 [4.3s]
  Iter 54: conv=77% loss=-0.4602 [4.3s]
  Iter 55: conv=78% loss=-0.4611 [4.3s]
  Iter 56: conv=79% loss=-0.4620 [4.3s]
  Iter 57: conv=80% loss=-0.4630 [4.3s]
  Iter 58: conv=81% loss=-0.4639 [4.3s]
  Iter 59: conv=82% loss=-0.4649 [4.4s]
  Iter 60: conv=82% loss=-0.4658 [4.4s]
  Iter 61: conv=83% loss=-0.4667 [4.3s]
  Iter 62: conv=84% loss=-0.4676 [4.4s]
  Iter 63: conv=84% loss=-0.4685 [4.3s]
  Iter 64: conv=85% loss=-0.4694 [4.3s]
  Iter 65: conv=85% loss=-0.4703 [4.3s]
  Iter 66: conv=86% loss=-0.4712 [4.3s]
  Iter 67: conv=86% loss=-0.4721 [4.3s]
  Iter 68: conv=87% loss=-0.4731 [4.3s]
  Iter 69: conv=87% loss=-0.4740 [4.3s]
  Iter 70: conv=88% loss=-0.4749 [4.3s]
  Iter 71: conv=88% loss=-0.4758 [4.4s]
  Iter 72: conv=89% loss=-0.4767 [4.3s]
  Iter 73: conv=89% loss=-0.4776 [4.3s]
  Iter 74: conv=90% loss=-0.4785 [4.3s]
  Iter 75: conv=90% loss=-0.4794 [4.3s]
  Iter 76: conv=90% loss=-0.4803 [4.3s]
  Iter 77: conv=91% loss=-0.4812 [4.3s]
  Iter 78: conv=91% loss=-0.4821 [4.3s]
  Iter 79: conv=91% loss=-0.4830 [4.3s]
  Iter 80: conv=91% loss=-0.4839 [4.3s]
  Iter 81: conv=92% loss=-0.4848 [4.3s]
  Iter 82: conv=92% loss=-0.4857 [4.3s]
  Iter 83: conv=92% loss=-0.4866 [4.3s]
  Iter 84: conv=92% loss=-0.4875 [4.3s]
  Iter 85: conv=93% loss=-0.4884 [4.3s]
  Iter 86: conv=93% loss=-0.4893 [4.3s]
  Iter 87: conv=93% loss=-0.4902 [4.3s]
  Iter 88: conv=93% loss=-0.4911 [4.4s]
  Iter 89: conv=94% loss=-0.4920 [4.3s]
  Iter 90: conv=94% loss=-0.4929 [4.4s]
  Iter 91: conv=94% loss=-0.4938 [4.3s]
  Iter 92: conv=94% loss=-0.4947 [4.3s]
  Iter 93: conv=94% loss=-0.4956 [4.3s]
  Iter 94: conv=94% loss=-0.4965 [4.3s]
  Iter 95: conv=95% loss=-0.4974 [4.3s]
  Iter 96: conv=95% loss=-0.4983 [4.3s]
  Iter 97: conv=95% loss=-0.4991 [4.3s]
  Iter 98: conv=95% loss=-0.5000 [4.3s]
  Iter 99: conv=95% loss=-0.5009 [4.3s]
  Iter 100: conv=95% loss=-0.5018 [4.4s]
  Done: 95% converged
  Collecting cache (parallel)...
  Cache collected (parallel) [3.7s]
  ER: train=67.9%, val=66.4%
✓ ContextBlock frozen
✓ Embedding frozen (Weight Tying: Output Head also frozen)
  → Only TokenBlock will be trained
✓ Training TokenBlock only: 1,426,944/42,038,080 parameters

[Phase 2] 473,429 train / 31,024 val tokens, 20 epochs
  Epoch 1: train_ppl=4818.3 val_ppl=769.0 acc=16.0% [11.2s] ★
  Epoch 2: train_ppl=553.2 val_ppl=447.3 acc=17.9% [11.1s] ★
  Epoch 3: train_ppl=352.0 val_ppl=352.7 acc=19.0% [11.0s] ★
  Epoch 4: train_ppl=268.1 val_ppl=307.0 acc=19.9% [11.0s] ★
  Epoch 5: train_ppl=219.0 val_ppl=279.9 acc=20.4% [11.0s] ★
  Epoch 6: train_ppl=186.2 val_ppl=262.8 acc=20.9% [11.0s] ★
  Epoch 7: train_ppl=162.7 val_ppl=251.8 acc=21.1% [11.0s] ★
  Epoch 8: train_ppl=145.0 val_ppl=244.6 acc=21.4% [11.1s] ★
  Epoch 9: train_ppl=131.0 val_ppl=239.8 acc=21.6% [11.1s] ★
  Epoch 10: train_ppl=119.7 val_ppl=236.8 acc=21.7% [11.2s] ★
  Epoch 11: train_ppl=110.4 val_ppl=235.2 acc=21.8% [11.2s] ★
  Epoch 12: train_ppl=102.4 val_ppl=234.7 acc=21.8% [11.2s] ★
  Epoch 13: train_ppl=95.7 val_ppl=235.0 acc=21.9% [11.2s]
  → Early stop at epoch 13
  Best: epoch 12, ppl=234.7, acc=21.8%
  Result: PPL=234.7, Acc=21.8%
    → PPL: 234.7, Acc: 21.8%, ER: 66.4%

  --- 800 samples ---

--- Experiment: 800 samples, 1L, 1085d, 1tok ---
Loading training data...
  Loading from cache: ./cache/ultrachat_800samples_full.pt
Loading validation data...
Token indices sequence length is longer than the specified maximum sequence length for this model (31024 > 1024). Running this sequence through the model will result in indexing errors
  Train: 948524 tokens (800 samples)
  Val:   31024 tokens
  Data: 948,524 train, 31,024 val tokens
Loading GPT-2 pretrained embeddings...
✓ Loaded GPT-2 embeddings: torch.Size([50257, 768])
Using E案 architecture: ContextBlock(1 layers) + TokenBlock(1 layers)
  num_input_tokens: 1
  token継ぎ足し方式: 全レイヤーでtoken入力
✓ Weight Tying: token_output shares weights with token_embedding
  → Saved ~38.60M parameters

[Phase 1] Train: 948,524 tokens, 100 iterations
  Iter 1: random init
  Iter 2: conv=0% loss=-0.2654 [9.4s]
  Iter 3: conv=0% loss=-0.2783 [8.7s]
  Iter 4: conv=0% loss=-0.3074 [8.7s]
  Iter 5: conv=0% loss=-0.3307 [8.7s]
  Iter 6: conv=0% loss=-0.3470 [8.8s]
  Iter 7: conv=0% loss=-0.3578 [8.6s]
  Iter 8: conv=0% loss=-0.3651 [8.6s]
  Iter 9: conv=0% loss=-0.3712 [8.6s]
  Iter 10: conv=0% loss=-0.3773 [8.8s]
  Iter 11: conv=0% loss=-0.3835 [8.7s]
  Iter 12: conv=0% loss=-0.3895 [8.6s]
  Iter 13: conv=0% loss=-0.3948 [8.6s]
  Iter 14: conv=1% loss=-0.3996 [8.7s]
  Iter 15: conv=1% loss=-0.4037 [8.6s]
  Iter 16: conv=1% loss=-0.4074 [8.6s]
  Iter 17: conv=1% loss=-0.4108 [8.6s]
  Iter 18: conv=1% loss=-0.4139 [8.7s]
  Iter 19: conv=2% loss=-0.4167 [8.6s]
  Iter 20: conv=3% loss=-0.4194 [8.5s]
  Iter 21: conv=4% loss=-0.4218 [8.6s]
  Iter 22: conv=5% loss=-0.4240 [8.7s]
  Iter 23: conv=6% loss=-0.4258 [8.7s]
  Iter 24: conv=8% loss=-0.4274 [8.6s]
  Iter 25: conv=9% loss=-0.4289 [8.7s]
  Iter 26: conv=12% loss=-0.4303 [8.6s]
  Iter 27: conv=14% loss=-0.4318 [8.8s]
  Iter 28: conv=17% loss=-0.4332 [8.6s]
  Iter 29: conv=20% loss=-0.4346 [8.7s]
  Iter 30: conv=24% loss=-0.4358 [8.6s]
  Iter 31: conv=28% loss=-0.4370 [8.6s]
  Iter 32: conv=32% loss=-0.4381 [8.6s]
  Iter 33: conv=36% loss=-0.4392 [8.7s]
  Iter 34: conv=40% loss=-0.4403 [8.6s]
  Iter 35: conv=43% loss=-0.4414 [8.7s]
  Iter 36: conv=46% loss=-0.4424 [8.6s]
  Iter 37: conv=49% loss=-0.4434 [8.7s]
  Iter 38: conv=52% loss=-0.4444 [8.7s]
  Iter 39: conv=55% loss=-0.4454 [8.7s]
  Iter 40: conv=57% loss=-0.4464 [8.6s]
  Iter 41: conv=60% loss=-0.4474 [8.6s]
  Iter 42: conv=62% loss=-0.4484 [8.6s]
  Iter 43: conv=64% loss=-0.4493 [8.7s]
  Iter 44: conv=65% loss=-0.4503 [8.7s]
  Iter 45: conv=67% loss=-0.4513 [8.8s]
  Iter 46: conv=69% loss=-0.4523 [8.7s]
  Iter 47: conv=70% loss=-0.4532 [8.7s]
  Iter 48: conv=72% loss=-0.4542 [8.7s]
  Iter 49: conv=73% loss=-0.4551 [8.7s]
  Iter 50: conv=74% loss=-0.4561 [8.6s]
  Iter 51: conv=75% loss=-0.4570 [8.6s]
  Iter 52: conv=76% loss=-0.4579 [8.6s]
  Iter 53: conv=77% loss=-0.4589 [8.7s]
  Iter 54: conv=78% loss=-0.4598 [8.6s]
  Iter 55: conv=79% loss=-0.4607 [8.7s]
  Iter 56: conv=80% loss=-0.4617 [8.8s]
  Iter 57: conv=81% loss=-0.4626 [8.8s]
  Iter 58: conv=82% loss=-0.4636 [8.6s]
  Iter 59: conv=82% loss=-0.4645 [8.6s]
  Iter 60: conv=83% loss=-0.4654 [8.7s]
  Iter 61: conv=83% loss=-0.4664 [8.7s]
  Iter 62: conv=84% loss=-0.4673 [8.6s]
  Iter 63: conv=85% loss=-0.4682 [8.6s]
  Iter 64: conv=85% loss=-0.4691 [8.6s]
  Iter 65: conv=86% loss=-0.4700 [8.7s]
  Iter 66: conv=86% loss=-0.4709 [8.6s]
  Iter 67: conv=87% loss=-0.4718 [8.6s]
  Iter 68: conv=87% loss=-0.4727 [8.7s]
  Iter 69: conv=88% loss=-0.4736 [8.7s]
  Iter 70: conv=88% loss=-0.4745 [8.7s]
  Iter 71: conv=89% loss=-0.4754 [8.7s]
  Iter 72: conv=89% loss=-0.4764 [8.6s]
  Iter 73: conv=90% loss=-0.4773 [8.7s]
  Iter 74: conv=90% loss=-0.4782 [8.6s]
  Iter 75: conv=90% loss=-0.4791 [8.7s]
  Iter 76: conv=91% loss=-0.4800 [8.6s]
  Iter 77: conv=91% loss=-0.4809 [8.6s]
  Iter 78: conv=91% loss=-0.4818 [8.6s]
  Iter 79: conv=91% loss=-0.4827 [8.6s]
  Iter 80: conv=92% loss=-0.4836 [8.7s]
  Iter 81: conv=92% loss=-0.4845 [8.6s]
  Iter 82: conv=92% loss=-0.4854 [8.6s]
  Iter 83: conv=92% loss=-0.4863 [8.7s]
  Iter 84: conv=93% loss=-0.4871 [8.7s]
  Iter 85: conv=93% loss=-0.4880 [8.6s]
  Iter 86: conv=93% loss=-0.4889 [8.6s]
  Iter 87: conv=93% loss=-0.4898 [8.7s]
  Iter 88: conv=93% loss=-0.4907 [8.8s]
  Iter 89: conv=93% loss=-0.4916 [8.7s]
  Iter 90: conv=94% loss=-0.4925 [8.6s]
  Iter 91: conv=94% loss=-0.4934 [8.6s]
  Iter 92: conv=94% loss=-0.4943 [8.8s]
  Iter 93: conv=94% loss=-0.4952 [8.6s]
  Iter 94: conv=94% loss=-0.4961 [8.6s]
  Iter 95: conv=94% loss=-0.4970 [8.7s]
  Iter 96: conv=95% loss=-0.4979 [8.8s]
  Iter 97: conv=95% loss=-0.4988 [8.7s]
  Iter 98: conv=95% loss=-0.4997 [8.6s]
  Iter 99: conv=95% loss=-0.5005 [8.6s]
  Iter 100: conv=95% loss=-0.5014 [8.9s]
  Done: 95% converged
  Collecting cache (parallel)...
  Cache collected (parallel) [7.1s]
  ER: train=67.7%, val=66.1%
✓ ContextBlock frozen
✓ Embedding frozen (Weight Tying: Output Head also frozen)
  → Only TokenBlock will be trained
✓ Training TokenBlock only: 1,426,944/42,038,080 parameters

[Phase 2] 948,524 train / 31,024 val tokens, 20 epochs
  Epoch 1: train_ppl=1734.1 val_ppl=445.5 acc=18.1% [22.3s] ★
  Epoch 2: train_ppl=357.3 val_ppl=303.0 acc=19.9% [21.9s] ★
  Epoch 3: train_ppl=253.1 val_ppl=253.9 acc=21.0% [21.6s] ★
  Epoch 4: train_ppl=203.8 val_ppl=229.1 acc=21.8% [21.7s] ★
  Epoch 5: train_ppl=174.4 val_ppl=214.8 acc=22.3% [22.0s] ★
  Epoch 6: train_ppl=154.6 val_ppl=205.4 acc=22.6% [21.9s] ★
  Epoch 7: train_ppl=140.1 val_ppl=199.2 acc=23.0% [21.8s] ★
  Epoch 8: train_ppl=129.0 val_ppl=194.9 acc=23.2% [21.8s] ★
  Epoch 9: train_ppl=120.1 val_ppl=191.8 acc=23.5% [21.9s] ★
  Epoch 10: train_ppl=112.8 val_ppl=189.8 acc=23.6% [21.9s] ★
  Epoch 11: train_ppl=106.7 val_ppl=188.4 acc=23.7% [22.0s] ★
  Epoch 12: train_ppl=101.5 val_ppl=187.7 acc=23.8% [21.9s] ★
  Epoch 13: train_ppl=97.0 val_ppl=187.4 acc=23.9% [21.8s] ★
  Epoch 14: train_ppl=93.1 val_ppl=187.4 acc=23.9% [21.8s]
  → Early stop at epoch 14
  Best: epoch 13, ppl=187.4, acc=23.9%
  Result: PPL=187.4, Acc=23.9%
    → PPL: 187.4, Acc: 23.9%, ER: 66.1%

====================================================================================================
RESULTS SUMMARY
====================================================================================================
Config                   α          A     R²     PPL    Acc   T.PPL    ER Iter
----------------------------------------------------------------------------------------------------
1L_1085d_1tok      -0.4218   5.94e+04  0.990   187.4  23.9%    97.0 66.1%  100

====================================================================================================
DETAILED RESULTS (All sample sizes)
====================================================================================================
Config             Samples     Tokens P1 Iter Train ER  Val ER   T.PPL   V.PPL    Acc
----------------------------------------------------------------------------------------------------
1L_1085d_1tok           50     62,891     100    67.6%   66.9%    88.0   592.6  17.8%
1L_1085d_1tok          100    122,795     100    67.6%   66.4%   103.0   409.8  19.4%
1L_1085d_1tok          200    240,132     100    67.9%   66.7%   112.0   305.4  20.5%
1L_1085d_1tok          400    473,429     100    67.9%   66.4%   102.4   234.7  21.8%
1L_1085d_1tok          800    948,524     100    67.7%   66.1%    97.0   187.4  23.9%

Results saved to: importants/logs/1130_v6

====================================================================================================
ALPHA PROGRESSION ANALYSIS (Sliding Window)
Window size: 4 points
====================================================================================================

1L_1085d_1tok:
--------------------------------------------------------------------------------
  Window              Samples                    Tokens          α            A       R²
--------------------------------------------------------------------------------
       1               50-400            62,891-473,429   -0.45664     8.94e+04   0.9934
       2              100-800           122,795-948,524   -0.38310     3.58e+04   0.9955

  α change: -0.45664 → -0.38310 (Δ = +0.07353, +16.10%)
  Trend: ↑ DEGRADING (α becoming less negative = worse scaling)

Alpha progression saved to: importants/logs/1130_v6/alpha_progression.json

Total time: 39.8 min
