# スケーリングモデル比較分析

**Date**: 2025-12-03
**結論**: 飽和モデル（Saturation Model）が最も適合

## 実験データ

### 2-Block (p=0) 構成

| Samples | Tokens | Val PPL | Val Acc | ER% |
|---------|--------|---------|---------|-----|
| 200 | 240,132 | 258.3 | 20.5% | 78.0% |
| 400 | 473,429 | 187.6 | 22.0% | 78.4% |
| 800 | 948,524 | 150.5 | 23.5% | 77.2% |
| 1600 | 1,920,992 | 127.4 | 24.5% | 78.1% |
| 3200 | 3,864,746 | 114.8 | 25.0% | 77.9% |

## 3つのスケーリングモデル

### 1. Power Law（べき乗則）

```
PPL = A × n^(-a)
```

- **特徴**: 理論限界値（PPL_min）なし
- **解釈**: データ量を増やし続ければPPLは0に近づく
- **現実**: 通常は非現実的

### 2. Saturation Model（飽和モデル）⭐ 最適

```
PPL = PPL_min + A × n^(-a)
```

- **特徴**: 有限の理論限界値（PPL_min）が存在
- **解釈**: データ量を増やしてもPPL_minより下がらない
- **物理的意味**: モデルの表現力の限界を反映

### 3. Exponential Decay（指数減衰モデル）

```
PPL = PPL_min + A × exp(-b × n^c)
```

- **特徴**: より急速な減衰、パラメータ多い
- **解釈**: 初期は急速改善、徐々に飽和
- **問題**: パラメータ数が多く過学習しやすい

## モデル比較結果

### AIC（赤池情報量基準）による選択

| Rank | Model | AIC | PPL_min | R² |
|------|-------|-----|---------|-----|
| **1** | **Saturation** | **7.12** | **95.4** | **0.9995** |
| 2 | Exp Decay | 11.83 | 109.7 | 0.9992 |
| 3 | Power Law | 26.65 | N/A | 0.9652 |

**AICが最も低い飽和モデルが最適**

### 予測精度

| Samples | Actual | Saturation | Exp Decay | Power Law |
|---------|--------|------------|-----------|-----------|
| 200 | 258.3 | 257.1 (-0.5%) | 257.6 (-0.3%) | 248.6 (-3.8%) |
| 400 | 187.6 | 189.7 (+1.1%) | 189.8 (+1.2%) | 199.0 (+6.1%) |
| 800 | 150.5 | 150.3 (-0.1%) | 148.7 (-1.2%) | 159.4 (+5.9%) |
| 1600 | 127.4 | 127.4 (+0.0%) | 126.5 (-0.7%) | 127.6 (+0.1%) |
| 3200 | 114.8 | 114.0 (-0.7%) | 115.9 (+1.0%) | 102.2 (-11.0%) |

**飽和モデルは全サンプルサイズで誤差1.1%以内**

## 外挿予測の検証

4点データ（200-1600）のみでフィッティングし、3200サンプルの結果を予測：

| Model | 予測値 | 実績値 | 誤差 |
|-------|--------|--------|------|
| **Saturation** | **113.4** | **114.8** | **-1.2%** |
| Exp Decay | 119.2 | 114.8 | +3.8% |

**飽和モデルは外挿でも高精度**

## 飽和モデルのパラメータ

```
PPL = 95.4 + 10000 × n^(-0.778)

PPL_min = 95.4   # 理論限界値
A = 10000        # スケール係数
a = 0.778        # 減衰指数
```

## 将来予測

| Samples | 予測 PPL | PPL_min との差 |
|---------|---------|---------------|
| 3,200 | 114.0 | 18.6 |
| 6,400 | 107.1 | 11.7 |
| 12,800 | 101.4 | 6.0 |
| 25,600 | 97.9 | 2.5 |
| ∞ | 95.4 | 0 |

## 結論

### 1. 飽和モデルが最も適合

- AIC最小（最も情報損失が少ない）
- R²最高（説明力最大）
- 外挿精度も良好

### 2. 理論限界値 PPL_min = 95.4

- 2-block (p=0) 構成での限界
- これ以上のデータ増加では改善しない
- アーキテクチャ変更が必要

### 3. 改善の方向性

- **prev_context_steps=1**: PPL_min を ~85-90 に改善可能
- **3-block, 4-block**: 表現力向上による限界値低下
- **context_dim増加**: 効果は限定的（N分割の方が効率的）

## 参考: なぜ飽和モデルか？

飽和モデルは以下の物理的解釈を持つ：

1. **モデル容量の限界**: ContextBlock + TokenBlock の表現力には上限がある
2. **データの本質的複雑性**: 言語モデルには予測不可能な部分がある
3. **Effective Rankの飽和**: コンテキスト空間の有効次元に上限がある

これらの要因により、データ量を増やしても特定の値以下にはPPLが下がらない。
