# 多様性損失アルゴリズム比較実験 - context_dim別分析 (2025-12-01)

## 実験概要

5種類の多様性損失アルゴリズムを、context_dim=768とcontext_dim=1000の2条件で比較。
**Val ERは訓練中の最高値を記録。**

### 実験条件

| 項目 | 値 |
|------|-----|
| サンプル数 | 100 |
| トークン数 | 122,795 |
| num_layers | 1 |
| dist_reg_weight | 0.9（多様性90%, CVFP 10%）|
| max_iterations | 60 |
| GPU | NVIDIA L4 (22.2GB) |

---

## 結果サマリー（Val ER最高値ベース）

### context_dim = 768（GPT-2標準）

| 順位 | アルゴリズム | Best Val ER% | 最高時iter | Train ER% | 時間(s) | Loss(ms) | 評価 |
|:----:|:------------|-------------:|----------:|----------:|--------:|---------:|:-----|
| 🥇1 | **SDL** | **96.0%** | 60（完走）| 96.7% | 210.2 | 71.56 | 最高ER、高コスト |
| 🥈2 | **ODCM** | **90.0%** | 60（完走）| 90.7% | 133.0 | 2.13 | 高ER、低コスト ⭐推奨 |
| 🥉3 | NUC | 77.5% | 10 | 82.6% | 51.5 | 72.46 | 早期停止 |
| 4 | MCDL | 74.5% | 5 | 74.9% | 22.0 | 1.26 | 早期停止 |
| 5 | WMSE | 71.5% | 5 | 73.6% | 21.9 | 1.08 | 早期停止 |

### context_dim = 1000

| 順位 | アルゴリズム | Best Val ER% | 最高時iter | Train ER% | 時間(s) | Loss(ms) | 評価 |
|:----:|:------------|-------------:|----------:|----------:|--------:|---------:|:-----|
| 🥇1 | **SDL** | **95.1%** | 45 | 96.2% | 248.3 | 117.36 | 最高ER、高コスト |
| 🥈2 | **NUC** | **92.4%** | 60（完走）| 93.8% | 297.5 | 111.85 | 高ER、完走 |
| 🥉3 | ODCM | 80.1% | 15 | 84.4% | 55.4 | 1.29 | 早期停止 |
| 4 | MCDL | 69.6% | 5 | 69.9% | 27.2 | 1.06 | 早期停止 |
| 5 | WMSE | 67.6% | 5 | 70.2% | 27.6 | 1.39 | 早期停止 |

---

## 主要な発見

### 1. context_dimがアルゴリズム性能に大きく影響

| アルゴリズム | 768 Best Val ER | 1000 Best Val ER | 差分 | 傾向 |
|:------------|----------------:|----------------:|-----:|:-----|
| SDL | 96.0% | 95.1% | -0.9% | 安定 |
| NUC | 77.5% | **92.4%** | **+14.9%** | 大幅改善 |
| ODCM | 90.0% | 80.1% | **-9.9%** | 悪化 |
| MCDL | 74.5% | 69.6% | -4.9% | 悪化 |
| WMSE | 71.5% | 67.6% | -3.9% | 悪化 |

**重要な発見**:
- **SDL**: 両条件で最高性能（95%以上）、context_dimに対して堅牢
- **NUC**: context_dim=1000で大幅改善、768の約1.2倍
- **ODCM**: context_dim=768に最適化、1000では10%低下

### 2. 完走したアルゴリズム

| アルゴリズム | 768 | 1000 | 備考 |
|:------------|:---:|:----:|:-----|
| SDL | ✅ 60iter | ✅ 60iter* | *iter 45で最高値達成 |
| NUC | 15iter | ✅ 60iter | 次元増加で安定化 |
| ODCM | ✅ 60iter | 20iter | 次元増加で不安定化 |
| MCDL | 10iter | 10iter | 両条件で早期停止 |
| WMSE | 10iter | 10iter | 両条件で早期停止 |

### 3. コストパフォーマンス分析

**context_dim=768の場合**:

| アルゴリズム | Best Val ER | Loss計算時間 | 効率性 |
|:------------|------------:|------------:|:-------|
| **ODCM** | 90.0% | 2.13ms | ⭐ 最高効率 |
| SDL | 96.0% | 71.56ms | 最高性能 |
| MCDL | 74.5% | 1.26ms | 最速だがER低め |

**ODCM vs SDL トレードオフ（768）**:
- SDLは+6% ERだがコスト33倍
- ODCMは低コストで90%達成

**context_dim=1000の場合**:

| アルゴリズム | Best Val ER | Loss計算時間 | 効率性 |
|:------------|------------:|------------:|:-------|
| SDL | 95.1% | 117.36ms | 最高性能 |
| NUC | 92.4% | 111.85ms | 高性能・安定 |
| ODCM | 80.1% | 1.29ms | 低コストだがER低下 |

---

## 推奨事項

### context_dim=768を使用する場合（推奨）

1. **標準用途**: **ODCM**
   - Best Val ER 90.0%、低コスト（2.13ms/iter）
   - GPT-2のembed_dim=768と一致、理論的整合性
   - 60イテレーション完走で安定

2. **最高品質用途**: **SDL**
   - Best Val ER 96.0%
   - 時間に余裕がある場合

### context_dim=1000を使用する場合

1. **最高性能**: **SDL**（Best Val ER 95.1%）
2. **代替**: **NUC**（Best Val ER 92.4%、60iter完走で安定）
3. **ODCM**: 80.1%に低下（768の90%より10%ダウン）

### 結論

| 条件 | 推奨アルゴリズム | Best Val ER | 理由 |
|:-----|:----------------|------------:|:-----|
| **context_dim=768** | **ODCM** | 90.0% | 高ER・低コスト・安定 |
| **context_dim=1000** | **SDL** | 95.1% | 最高ER・安定 |

**context_dim=768 + ODCMが現時点での最適解。**

---

## 付録: イテレーション別Val ER推移

### context_dim=768

**ODCM（60iter完走、継続改善）**:
| Iter | Val ER% | 累積改善 |
|-----:|--------:|--------:|
| 5 | 75.2% | - |
| 10 | 79.6% | +4.4% |
| 15 | 82.6% | +7.4% |
| 20 | 84.3% | +9.1% |
| 25 | 85.6% | +10.4% |
| 30 | 85.9% | +10.7% |
| 35 | 86.3% | +11.1% |
| 40 | 87.0% | +11.8% |
| 45 | 88.4% | +13.2% |
| 50 | 88.9% | +13.7% |
| 55 | 89.4% | +14.2% |
| 60 | **90.0%** | +14.8% |

**SDL（60iter完走、急上昇後安定）**:
| Iter | Val ER% | 累積改善 |
|-----:|--------:|--------:|
| 5 | 80.4% | - |
| 10 | 82.0% | +1.6% |
| 15 | 83.2% | +2.8% |
| 20 | 90.9% | +10.5%（急上昇）|
| 25 | 94.0% | +13.6% |
| 30 | 94.6% | +14.2% |
| 35 | 94.9% | +14.5% |
| 40 | 95.0% | +14.6% |
| 45 | 95.4% | +15.0% |
| 50 | 95.5% | +15.1% |
| 55 | 95.6% | +15.2% |
| 60 | **96.0%** | +15.6% |

### context_dim=1000

**NUC（60iter完走、継続改善）**:
| Iter | Val ER% | 累積改善 |
|-----:|--------:|--------:|
| 5 | 68.9% | - |
| 10 | 70.3% | +1.4% |
| 15 | 75.1% | +6.2% |
| 20 | 80.5% | +11.6% |
| 25 | 83.8% | +14.9% |
| 30 | 86.0% | +17.1% |
| 35 | 88.4% | +19.5% |
| 40 | 89.8% | +20.9% |
| 45 | 91.0% | +22.1% |
| 50 | 91.7% | +22.8% |
| 55 | 91.9% | +23.0% |
| 60 | **92.4%** | +23.5% |

**ODCM（20iterで早期停止）**:
| Iter | Val ER% | 備考 |
|-----:|--------:|:-----|
| 5 | 72.3% | - |
| 10 | 76.2% | +3.9% |
| 15 | **80.1%** | +7.8%（最高値）|
| 20 | 70.9% | -9.2%（急落→早期停止）|

ODCM はcontext_dim=1000で過学習の兆候を示し、iter 15以降にVal ERが急落。
