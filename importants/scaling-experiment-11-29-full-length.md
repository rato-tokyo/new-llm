# スケーリング実験 2025-11-29（全長トークン化 + 11/27設定再現）

## 概要

11/27実験の設定（`token_input_all_layers=True`, `Embedding freeze=False`）を、全長トークン化（`truncation=False`）で再現した実験。

**スケーリング則**: `PPL = 37,792 × tokens^(-0.35)`

**α = -0.35** (2倍のデータで22% PPL削減)

---

## 実験設定

| 設定 | 値 |
|------|-----|
| GPU | NVIDIA L4 (22.2GB) |
| モデル | 6層, context_dim=768, embed_dim=768 |
| パラメータ | 91.43M (うちPhase 2学習対象: 45.74M) |
| num_input_tokens | 1 |
| token_input_all_layers | **True** (11/27設定) |
| Embedding freeze | **False** (11/27設定) |
| トークン化 | **truncation=False (全長)** |
| 乱数シード | 42 |
| Phase 1 | max_iterations=40, early stopping |
| Phase 2 | epochs=10, patience=1 |

---

## 実験結果

### 実験1: 50サンプル

| フェーズ | 項目 | 値 |
|---------|------|-----|
| データ | 訓練トークン | 56,602 |
| データ | 検証トークン | 6,289 |
| Phase 1 | 収束イテレーション | 7/40 (early stop) |
| Phase 1 | 収束率 | 99.3% |
| Phase 1 | Train ER | 75.1% |
| Phase 1 | Val ER | 71.6% |
| Phase 1 | 所要時間 | 1.3min |
| Phase 2 | Best Epoch | 7/10 (early stop at 8) |
| Phase 2 | **Val PPL** | **799.42** |
| Phase 2 | **Val Acc** | **17.11%** |
| Phase 2 | 所要時間 | 1.4min |
| | キャッシュサイズ | 994.9MB + 110.5MB |

### 実験2: 100サンプル

| フェーズ | 項目 | 値 |
|---------|------|-----|
| データ | 訓練トークン | 110,516 |
| データ | 検証トークン | 12,279 |
| Phase 1 | 収束イテレーション | 7/40 (early stop) |
| Phase 1 | 収束率 | 99.3% |
| Phase 1 | Train ER | 75.6% |
| Phase 1 | Val ER | 73.0% |
| Phase 1 | 所要時間 | 2.5min |
| Phase 2 | Best Epoch | 6/10 (early stop at 7) |
| Phase 2 | **Val PPL** | **680.12** |
| Phase 2 | **Val Acc** | **17.77%** |
| Phase 2 | 所要時間 | 2.8min |
| | キャッシュサイズ | 1942.6MB + 215.8MB |

### 実験3: 200サンプル

| フェーズ | 項目 | 値 |
|---------|------|-----|
| データ | 訓練トークン | 216,119 |
| データ | 検証トークン | 24,013 |
| Phase 1 | 収束イテレーション | 7/40 (early stop) |
| Phase 1 | 収束率 | 99.2% |
| Phase 1 | Train ER | 76.3% |
| Phase 1 | Val ER | 73.7% |
| Phase 1 | 所要時間 | 4.9min |
| Phase 2 | Best Epoch | 4/10 (early stop at 5) |
| Phase 2 | **Val PPL** | **500.12** |
| Phase 2 | **Val Acc** | **20.81%** |
| Phase 2 | 所要時間 | 5.1min |
| | キャッシュサイズ | 3798.9MB + 422.1MB |

### 実験4: 500サンプル（OOMで中断）

| フェーズ | 項目 | 値 |
|---------|------|-----|
| データ | 訓練トークン | 529,173 |
| データ | 検証トークン | 58,797 |
| Phase 1 | 収束イテレーション | 7/40 (early stop) |
| Phase 1 | 収束率 | 99.2% |
| Phase 1 | Train ER | 75.9% |
| Phase 1 | Val ER | 75.5% |
| Phase 1 | 所要時間 | 11.8min |
| Phase 2 | キャッシュ構築 | 完了 (646.1s) |
| Phase 2 | キャッシュサイズ | **9301.9MB + 1033.5MB = 10.3GB** |
| Phase 2 | **エラー** | **CUDA OOM** (22.2GB中21.4GB使用中) |

**500サンプルのOOM原因**:
- キャッシュが10.3GB使用
- モデル + 勾配で残り〜11GB
- バッチ処理でlogits (50257 × batch_size × 4) が必要
- 1.66GBのアロケーション要求で失敗

---

## スケーリング則（実験1-3）

```
PPL = A × tokens^α

α = -0.3501
A = 37,791.58
R² = 0.9690
```

| サンプル数 | トークン数 | Val PPL | Val Acc |
|-----------|-----------|---------|---------|
| 50 | 56,602 | 799.42 | 17.11% |
| 100 | 110,516 | 680.12 | 17.77% |
| 200 | 216,119 | 500.12 | 20.81% |

**解釈**: 2倍のデータで約22% PPL削減

### PPL予測（外挿）

| トークン数 | 予測PPL |
|-----------|---------|
| 500,000 | 382 |
| 1,000,000 | 300 |
| 5,000,000 | 171 |
| 10,000,000 | 134 |

---

## 11/27実験との比較

| 項目 | 11/27実験 | 本実験 (11/29) |
|------|----------|---------------|
| トークン化 | max_length=128 | truncation=False (全長) |
| tokens/sample | ~80 | ~174 (2.2倍) |
| α値 | **-0.75** | **-0.35** |
| 500samples時PPL | 1,145 | 500.12 (200samplesで) |

**考察**:
- 全長トークン化により、同じサンプル数でもトークン数が2.2倍に増加
- α値が-0.75から-0.35に低下（見かけ上のスケーリング効率が下がった）
- しかし絶対的なPPLは改善（より多くの情報を学習）

---

## Phase 1 分析

### Effective Rank推移

| サンプル数 | Train ER | Val ER |
|-----------|----------|--------|
| 50 | 75.1% | 71.6% |
| 100 | 75.6% | 73.0% |
| 200 | 76.3% | 73.7% |
| 500 | 75.9% | 75.5% |

**観察**:
- Effective Rankは75-76%で安定
- データ量増加によるER低下は見られない
- 検証データのERも70-75%を維持

### 収束特性

- 全実験で7イテレーションで早期終了
- 収束率は99%以上を達成
- CVFPロスは安定して減少

---

## 技術的問題と解決策

### 500サンプルでのOOM問題

**原因**:
1. キャッシュサイズ: 10.3GB (GPU総容量の46%)
2. モデル + 勾配: 約11GB
3. バッチ処理時のlogits: 1.66GB要求 → 失敗

**解決策（実装済み）**:
```python
# src/trainers/phase2.py に自動メモリ管理を追加
- キャッシュ構築前にメモリ要件を事前見積もり
- キャッシュ構築後に空きメモリを確認
- バッチサイズを自動的に削減（安全係数0.5）
```

---

## 次のステップ

1. **500サンプル実験の再実行**
   - 自動メモリ管理機能を使用
   - `git pull` して最新コードで実行

2. **α値の検証**
   - 4点データでスケーリング則を再計算
   - より正確なα値を導出

3. **さらなる大規模実験**
   - 1000サンプル以上での検証
   - α値の収束挙動を確認

---

## 関連ファイル

- [scaling-experiments-summary-2025-11-28.md](scaling-experiments-summary-2025-11-28.md) - 過去実験のまとめ
- [scripts/unified_scaling_experiment.py](../scripts/unified_scaling_experiment.py) - 実験スクリプト
- [src/utils/memory.py](../src/utils/memory.py) - メモリ管理ユーティリティ（新規追加）

---

## 実験ログ

実験ログファイル: `colab_1_3.txt`

実験日時: 2025-11-29 03:12:47 開始
