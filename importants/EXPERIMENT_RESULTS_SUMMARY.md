# 実験結果統合サマリー (2025年12月)

**作成日**: 2025-12-02
**統合元**: experiment-results-20251202-*.md (4ファイル)

---

## 最終結論

### 🏆 推奨構成: Cascade Context (cd=500×2)

| 指標 | 値 | 備考 |
|------|-----|------|
| **Val PPL** | **111.9** | 全構成中最良 |
| **Val Acc** | **25.6%** | 全構成中最高 |
| 実効次元 | 736/1000 (73.6%) | 絶対値で最大 |
| パラメータ | 41.2M | C1T1-500と同等 |

### 代替構成: C1T1 (cd=500)

| 指標 | 値 | 備考 |
|------|-----|------|
| Val PPL | 127.2 | バランス重視 |
| Val Acc | 24.7% | - |
| ER | 79.7% | 割合では最高 |
| パラメータ | 40.2M | 最小 |

---

## 1. レイヤー構成比較

**結論: C1T1（1層+1層）が最良。層を増やしても改善なし。**

| Config | Context層 | Token層 | Val PPL | Val Acc |
|--------|-----------|---------|---------|---------|
| **C1T1** | 1 | 1 | **127.2** | **24.7%** |
| C2T1 | 2 | 1 | 138.7 | 23.2% |
| C2T2 | 2 | 2 | 132.2 | 24.4% |
| C1T2 | 1 | 2 | 300.8 | 17.4% |

**重要な発見**:
- C1T2（Token層だけ深い）は性能が大幅悪化 → **絶対に避ける**
- 2層構成はPhase 1収束が速いが（14 iter vs 30 iter）、最終性能は1層が勝る

---

## 2. Early Stopping閾値（収束率）

**結論: 90%が最適。99%は過収束で悪化。**

| DWR | Config | Val PPL | Val Acc |
|-----|--------|---------|---------|
| **0.90** | C1T1 | **127.2** | **24.7%** |
| 0.99 | C1T1 | 235.1 | 18.5% |
| 0.90 | C2T2 | 132.2 | 24.4% |
| 0.99 | C2T2 | 133.0 | 24.5% |

**重要な発見**:
- C1T1でdwr=0.99にするとPPL +85%悪化、Acc -6.2%低下
- C2T2は0.90/0.99で差なし（2層の冗長性がバッファ）
- **1層モデルでは適度な収束（90%）が最適**

---

## 3. context_dim比較

**結論: cd=500が全指標で優位。cd=1000はメリットなし。**

| context_dim | Config | Val PPL | ER% | 収束iter |
|-------------|--------|---------|-----|----------|
| **500** | C1T1 | **127.2** | **79.7%** | 30 |
| 1000 | C1T1 | 134.0 | 69.3% | 46 |
| **500** | C2T2 | **132.2** | **79.6%** | 14 |
| 1000 | C2T2 | 137.9 | 73.4% | 24 |

**cd=1000のデメリット**:
- PPL: +4-5%悪化
- ER: -6〜10%低下
- 収束: +50-70%遅延
- 処理時間: +24-36%増加

---

## 4. Dual/Cascade Context

**結論: cd=500×2の連結がcd=1000単体より大幅に優れる。**

| 構成 | context_dim | Val PPL | Val Acc | ER% |
|------|-------------|---------|---------|-----|
| **Dual** | 500×2=1000 | **111.9** | **25.6%** | 73.6% |
| C1T1 | 500 | 127.2 | 24.7% | 79.7% |
| C1T1 | 1000 | 134.0 | 23.6% | 69.3% |

**Dual Contextの優位性**:
- PPL: -12% vs C1T1-500
- Acc: +0.9% vs C1T1-500
- 実効次元: 736（絶対値で最大）
- 各ブロックが異なるデータで専門化 → 相補的表現

**トレードオフ**:
- 処理時間: 1745s vs 1200s（+45%）
- 実装複雑度: やや高い

---

## 設計指針

### 最高精度を目指す場合

```python
architecture = "CascadeContext"
context_dim_per_block = 500
num_blocks = 2
# → combined_context_dim = 1000
```

### バランス重視の場合

```python
architecture = "Standard"
context_dim = 500
num_layers = 1  # C1T1
early_stopping_threshold = 0.90
```

### 避けるべき設定

- ❌ C1T2（Token層だけ深い）
- ❌ context_dim = 1000（単体）
- ❌ early_stopping_threshold = 0.99（C1T1使用時）

---

## 実験環境

| 項目 | 値 |
|------|-----|
| GPU | NVIDIA L4 (22.2GB) |
| Samples | 2000 |
| Train tokens | 2,403,563 |
| Val tokens | 22,723 |

---

*Last Updated: 2025-12-02*
*詳細データは old/ フォルダ参照*
