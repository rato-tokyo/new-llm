# Scaling Experiment Report (2025-11-27)

## 実験概要

Colab L4 GPUを使用したサンプル数スケーリング実験。
訓練トークン数とValidation PPLの関係を調査し、スケーリング則を導出。

## 実験環境

- **GPU**: NVIDIA L4 (23.8GB)
- **モデル**: E案アーキテクチャ (ContextBlock + TokenBlock)
  - ContextBlock: 3 layers
  - TokenBlock: 3 layers
  - context_dim: 768
- **パラメータ数**: 84,338,257 (全体), 42,193,489 (Phase 2学習対象)
- **Phase 1設定**:
  - max_iterations: 10
  - learning_rate: 0.002
  - dist_reg_weight: 0.5
- **Phase 2設定**:
  - epochs: 10
  - batch_size: 512
  - patience: 2 (early stopping)

## 実験結果

| Samples | Train Tokens | Val Tokens | Val PPL | Val Acc | Train ER% | Val ER% | Time |
|---------|-------------|------------|---------|---------|-----------|---------|------|
| 50 | 3,495 | 690 | 7,152.28 | 10.01% | 77.9% | 58.0% | 1.4min |
| 100 | 7,466 | 690 | 3,360.15 | 7.40% | 79.7% | 57.4% | 1.9min |
| 200 | 15,832 | 690 | 2,439.31 | 9.14% | 79.6% | 56.9% | 3.9min |
| 500 | 39,814 | 690 | 1,171.15 | 13.79% | 78.9% | 56.3% | 9.8min |

**Total experiment time**: 17.2 minutes

## スケーリング則

### PPL vs Train Tokens

PPLはべき乗則（Power Law）に従う：

```
PPL = A × N^(-α)
```

### 線形回帰分析（scipy.stats.linregress使用）

対数変換したデータで線形回帰を実施：

| Tokens (N) | log(N) | PPL | log(PPL) |
|------------|--------|-----|----------|
| 3,495 | 8.1591 | 7,152.28 | 8.8752 |
| 7,466 | 8.9181 | 3,360.15 | 8.1197 |
| 15,832 | 9.6698 | 2,439.31 | 7.7995 |
| 39,814 | 10.5920 | 1,171.15 | 7.0657 |

### 回帰結果

| 統計量 | 値 |
|--------|-----|
| **傾き (α)** | **0.7143** |
| **切片 log(A)** | 14.6331 |
| **A** | 2,264,935 |
| **R²** | **0.9818** |
| **p-value** | 0.0092 |
| **標準誤差** | 0.0689 |

### 導出された数式

```
log(PPL) = 14.63 - 0.7143 × log(N)
```

または：

```
PPL = 2,264,935 × N^(-0.7143)
```

**スケーリング指数 α = 0.7143**

### モデルの適合度

| Tokens | 実測PPL | 予測PPL | 誤差 |
|--------|---------|---------|------|
| 3,495 | 7,152.28 | 6,666.37 | -6.79% |
| 7,466 | 3,360.15 | 3,876.32 | +15.36% |
| 15,832 | 2,439.31 | 2,265.84 | -7.11% |
| 39,814 | 1,171.15 | 1,172.58 | +0.12% |

## PPL予測表

| Train Tokens | 予測 PPL | 備考 |
|--------------|----------|------|
| 3,495 | 6,666 | 実測: 7,152 |
| 7,466 | 3,876 | 実測: 3,360 |
| 15,832 | 2,266 | 実測: 2,439 |
| 39,814 | 1,173 | 実測: 1,171 |
| 100,000 | **607** | 予測 |
| 500,000 | **192** | 予測 |
| 1,000,000 | **117** | 予測 |
| 10,000,000 | **23** | 予測 |

## 分析に使用したPythonコード

```python
import numpy as np
from scipy import stats

# 実験データ
tokens = np.array([3495, 7466, 15832, 39814])
ppl = np.array([7152.28, 3360.15, 2439.31, 1171.15])

# 対数変換
log_tokens = np.log(tokens)
log_ppl = np.log(ppl)

# 線形回帰: log(PPL) = a + b * log(N)
slope, intercept, r_value, p_value, std_err = stats.linregress(log_tokens, log_ppl)

# 結果
# slope = -0.7143 (α)
# intercept = 14.6331 (log(A))
# A = exp(14.6331) = 2,264,935
# R² = 0.9818
```

## 観察事項

### Phase 1 (CVFP Learning)
- 全サンプル数で**9イテレーション**で早期停止（収束率 > 95%）
- Train Effective Rank: 77.9% - 79.7%（安定）
- Val Effective Rank: 56.3% - 58.0%（サンプル増加で微減）
- 検証データはすべて**CONVERGED**状態

### Phase 2 (Next-Token Prediction)
- 全実験で**Epoch 1が最良**（early stoppingでEpoch 3-4で停止）
- 過学習傾向が強い（TrainとValの乖離が大きい）
- サンプル数増加でVal Accが改善（10.01% → 13.79%）

### 問題点・課題
1. **Val Accの不規則性**: 100サンプルで7.40%と低下
   - early stoppingが早すぎた可能性
2. **過学習**: Train Lossは下がるがVal Lossが上昇
   - 正則化の強化が必要かもしれない
3. **データポイント不足**: 4点のみでスケーリング則を推定
   - より多くのデータポイントで精度向上が期待される

## GPU消費量

| Samples | Train Tokens | GPU Memory |
|---------|-------------|------------|
| 50 | 3,495 | ~4.8GB |
| 200 | 15,832 | ~6GB (batch_size=512) |
| 500 | 39,814 | ~8GB (推定) |

**注意**: `phase2_batch_size=16000`だと16GB超消費。512推奨。

## 実験データ

- **出力ファイル**: `results/colab_scaling_experiment.json`
- **ログ**: `colab_output.txt`

## 結論

1. **スケーリング則の確認**: PPLはトークン数のべき乗に反比例（α=0.7143, R²=0.9818）
2. **実用的なPPL達成には大量データが必要**: PPL<100には約100万トークン以上が必要
3. **モデルアーキテクチャの検証**: E案（レイヤー対応版）は機能している
4. **過学習対策が次の課題**: 正則化、dropout、データ増強などの検討
