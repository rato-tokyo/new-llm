# スケーリング則まとめ (Scaling Laws Summary)

**最終更新**: 2025-12-02

---

## スケーリング則の基本式

```
PPL = A × tokens^α
```

- **α (スケーリング指数)**: 負の値。絶対値が大きいほどデータ増加の恩恵が大きい
- **A**: 定数項（モデル・設定依存）
- **R²**: 決定係数（1に近いほどフィットが良い）

### α値の解釈

| α値 | 2倍データでのPPL削減率 |
|-----|----------------------|
| -0.3 | 約19% |
| -0.4 | 約24% |
| -0.5 | 約29% |

---

## 主要な発見

### 1. トークン数が支配的要因

PPLの改善はEffective Rank (ER)ではなく、**トークン数（データ量）**に支配される。

| 要因 | 重要度 |
|------|--------|
| **トークン数** | ★★★★★ |
| **Effective Rank** | ★★☆☆☆ |

### 2. context_dim=500が最適

| context_dim | Val ER | Best PPL |
|-------------|--------|----------|
| **500** | **79.7%** | **127.2** |
| 768 | 77-81% | 中程度 |
| 1000+ | 69-73% | 悪化 |

### 3. Cascade Contextによる改善

単一cd=1000より、cd=500×2のCascade連結が優れる。

| 構成 | Val PPL |
|------|---------|
| **Cascade (500×2)** | **111.9** |
| 単一 (1000) | 134.0 |

---

## PPL予測表（参考値）

### Cascade Context (α ≈ -0.5)

| Tokens | 予測 PPL |
|--------|----------|
| 500,000 | ~180 |
| 1,000,000 | ~130 |
| 2,000,000 | ~90 |
| 5,000,000 | ~60 |

---

## 実用的推奨事項

1. **データ量を優先**: ERの改善よりトークン数増加が効果的
2. **context_dim=500**: これ以上は効果薄い
3. **Cascade Context採用**: 高次元が必要ならcd=500×2連結
4. **早期停止90%**: 過収束は悪影響

---

*Last Updated: 2025-12-02*
