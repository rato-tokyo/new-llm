# Training Resume Guide - è¨“ç·´å†é–‹ã‚¬ã‚¤ãƒ‰

## æ¦‚è¦

è¨“ç·´ã®é€”ä¸­ã§ä¸­æ–­ã—ãŸå ´åˆã€ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å†é–‹ã§ãã¾ã™ã€‚

---

## ğŸ”„ è‡ªå‹•ä¿å­˜ã•ã‚Œã‚‹ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ

è¨“ç·´ä¸­ã€ä»¥ä¸‹ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãŒè‡ªå‹•ä¿å­˜ã•ã‚Œã¾ã™ï¼š

| ãƒ•ã‚¡ã‚¤ãƒ«å | ä¿å­˜ã‚¿ã‚¤ãƒŸãƒ³ã‚° | å†…å®¹ |
|-----------|--------------|------|
| `best_{model_name}.pt` | Validation LossãŒæ”¹å–„æ™‚ | **æœ€è‰¯ãƒ¢ãƒ‡ãƒ«** |
| `{model_name}_epoch_5.pt` | 5ã‚¨ãƒãƒƒã‚¯ã”ã¨ | å®šæœŸãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ |
| `{model_name}_final.pt` | è¨“ç·´å®Œäº†æ™‚ | **æœ€çµ‚ãƒ¢ãƒ‡ãƒ«** |

### ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®å†…å®¹

å„`.pt`ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯ä»¥ä¸‹ãŒä¿å­˜ã•ã‚Œã¦ã„ã¾ã™ï¼š
- ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ (`model_state_dict`)
- OptimizerçŠ¶æ…‹ (`optimizer_state_dict`)
- è¨“ç·´å±¥æ­´ (`train_losses`, `val_losses`, `train_ppls`, `val_ppls`)
- ç¾åœ¨ã®ã‚¨ãƒãƒƒã‚¯æ•° (`current_epoch`)
- è¨­å®š (`config`)

---

## ğŸš€ è¨“ç·´å†é–‹ã®æ–¹æ³•

### æ–¹æ³•1: ã‚¹ã‚¯ãƒªãƒ—ãƒˆå†…ã§æŒ‡å®š

```python
# scripts/train_wikitext_advanced.py ã®ä¾‹

from src.training.trainer import Trainer

# Trainerä½œæˆ
trainer = Trainer(
    model=model,
    train_dataloader=train_dataloader,
    val_dataloader=val_dataloader,
    config=config,
    model_name="new_llm_wikitext_ctx512_layers12"
)

# è¨“ç·´å†é–‹ï¼ˆãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰ï¼‰
trainer.train(
    resume_from="new_llm_wikitext_ctx512_layers12_epoch_25.pt"
)
```

### æ–¹æ³•2: Trainerä½œæˆå¾Œã«æ‰‹å‹•ãƒ­ãƒ¼ãƒ‰

```python
from src.training.trainer import Trainer

trainer = Trainer(...)

# ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰çŠ¶æ…‹ã‚’å¾©å…ƒ
start_epoch = trainer.resume_from_checkpoint("best_new_llm_wikitext.pt")

# è¨“ç·´å®Ÿè¡Œï¼ˆè‡ªå‹•çš„ã«ç¶šãã‹ã‚‰é–‹å§‹ï¼‰
trainer.train()
```

---

## ğŸ“‹ ä½¿ç”¨ä¾‹

### ä¾‹1: Google Colabã§90åˆ†åˆ¶é™ã«å¼•ã£ã‹ã‹ã£ãŸå ´åˆ

```python
# 1å›ç›®ã®å®Ÿè¡Œï¼ˆEpoch 25ã¾ã§é€²ã‚“ã ã¨ã“ã‚ã§åˆ‡æ–­ï¼‰
trainer.train()  # â†’ epoch_25.pt ãŒä¿å­˜ã•ã‚Œã‚‹

# 2å›ç›®ã®å®Ÿè¡Œï¼ˆå†æ¥ç¶šå¾Œï¼‰
trainer = Trainer(...)
trainer.train(resume_from="new_llm_wikitext_epoch_25.pt")
# â†’ Epoch 26ã‹ã‚‰å†é–‹
```

### ä¾‹2: æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰å†è¨“ç·´

```python
# ã‚ˆã‚Šé•·ãè¨“ç·´ã—ãŸã„å ´åˆ
trainer = Trainer(...)
trainer.train(
    num_epochs=100,  # 50 â†’ 100ã«å»¶é•·
    resume_from="best_new_llm_wikitext.pt"
)
```

### ä¾‹3: ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ã«æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰

```python
# WikiTextã§è¨“ç·´ã—ãŸbestãƒ¢ãƒ‡ãƒ«ã‚’DailyDialogã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
trainer = Trainer(...)
trainer.resume_from_checkpoint("best_new_llm_wikitext.pt")
trainer.train()  # ç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ç¶šãã‹ã‚‰è¨“ç·´
```

---

## ğŸ” ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®ç¢ºèª

åˆ©ç”¨å¯èƒ½ãªãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ç¢ºèªï¼š

```bash
ls -lh checkpoints/*.pt
```

æœ€æ–°ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ç¢ºèªï¼š

```bash
ls -lt checkpoints/*.pt | head -5
```

---

## ğŸ’¡ Tips

### 1. å®šæœŸãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®æ´»ç”¨

5ã‚¨ãƒãƒƒã‚¯ã”ã¨ã«ä¿å­˜ã•ã‚Œã‚‹ã®ã§ã€ä»»æ„ã®æ™‚ç‚¹ã‹ã‚‰å†é–‹å¯èƒ½ï¼š

```python
# Epoch 15ã‹ã‚‰å†é–‹
trainer.train(resume_from="new_llm_wikitext_epoch_15.pt")

# Epoch 20ã‹ã‚‰å†é–‹
trainer.train(resume_from="new_llm_wikitext_epoch_20.pt")
```

### 2. bestãƒ¢ãƒ‡ãƒ«ã®å„ªå…ˆä½¿ç”¨

é€šå¸¸ã¯ `best_{model_name}.pt` ã‚’ä½¿ã†ã®ãŒæ¨å¥¨ï¼š

```python
# æœ€è‰¯æ€§èƒ½ã®ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰å†é–‹
trainer.train(resume_from="best_new_llm_wikitext.pt")
```

### 3. è¨“ç·´å®Œäº†å¾Œã®è¿½åŠ è¨“ç·´

`final.pt` ã‚’ä½¿ã£ã¦è¿½åŠ è¨“ç·´ãŒå¯èƒ½ï¼š

```python
# 50ã‚¨ãƒãƒƒã‚¯ã§çµ‚äº†ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’100ã‚¨ãƒãƒƒã‚¯ã¾ã§å»¶é•·
trainer.train(
    num_epochs=100,
    resume_from="new_llm_wikitext_final.pt"
)
```

---

## âš ï¸ æ³¨æ„äº‹é …

### 1. ãƒ¢ãƒ‡ãƒ«æ§‹æˆã®ä¸€è‡´

ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹éš›ã€**ãƒ¢ãƒ‡ãƒ«ã®æ§‹æˆï¼ˆconfigï¼‰ãŒä¸€è‡´**ã—ã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼š

```python
# âœ“ OK - åŒã˜æ§‹æˆ
config = AdvancedConfig()  # context_vector_dim=512, num_layers=12
model = ContextVectorLLM(config)
trainer = Trainer(model, ...)
trainer.train(resume_from="new_llm_wikitext_ctx512_layers12_epoch_10.pt")

# âœ— NG - ç•°ãªã‚‹æ§‹æˆ
config = AdvancedConfig()
config.context_vector_dim = 1024  # 512 â†’ 1024ã«å¤‰æ›´
model = ContextVectorLLM(config)
trainer = Trainer(model, ...)
trainer.train(resume_from="new_llm_wikitext_ctx512_layers12_epoch_10.pt")
# â†’ ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«æ§‹é€ ãŒä¸€è‡´ã—ãªã„
```

### 2. ãƒ‡ãƒã‚¤ã‚¹ã®ä¸€è‡´

CPU/GPUã¯è‡ªå‹•çš„ã«å¯¾å¿œã•ã‚Œã¾ã™ãŒã€å¿µã®ãŸã‚ç¢ºèªï¼š

```python
# ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã¯CPU/GPUé–“ã§å…±æœ‰å¯èƒ½
config.device = "cuda" if torch.cuda.is_available() else "cpu"
```

### 3. early stoppingã®ãƒªã‚»ãƒƒãƒˆ

è¨“ç·´å†é–‹æ™‚ã€early stoppingã®ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã¯ãƒªã‚»ãƒƒãƒˆã•ã‚Œã¾ã™ã€‚

---

## ğŸ“Š å†é–‹æ™‚ã®è¡¨ç¤ºä¾‹

```
============================================================
Resuming from checkpoint: new_llm_wikitext_epoch_25.pt
============================================================
Completed epochs: 25
Best Val Loss so far: 3.1563
Best Val PPL so far: 23.48
============================================================

Resuming from epoch 26

============================================================
Training new_llm_wikitext
============================================================

Epoch 26/50
  Training... 20% 40% 60% 80% 100% | 0.6min | Loss: 3.1200
  Val: Loss=3.14 PPL=23.1 Acc=31.2% âœ“
```

---

## ğŸ¯ ã¾ã¨ã‚

- âœ… **è‡ªå‹•ä¿å­˜**: bestãƒ¢ãƒ‡ãƒ«ã¨å®šæœŸãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãŒè‡ªå‹•ä¿å­˜ã•ã‚Œã‚‹
- âœ… **ç°¡å˜å†é–‹**: `resume_from="checkpoint.pt"` ã§1è¡Œã§å†é–‹
- âœ… **å±¥æ­´ä¿æŒ**: è¨“ç·´å±¥æ­´ã‚‚å¾©å…ƒã•ã‚Œã‚‹ã®ã§ã€ã‚°ãƒ©ãƒ•ã‚‚ç¶™ç¶šæç”»
- âœ… **æŸ”è»Ÿæ€§**: ä»»æ„ã®ã‚¨ãƒãƒƒã‚¯ã‹ã‚‰å†é–‹å¯èƒ½

**è¨“ç·´ãŒä¸­æ–­ã—ã¦ã‚‚å®‰å¿ƒã—ã¦å†é–‹ã§ãã¾ã™ï¼** ğŸš€
