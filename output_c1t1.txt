remote: Enumerating objects: 7, done.
remote: Counting objects: 100% (7/7), done.
remote: Compressing objects: 100% (1/1), done.
remote: Total 4 (delta 3), reused 4 (delta 3), pack-reused 0 (from 0)
Unpacking objects: 100% (4/4), 550 bytes | 550.00 KiB/s, done.
From https://github.com/rato-tokyo/new-llm
 * branch            main       -> FETCH_HEAD
   e0605a3..c8bd0e9  main       -> origin/main
Updating e0605a3..c8bd0e9
Fast-forward
 scripts/layer_asymmetric_experiment.py | 6 ++++--
 1 file changed, 4 insertions(+), 2 deletions(-)
======================================================================
ASYMMETRIC LAYER EXPERIMENT
======================================================================
Device: cuda
GPU: NVIDIA L4
Memory: 22.2GB

Mode: c1t1
Samples: 2000
Context dim: 500
Output: importants/logs/20251202_075428_asymmetric_c1t1
======================================================================

============================================================
Running C1T1: Context 1L, Token 1L
============================================================
tokenizer_config.json: 100% 26.0/26.0 [00:00<00:00, 184kB/s]
config.json: 100% 665/665 [00:00<00:00, 5.04MB/s]
vocab.json: 100% 1.04M/1.04M [00:00<00:00, 1.62MB/s]
merges.txt: 100% 456k/456k [00:00<00:00, 85.3MB/s]
tokenizer.json: 100% 1.36M/1.36M [00:00<00:00, 1.63MB/s]
Loading training data...
  Loading 2000 samples from UltraChat...
README.md: 3.90kB [00:00, 21.2MB/s]
data/train_sft-00000-of-00003-a3ecf92756(…): 100% 244M/244M [00:01<00:00, 123MB/s]
data/train_sft-00001-of-00003-0a1804bcb6(…): 100% 244M/244M [00:01<00:00, 185MB/s]
data/train_sft-00002-of-00003-ee46ed25cf(…): 100% 244M/244M [00:01<00:00, 232MB/s]
data/test_sft-00000-of-00001-f7dfac4afe5(…): 100% 81.2M/81.2M [00:00<00:00, 101MB/s] 
data/train_gen-00000-of-00003-a6c9fb894b(…): 100% 244M/244M [00:01<00:00, 216MB/s]
data/train_gen-00001-of-00003-d6a0402e41(…): 100% 243M/243M [00:03<00:00, 73.1MB/s]
data/train_gen-00002-of-00003-c0db75b92a(…): 100% 243M/243M [00:01<00:00, 233MB/s]  
data/test_gen-00000-of-00001-3d4cd830914(…): 100% 80.4M/80.4M [00:00<00:00, 105MB/s] 
Generating train_sft split: 100% 207865/207865 [00:04<00:00, 51584.66 examples/s]
Generating test_sft split: 100% 23110/23110 [00:00<00:00, 58407.13 examples/s]
Generating train_gen split: 100% 256032/256032 [00:03<00:00, 74252.41 examples/s]
Generating test_gen split: 100% 28304/28304 [00:00<00:00, 76711.51 examples/s]
Token indices sequence length is longer than the specified maximum sequence length for this model (1464 > 1024). Running this sequence through the model will result in indexing errors
  Cached to: ./cache/ultrachat_2000samples_full.pt
Loading validation data...
  Validation file not found, generating: ./cache/example_val.txt
  Generated 20 validation samples (indices 50000-50019)
  Train: 2403563 tokens (2000 samples)
  Val:   22723 tokens
Data: 2,403,563 train, 22,723 val tokens
2025-12-02 07:55:13.641850: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-12-02 07:55:13.657574: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1764662113.675688    3502 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1764662113.681003    3502 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1764662113.695942    3502 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1764662113.695967    3502 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1764662113.695970    3502 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1764662113.695972    3502 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-12-02 07:55:13.700810: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
Loading GPT-2 pretrained embeddings...
config.json: 100% 665/665 [00:00<00:00, 5.44MB/s]
model.safetensors: 100% 548M/548M [00:00<00:00, 574MB/s]
✓ Loaded GPT-2 embeddings: torch.Size([50257, 768])
Using G案 architecture: ContextBlock(1L) + TokenBlock(1L)
  num_input_tokens: 1
  Context injection: Layer1=current (single layer)
✓ Weight Tying: token_output shares weights with token_embedding
  → Saved ~38.60M parameters
Parameters: 40,210,540 total
  ContextBlock: 635,500
  TokenBlock: 976,128

[Phase 1] OACD: 2,403,563 tokens, 60 iterations
  Iter 1: random init
  Iter 2: conv=0% loss=11.2666 [12.4s]
  Iter 3: conv=0% loss=13.2686 [9.9s]
  Iter 4: conv=0% loss=10.7604 [9.9s]
  Iter 5: conv=0% loss=7.2892 [10.0s]
  Iter 6: conv=0% loss=4.6364 [9.9s]
  Iter 7: conv=0% loss=3.3867 [9.8s]
  Iter 8: conv=0% loss=3.0639 [9.9s]
  Iter 9: conv=0% loss=3.0013 [9.9s]
  Iter 10: conv=0% loss=2.9394 [9.9s]
  Iter 11: conv=1% loss=2.8770 [9.4s]
  Iter 12: conv=1% loss=2.8110 [10.0s]
  Iter 13: conv=2% loss=2.7113 [9.8s]
  Iter 14: conv=3% loss=2.5479 [9.8s]
  Iter 15: conv=4% loss=2.3238 [9.9s]
  Iter 16: conv=7% loss=2.0882 [9.9s]
  Iter 17: conv=11% loss=1.8952 [9.9s]
  Iter 18: conv=17% loss=1.7504 [9.9s]
  Iter 19: conv=24% loss=1.6307 [9.9s]
  Iter 20: conv=33% loss=1.5246 [10.0s]
  Iter 21: conv=43% loss=1.4308 [10.0s]
  Iter 22: conv=53% loss=1.3427 [9.8s]
  Iter 23: conv=62% loss=1.2548 [9.9s]
  Iter 24: conv=69% loss=1.1714 [9.5s]
  Iter 25: conv=75% loss=1.1009 [9.9s]
  Iter 26: conv=80% loss=1.0451 [10.0s]
  Iter 27: conv=84% loss=1.0027 [9.9s]
  Iter 28: conv=87% loss=0.9750 [10.0s]
  Iter 29: conv=90% loss=0.9633 [9.9s]
  Iter 30: conv=92% loss=0.9593 [9.9s]
  Iter 31: conv=94% loss=0.9469 [9.9s]
  Iter 32: conv=95% loss=0.9135 [9.9s]
  Iter 33: conv=96% loss=0.8591 [9.9s]
  Iter 34: conv=96% loss=0.7980 [10.0s]
  Iter 35: conv=97% loss=0.7499 [9.8s]
  Iter 36: conv=97% loss=0.7253 [9.9s]
  Iter 37: conv=98% loss=0.7198 [10.0s]
  Iter 38: conv=98% loss=0.7190 [9.8s]
  Iter 39: conv=99% loss=0.7098 [9.9s]
  Iter 40: conv=99% loss=0.6881 [9.9s]
  Iter 41: conv=99% loss=0.6587 [9.9s]
  → Early stop: conv 99% >= 99%
  Done: 99% converged
  Collecting cache (parallel)...
  Cache collected (parallel) [8.0s]
Phase 1: 429.9s, 41 iter, conv=99%, ER=77.7%/76.1%
✓ ContextBlock frozen
✓ Embedding frozen (Weight Tying: Output Head also frozen)
  → Only TokenBlock will be trained
✓ Training TokenBlock only: 977,664/40,210,540 parameters

[Phase 2] 2,403,563 train / 22,723 val tokens, 20 epochs
  Epoch 1: train_ppl=986.5 val_ppl=346.0 acc=16.5% [54.7s] ★
  Epoch 2: train_ppl=219.3 val_ppl=274.3 acc=17.5% [54.0s] ★
  Epoch 3: train_ppl=167.8 val_ppl=252.8 acc=18.0% [54.5s] ★
  Epoch 4: train_ppl=144.2 val_ppl=243.5 acc=18.3% [54.3s] ★
  Epoch 5: train_ppl=130.4 val_ppl=238.9 acc=18.5% [54.5s] ★
  Epoch 6: train_ppl=121.4 val_ppl=236.6 acc=18.5% [54.4s] ★
  Epoch 7: train_ppl=114.9 val_ppl=235.5 acc=18.4% [54.5s] ★
  Epoch 8: train_ppl=110.0 val_ppl=235.1 acc=18.5% [54.4s] ★
  Epoch 9: train_ppl=106.1 val_ppl=235.3 acc=18.5% [54.5s]
  → Early stop at epoch 9
  Best: epoch 8, ppl=235.1, acc=18.5%
Phase 2: 489.7s, Best epoch 8
Result: PPL=235.1, Acc=18.5%
Total time: 919.5s

======================================================================
SUMMARY
======================================================================

Config     Context  Token    Params       Val PPL    Acc      ER%      Time    
--------------------------------------------------------------------------------
C1T1       1        1        40,210,540  235.1      18.5     76.1     919.5   

Results saved to: importants/logs/20251202_075428_asymmetric_c1t1/results_c1t1.txt

======================================================================
DONE
======================================================================
